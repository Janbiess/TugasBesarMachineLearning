{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Ggjf6n7jzA"
      },
      "source": [
        "# Pytorch Quantization\n",
        "\n",
        "PyTorch mendukung kuantisasi INT8 dibandingkan dengan model FP32 yang umum sehingga memungkinkan pengurangan 4x dalam ukuran model dan pengurangan 4x dalam persyaratan bandwidth memori\n",
        "sambil tetap mencapai akurasi yang sebanding untuk banyak aplikasi. Buku catatan ini menunjukkan cara mengkuantisasi model dari FP32 ke INT8 menggunakan perkakas kuantisasi PyTorch. Kami akan melatih model CNN sederhana pada mnist dan kemudian mengkuantisasinya menggunakan perkakas kuantisasi dan membandingkan akurasi dan ukuran model yang dikuantisasi dengan model FP32 asli."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tqQYTtd7jzD"
      },
      "source": [
        "## Siapkan PyTorch\n",
        "\n",
        "Pertama, mari instal PyTorch dan torchvision, lalu impor modul yang diperlukan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlydkIzb7jzD",
        "outputId": "e14a692d-abdc-4873-f88c-877ec4e9f74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8IJtMx2Z7jzF"
      },
      "outputs": [],
      "source": [
        "import torch #Mengimpor pustaka PyTorch, yang digunakan untuk membangun dan melatih model deep learning.\n",
        "import torch.nn as nn # Mengimpor modul `nn` dari PyTorch, yang menyediakan berbagai lapisan dan fungsi untuk membangun jaringan saraf.\n",
        "import torch.nn.functional as F # Mengimpor fungsi fungsional dari PyTorch, yang berisi berbagai fungsi aktivasi, fungsi loss, dll.\n",
        "import torch.optim as optim # Mengimpor modul `optim` dari PyTorch, yang menyediakan algoritma optimisasi untuk memperbarui bobot model.\n",
        "from torchvision import datasets, transforms # Mengimpor `datasets` dan `transforms` dari `torchvision` untuk memudahkan pengolahan gambar dan dataset.\n",
        "import torch.quantization # Mengimpor modul kuantisasi dari PyTorch untuk mengoptimalkan model dengan mengurangi presisi data.\n",
        "import pathlib # Mengimpor pustaka `pathlib` untuk memanipulasi dan bekerja dengan path file dan direktori."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNik-js7jzG"
      },
      "source": [
        "## Kuantisasi Dinamis\n",
        "\n",
        "Untuk kuantisasi dinamis, bobot dikuantisasi tetapi aktivasi dibaca atau disimpan dalam floating point dan aktivasi hanya dikuantisasi untuk komputasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKgTyhrR7jzG"
      },
      "source": [
        "### Memuat dataset MNIST\n",
        "\n",
        "Pertama, kita memuat dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d7cnj4RZ7jzG"
      },
      "outputs": [],
      "source": [
        "# Membuat pipeline transformasi yang akan diterapkan pada data gambar\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),  # Mengubah gambar menjadi tensor PyTorch. Gambar akan dikonversi ke format tensor dengan dimensi (C, H, W), yaitu channel, tinggi, dan lebar\n",
        "        transforms.Normalize((0.1307,), (0.3081,))  # Menormalkan gambar dengan rata-rata (0.1307) dan deviasi standar (0.3081), yang sesuai dengan dataset MNIST\n",
        "        ])\n",
        "\n",
        "# Memuat dataset MNIST untuk pelatihan. Data akan disimpan di direktori './data', dan jika belum ada, dataset akan diunduh. Transformasi yang telah didefinisikan akan diterapkan pada data pelatihan\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Memuat dataset MNIST untuk pengujian (test). Transformasi yang sama akan diterapkan pada data pengujian.\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7vvU95h7jzH"
      },
      "source": [
        "### Melatih Model\n",
        "\n",
        "Selanjutnya, kami mendefinisikan model CNN sederhana dan kemudian melatihnya pada dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd-JHU4y7jzH",
        "outputId": "3c1bf30c-6a88-45f0-960d-fadcdc590bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.276172\n",
            "Train Epoch: 1 [32/60000 (0%)]\tLoss: 2.261181\n",
            "Train Epoch: 1 [64/60000 (0%)]\tLoss: 2.167956\n",
            "Train Epoch: 1 [96/60000 (0%)]\tLoss: 1.994696\n",
            "Train Epoch: 1 [128/60000 (0%)]\tLoss: 2.061158\n",
            "Train Epoch: 1 [160/60000 (0%)]\tLoss: 2.018412\n",
            "Train Epoch: 1 [192/60000 (0%)]\tLoss: 1.694208\n",
            "Train Epoch: 1 [224/60000 (0%)]\tLoss: 1.790973\n",
            "Train Epoch: 1 [256/60000 (0%)]\tLoss: 1.864609\n",
            "Train Epoch: 1 [288/60000 (0%)]\tLoss: 1.572603\n",
            "Train Epoch: 1 [320/60000 (1%)]\tLoss: 1.622503\n",
            "Train Epoch: 1 [352/60000 (1%)]\tLoss: 1.482278\n",
            "Train Epoch: 1 [384/60000 (1%)]\tLoss: 1.471231\n",
            "Train Epoch: 1 [416/60000 (1%)]\tLoss: 1.308674\n",
            "Train Epoch: 1 [448/60000 (1%)]\tLoss: 1.218686\n",
            "Train Epoch: 1 [480/60000 (1%)]\tLoss: 1.577137\n",
            "Train Epoch: 1 [512/60000 (1%)]\tLoss: 1.396695\n",
            "Train Epoch: 1 [544/60000 (1%)]\tLoss: 1.127923\n",
            "Train Epoch: 1 [576/60000 (1%)]\tLoss: 1.395177\n",
            "Train Epoch: 1 [608/60000 (1%)]\tLoss: 1.378385\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.363495\n",
            "Train Epoch: 1 [672/60000 (1%)]\tLoss: 0.976132\n",
            "Train Epoch: 1 [704/60000 (1%)]\tLoss: 1.051027\n",
            "Train Epoch: 1 [736/60000 (1%)]\tLoss: 1.012759\n",
            "Train Epoch: 1 [768/60000 (1%)]\tLoss: 0.994516\n",
            "Train Epoch: 1 [800/60000 (1%)]\tLoss: 0.750043\n",
            "Train Epoch: 1 [832/60000 (1%)]\tLoss: 0.966765\n",
            "Train Epoch: 1 [864/60000 (1%)]\tLoss: 0.874795\n",
            "Train Epoch: 1 [896/60000 (1%)]\tLoss: 0.888709\n",
            "Train Epoch: 1 [928/60000 (2%)]\tLoss: 0.933136\n",
            "Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.693401\n",
            "Train Epoch: 1 [992/60000 (2%)]\tLoss: 0.791802\n",
            "Train Epoch: 1 [1024/60000 (2%)]\tLoss: 0.858002\n",
            "Train Epoch: 1 [1056/60000 (2%)]\tLoss: 1.008049\n",
            "Train Epoch: 1 [1088/60000 (2%)]\tLoss: 0.715044\n",
            "Train Epoch: 1 [1120/60000 (2%)]\tLoss: 1.028037\n",
            "Train Epoch: 1 [1152/60000 (2%)]\tLoss: 0.597155\n",
            "Train Epoch: 1 [1184/60000 (2%)]\tLoss: 0.566004\n",
            "Train Epoch: 1 [1216/60000 (2%)]\tLoss: 1.020259\n",
            "Train Epoch: 1 [1248/60000 (2%)]\tLoss: 0.689708\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.577354\n",
            "Train Epoch: 1 [1312/60000 (2%)]\tLoss: 0.634361\n",
            "Train Epoch: 1 [1344/60000 (2%)]\tLoss: 0.770616\n",
            "Train Epoch: 1 [1376/60000 (2%)]\tLoss: 0.606572\n",
            "Train Epoch: 1 [1408/60000 (2%)]\tLoss: 0.540349\n",
            "Train Epoch: 1 [1440/60000 (2%)]\tLoss: 0.467351\n",
            "Train Epoch: 1 [1472/60000 (2%)]\tLoss: 0.459803\n",
            "Train Epoch: 1 [1504/60000 (3%)]\tLoss: 0.744623\n",
            "Train Epoch: 1 [1536/60000 (3%)]\tLoss: 0.481829\n",
            "Train Epoch: 1 [1568/60000 (3%)]\tLoss: 0.494497\n",
            "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.628231\n",
            "Train Epoch: 1 [1632/60000 (3%)]\tLoss: 0.419280\n",
            "Train Epoch: 1 [1664/60000 (3%)]\tLoss: 0.492227\n",
            "Train Epoch: 1 [1696/60000 (3%)]\tLoss: 0.265255\n",
            "Train Epoch: 1 [1728/60000 (3%)]\tLoss: 0.347470\n",
            "Train Epoch: 1 [1760/60000 (3%)]\tLoss: 0.501348\n",
            "Train Epoch: 1 [1792/60000 (3%)]\tLoss: 0.395666\n",
            "Train Epoch: 1 [1824/60000 (3%)]\tLoss: 0.405406\n",
            "Train Epoch: 1 [1856/60000 (3%)]\tLoss: 0.368502\n",
            "Train Epoch: 1 [1888/60000 (3%)]\tLoss: 0.393014\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.423895\n",
            "Train Epoch: 1 [1952/60000 (3%)]\tLoss: 0.496026\n",
            "Train Epoch: 1 [1984/60000 (3%)]\tLoss: 0.463942\n",
            "Train Epoch: 1 [2016/60000 (3%)]\tLoss: 0.696550\n",
            "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 0.468644\n",
            "Train Epoch: 1 [2080/60000 (3%)]\tLoss: 0.376793\n",
            "Train Epoch: 1 [2112/60000 (4%)]\tLoss: 0.377102\n",
            "Train Epoch: 1 [2144/60000 (4%)]\tLoss: 0.150835\n",
            "Train Epoch: 1 [2176/60000 (4%)]\tLoss: 0.389887\n",
            "Train Epoch: 1 [2208/60000 (4%)]\tLoss: 0.335399\n",
            "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 0.252526\n",
            "Train Epoch: 1 [2272/60000 (4%)]\tLoss: 0.425479\n",
            "Train Epoch: 1 [2304/60000 (4%)]\tLoss: 0.313010\n",
            "Train Epoch: 1 [2336/60000 (4%)]\tLoss: 0.322575\n",
            "Train Epoch: 1 [2368/60000 (4%)]\tLoss: 0.350673\n",
            "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.683227\n",
            "Train Epoch: 1 [2432/60000 (4%)]\tLoss: 0.427811\n",
            "Train Epoch: 1 [2464/60000 (4%)]\tLoss: 0.300556\n",
            "Train Epoch: 1 [2496/60000 (4%)]\tLoss: 0.163427\n",
            "Train Epoch: 1 [2528/60000 (4%)]\tLoss: 0.352947\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.293453\n",
            "Train Epoch: 1 [2592/60000 (4%)]\tLoss: 0.380516\n",
            "Train Epoch: 1 [2624/60000 (4%)]\tLoss: 0.431641\n",
            "Train Epoch: 1 [2656/60000 (4%)]\tLoss: 0.635969\n",
            "Train Epoch: 1 [2688/60000 (4%)]\tLoss: 0.370454\n",
            "Train Epoch: 1 [2720/60000 (5%)]\tLoss: 0.457423\n",
            "Train Epoch: 1 [2752/60000 (5%)]\tLoss: 0.429083\n",
            "Train Epoch: 1 [2784/60000 (5%)]\tLoss: 0.425561\n",
            "Train Epoch: 1 [2816/60000 (5%)]\tLoss: 0.388031\n",
            "Train Epoch: 1 [2848/60000 (5%)]\tLoss: 0.152747\n",
            "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.506807\n",
            "Train Epoch: 1 [2912/60000 (5%)]\tLoss: 0.363528\n",
            "Train Epoch: 1 [2944/60000 (5%)]\tLoss: 0.296403\n",
            "Train Epoch: 1 [2976/60000 (5%)]\tLoss: 0.284407\n",
            "Train Epoch: 1 [3008/60000 (5%)]\tLoss: 0.460168\n",
            "Train Epoch: 1 [3040/60000 (5%)]\tLoss: 0.590145\n",
            "Train Epoch: 1 [3072/60000 (5%)]\tLoss: 0.342059\n",
            "Train Epoch: 1 [3104/60000 (5%)]\tLoss: 0.329672\n",
            "Train Epoch: 1 [3136/60000 (5%)]\tLoss: 0.229851\n",
            "Train Epoch: 1 [3168/60000 (5%)]\tLoss: 0.235041\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.471249\n",
            "Train Epoch: 1 [3232/60000 (5%)]\tLoss: 0.171871\n",
            "Train Epoch: 1 [3264/60000 (5%)]\tLoss: 0.599800\n",
            "Train Epoch: 1 [3296/60000 (5%)]\tLoss: 0.276171\n",
            "Train Epoch: 1 [3328/60000 (6%)]\tLoss: 0.247420\n",
            "Train Epoch: 1 [3360/60000 (6%)]\tLoss: 0.432518\n",
            "Train Epoch: 1 [3392/60000 (6%)]\tLoss: 0.384973\n",
            "Train Epoch: 1 [3424/60000 (6%)]\tLoss: 0.226647\n",
            "Train Epoch: 1 [3456/60000 (6%)]\tLoss: 0.306117\n",
            "Train Epoch: 1 [3488/60000 (6%)]\tLoss: 0.471747\n",
            "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 0.465366\n",
            "Train Epoch: 1 [3552/60000 (6%)]\tLoss: 0.229960\n",
            "Train Epoch: 1 [3584/60000 (6%)]\tLoss: 0.163171\n",
            "Train Epoch: 1 [3616/60000 (6%)]\tLoss: 0.225209\n",
            "Train Epoch: 1 [3648/60000 (6%)]\tLoss: 0.416085\n",
            "Train Epoch: 1 [3680/60000 (6%)]\tLoss: 0.258900\n",
            "Train Epoch: 1 [3712/60000 (6%)]\tLoss: 0.527541\n",
            "Train Epoch: 1 [3744/60000 (6%)]\tLoss: 0.344688\n",
            "Train Epoch: 1 [3776/60000 (6%)]\tLoss: 0.421333\n",
            "Train Epoch: 1 [3808/60000 (6%)]\tLoss: 0.426599\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.197458\n",
            "Train Epoch: 1 [3872/60000 (6%)]\tLoss: 0.288508\n",
            "Train Epoch: 1 [3904/60000 (7%)]\tLoss: 0.196980\n",
            "Train Epoch: 1 [3936/60000 (7%)]\tLoss: 0.255274\n",
            "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.324067\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.344116\n",
            "Train Epoch: 1 [4032/60000 (7%)]\tLoss: 0.335951\n",
            "Train Epoch: 1 [4064/60000 (7%)]\tLoss: 0.442401\n",
            "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.245730\n",
            "Train Epoch: 1 [4128/60000 (7%)]\tLoss: 0.479274\n",
            "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 0.418209\n",
            "Train Epoch: 1 [4192/60000 (7%)]\tLoss: 0.191287\n",
            "Train Epoch: 1 [4224/60000 (7%)]\tLoss: 0.221179\n",
            "Train Epoch: 1 [4256/60000 (7%)]\tLoss: 0.513754\n",
            "Train Epoch: 1 [4288/60000 (7%)]\tLoss: 0.190019\n",
            "Train Epoch: 1 [4320/60000 (7%)]\tLoss: 0.328069\n",
            "Train Epoch: 1 [4352/60000 (7%)]\tLoss: 0.323195\n",
            "Train Epoch: 1 [4384/60000 (7%)]\tLoss: 0.296586\n",
            "Train Epoch: 1 [4416/60000 (7%)]\tLoss: 0.154063\n",
            "Train Epoch: 1 [4448/60000 (7%)]\tLoss: 0.437387\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.413342\n",
            "Train Epoch: 1 [4512/60000 (8%)]\tLoss: 0.130938\n",
            "Train Epoch: 1 [4544/60000 (8%)]\tLoss: 0.126048\n",
            "Train Epoch: 1 [4576/60000 (8%)]\tLoss: 0.258756\n",
            "Train Epoch: 1 [4608/60000 (8%)]\tLoss: 0.413938\n",
            "Train Epoch: 1 [4640/60000 (8%)]\tLoss: 0.392889\n",
            "Train Epoch: 1 [4672/60000 (8%)]\tLoss: 0.413413\n",
            "Train Epoch: 1 [4704/60000 (8%)]\tLoss: 0.170547\n",
            "Train Epoch: 1 [4736/60000 (8%)]\tLoss: 0.378984\n",
            "Train Epoch: 1 [4768/60000 (8%)]\tLoss: 0.294958\n",
            "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.302514\n",
            "Train Epoch: 1 [4832/60000 (8%)]\tLoss: 0.197746\n",
            "Train Epoch: 1 [4864/60000 (8%)]\tLoss: 0.148206\n",
            "Train Epoch: 1 [4896/60000 (8%)]\tLoss: 0.237825\n",
            "Train Epoch: 1 [4928/60000 (8%)]\tLoss: 0.516215\n",
            "Train Epoch: 1 [4960/60000 (8%)]\tLoss: 0.410987\n",
            "Train Epoch: 1 [4992/60000 (8%)]\tLoss: 0.336668\n",
            "Train Epoch: 1 [5024/60000 (8%)]\tLoss: 0.230695\n",
            "Train Epoch: 1 [5056/60000 (8%)]\tLoss: 0.359315\n",
            "Train Epoch: 1 [5088/60000 (8%)]\tLoss: 0.260906\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.400756\n",
            "Train Epoch: 1 [5152/60000 (9%)]\tLoss: 0.677601\n",
            "Train Epoch: 1 [5184/60000 (9%)]\tLoss: 0.186152\n",
            "Train Epoch: 1 [5216/60000 (9%)]\tLoss: 0.161718\n",
            "Train Epoch: 1 [5248/60000 (9%)]\tLoss: 0.173044\n",
            "Train Epoch: 1 [5280/60000 (9%)]\tLoss: 0.407480\n",
            "Train Epoch: 1 [5312/60000 (9%)]\tLoss: 0.340282\n",
            "Train Epoch: 1 [5344/60000 (9%)]\tLoss: 0.315327\n",
            "Train Epoch: 1 [5376/60000 (9%)]\tLoss: 0.301211\n",
            "Train Epoch: 1 [5408/60000 (9%)]\tLoss: 0.171825\n",
            "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 0.145924\n",
            "Train Epoch: 1 [5472/60000 (9%)]\tLoss: 0.126828\n",
            "Train Epoch: 1 [5504/60000 (9%)]\tLoss: 0.179430\n",
            "Train Epoch: 1 [5536/60000 (9%)]\tLoss: 0.690434\n",
            "Train Epoch: 1 [5568/60000 (9%)]\tLoss: 0.167162\n",
            "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 0.266317\n",
            "Train Epoch: 1 [5632/60000 (9%)]\tLoss: 0.270732\n",
            "Train Epoch: 1 [5664/60000 (9%)]\tLoss: 0.227113\n",
            "Train Epoch: 1 [5696/60000 (9%)]\tLoss: 0.301279\n",
            "Train Epoch: 1 [5728/60000 (10%)]\tLoss: 0.283752\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.204361\n",
            "Train Epoch: 1 [5792/60000 (10%)]\tLoss: 0.248115\n",
            "Train Epoch: 1 [5824/60000 (10%)]\tLoss: 0.390867\n",
            "Train Epoch: 1 [5856/60000 (10%)]\tLoss: 0.176756\n",
            "Train Epoch: 1 [5888/60000 (10%)]\tLoss: 0.266636\n",
            "Train Epoch: 1 [5920/60000 (10%)]\tLoss: 0.227589\n",
            "Train Epoch: 1 [5952/60000 (10%)]\tLoss: 0.327992\n",
            "Train Epoch: 1 [5984/60000 (10%)]\tLoss: 0.062711\n",
            "Train Epoch: 1 [6016/60000 (10%)]\tLoss: 0.166386\n",
            "Train Epoch: 1 [6048/60000 (10%)]\tLoss: 0.256370\n",
            "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 0.337474\n",
            "Train Epoch: 1 [6112/60000 (10%)]\tLoss: 0.180576\n",
            "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 0.178554\n",
            "Train Epoch: 1 [6176/60000 (10%)]\tLoss: 0.106470\n",
            "Train Epoch: 1 [6208/60000 (10%)]\tLoss: 0.152946\n",
            "Train Epoch: 1 [6240/60000 (10%)]\tLoss: 0.313891\n",
            "Train Epoch: 1 [6272/60000 (10%)]\tLoss: 0.281113\n",
            "Train Epoch: 1 [6304/60000 (11%)]\tLoss: 0.166584\n",
            "Train Epoch: 1 [6336/60000 (11%)]\tLoss: 0.224982\n",
            "Train Epoch: 1 [6368/60000 (11%)]\tLoss: 0.111407\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.339501\n",
            "Train Epoch: 1 [6432/60000 (11%)]\tLoss: 0.183044\n",
            "Train Epoch: 1 [6464/60000 (11%)]\tLoss: 0.463205\n",
            "Train Epoch: 1 [6496/60000 (11%)]\tLoss: 0.269877\n",
            "Train Epoch: 1 [6528/60000 (11%)]\tLoss: 0.148100\n",
            "Train Epoch: 1 [6560/60000 (11%)]\tLoss: 0.164145\n",
            "Train Epoch: 1 [6592/60000 (11%)]\tLoss: 0.141216\n",
            "Train Epoch: 1 [6624/60000 (11%)]\tLoss: 0.200233\n",
            "Train Epoch: 1 [6656/60000 (11%)]\tLoss: 0.368482\n",
            "Train Epoch: 1 [6688/60000 (11%)]\tLoss: 0.161159\n",
            "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.203873\n",
            "Train Epoch: 1 [6752/60000 (11%)]\tLoss: 0.130297\n",
            "Train Epoch: 1 [6784/60000 (11%)]\tLoss: 0.272591\n",
            "Train Epoch: 1 [6816/60000 (11%)]\tLoss: 0.355039\n",
            "Train Epoch: 1 [6848/60000 (11%)]\tLoss: 0.355490\n",
            "Train Epoch: 1 [6880/60000 (11%)]\tLoss: 0.357300\n",
            "Train Epoch: 1 [6912/60000 (12%)]\tLoss: 0.404194\n",
            "Train Epoch: 1 [6944/60000 (12%)]\tLoss: 0.233892\n",
            "Train Epoch: 1 [6976/60000 (12%)]\tLoss: 0.274640\n",
            "Train Epoch: 1 [7008/60000 (12%)]\tLoss: 0.617438\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.255292\n",
            "Train Epoch: 1 [7072/60000 (12%)]\tLoss: 0.146785\n",
            "Train Epoch: 1 [7104/60000 (12%)]\tLoss: 0.093621\n",
            "Train Epoch: 1 [7136/60000 (12%)]\tLoss: 0.479471\n",
            "Train Epoch: 1 [7168/60000 (12%)]\tLoss: 0.252440\n",
            "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.445542\n",
            "Train Epoch: 1 [7232/60000 (12%)]\tLoss: 0.347537\n",
            "Train Epoch: 1 [7264/60000 (12%)]\tLoss: 0.462893\n",
            "Train Epoch: 1 [7296/60000 (12%)]\tLoss: 0.218959\n",
            "Train Epoch: 1 [7328/60000 (12%)]\tLoss: 0.347153\n",
            "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 0.265068\n",
            "Train Epoch: 1 [7392/60000 (12%)]\tLoss: 0.078126\n",
            "Train Epoch: 1 [7424/60000 (12%)]\tLoss: 0.180374\n",
            "Train Epoch: 1 [7456/60000 (12%)]\tLoss: 0.128131\n",
            "Train Epoch: 1 [7488/60000 (12%)]\tLoss: 0.207211\n",
            "Train Epoch: 1 [7520/60000 (13%)]\tLoss: 0.350349\n",
            "Train Epoch: 1 [7552/60000 (13%)]\tLoss: 0.033433\n",
            "Train Epoch: 1 [7584/60000 (13%)]\tLoss: 0.371750\n",
            "Train Epoch: 1 [7616/60000 (13%)]\tLoss: 0.380901\n",
            "Train Epoch: 1 [7648/60000 (13%)]\tLoss: 0.184502\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.124537\n",
            "Train Epoch: 1 [7712/60000 (13%)]\tLoss: 0.266766\n",
            "Train Epoch: 1 [7744/60000 (13%)]\tLoss: 0.270123\n",
            "Train Epoch: 1 [7776/60000 (13%)]\tLoss: 0.220884\n",
            "Train Epoch: 1 [7808/60000 (13%)]\tLoss: 0.295184\n",
            "Train Epoch: 1 [7840/60000 (13%)]\tLoss: 0.342100\n",
            "Train Epoch: 1 [7872/60000 (13%)]\tLoss: 0.538945\n",
            "Train Epoch: 1 [7904/60000 (13%)]\tLoss: 0.239491\n",
            "Train Epoch: 1 [7936/60000 (13%)]\tLoss: 0.225269\n",
            "Train Epoch: 1 [7968/60000 (13%)]\tLoss: 0.262541\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.237529\n",
            "Train Epoch: 1 [8032/60000 (13%)]\tLoss: 0.082862\n",
            "Train Epoch: 1 [8064/60000 (13%)]\tLoss: 0.124537\n",
            "Train Epoch: 1 [8096/60000 (13%)]\tLoss: 0.660089\n",
            "Train Epoch: 1 [8128/60000 (14%)]\tLoss: 0.174689\n",
            "Train Epoch: 1 [8160/60000 (14%)]\tLoss: 0.188641\n",
            "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.730385\n",
            "Train Epoch: 1 [8224/60000 (14%)]\tLoss: 0.416522\n",
            "Train Epoch: 1 [8256/60000 (14%)]\tLoss: 0.190215\n",
            "Train Epoch: 1 [8288/60000 (14%)]\tLoss: 0.350450\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.172680\n",
            "Train Epoch: 1 [8352/60000 (14%)]\tLoss: 0.091713\n",
            "Train Epoch: 1 [8384/60000 (14%)]\tLoss: 0.158336\n",
            "Train Epoch: 1 [8416/60000 (14%)]\tLoss: 0.304552\n",
            "Train Epoch: 1 [8448/60000 (14%)]\tLoss: 0.425697\n",
            "Train Epoch: 1 [8480/60000 (14%)]\tLoss: 0.416276\n",
            "Train Epoch: 1 [8512/60000 (14%)]\tLoss: 0.168973\n",
            "Train Epoch: 1 [8544/60000 (14%)]\tLoss: 0.236503\n",
            "Train Epoch: 1 [8576/60000 (14%)]\tLoss: 0.155430\n",
            "Train Epoch: 1 [8608/60000 (14%)]\tLoss: 0.292731\n",
            "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.325230\n",
            "Train Epoch: 1 [8672/60000 (14%)]\tLoss: 0.767586\n",
            "Train Epoch: 1 [8704/60000 (15%)]\tLoss: 1.159916\n",
            "Train Epoch: 1 [8736/60000 (15%)]\tLoss: 0.204558\n",
            "Train Epoch: 1 [8768/60000 (15%)]\tLoss: 0.467226\n",
            "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 0.276878\n",
            "Train Epoch: 1 [8832/60000 (15%)]\tLoss: 0.399549\n",
            "Train Epoch: 1 [8864/60000 (15%)]\tLoss: 0.437577\n",
            "Train Epoch: 1 [8896/60000 (15%)]\tLoss: 0.634277\n",
            "Train Epoch: 1 [8928/60000 (15%)]\tLoss: 0.162449\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.363560\n",
            "Train Epoch: 1 [8992/60000 (15%)]\tLoss: 0.391560\n",
            "Train Epoch: 1 [9024/60000 (15%)]\tLoss: 0.093151\n",
            "Train Epoch: 1 [9056/60000 (15%)]\tLoss: 0.190281\n",
            "Train Epoch: 1 [9088/60000 (15%)]\tLoss: 0.595222\n",
            "Train Epoch: 1 [9120/60000 (15%)]\tLoss: 0.247170\n",
            "Train Epoch: 1 [9152/60000 (15%)]\tLoss: 0.229333\n",
            "Train Epoch: 1 [9184/60000 (15%)]\tLoss: 0.118512\n",
            "Train Epoch: 1 [9216/60000 (15%)]\tLoss: 0.272911\n",
            "Train Epoch: 1 [9248/60000 (15%)]\tLoss: 0.348376\n",
            "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.230150\n",
            "Train Epoch: 1 [9312/60000 (16%)]\tLoss: 0.220358\n",
            "Train Epoch: 1 [9344/60000 (16%)]\tLoss: 0.252251\n",
            "Train Epoch: 1 [9376/60000 (16%)]\tLoss: 0.412942\n",
            "Train Epoch: 1 [9408/60000 (16%)]\tLoss: 0.723198\n",
            "Train Epoch: 1 [9440/60000 (16%)]\tLoss: 0.278387\n",
            "Train Epoch: 1 [9472/60000 (16%)]\tLoss: 0.320549\n",
            "Train Epoch: 1 [9504/60000 (16%)]\tLoss: 0.213459\n",
            "Train Epoch: 1 [9536/60000 (16%)]\tLoss: 0.418346\n",
            "Train Epoch: 1 [9568/60000 (16%)]\tLoss: 0.342032\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.227386\n",
            "Train Epoch: 1 [9632/60000 (16%)]\tLoss: 0.311474\n",
            "Train Epoch: 1 [9664/60000 (16%)]\tLoss: 0.226039\n",
            "Train Epoch: 1 [9696/60000 (16%)]\tLoss: 0.065085\n",
            "Train Epoch: 1 [9728/60000 (16%)]\tLoss: 0.215018\n",
            "Train Epoch: 1 [9760/60000 (16%)]\tLoss: 0.620262\n",
            "Train Epoch: 1 [9792/60000 (16%)]\tLoss: 0.124479\n",
            "Train Epoch: 1 [9824/60000 (16%)]\tLoss: 0.042023\n",
            "Train Epoch: 1 [9856/60000 (16%)]\tLoss: 0.292337\n",
            "Train Epoch: 1 [9888/60000 (16%)]\tLoss: 0.047910\n",
            "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.129388\n",
            "Train Epoch: 1 [9952/60000 (17%)]\tLoss: 0.207223\n",
            "Train Epoch: 1 [9984/60000 (17%)]\tLoss: 0.067602\n",
            "Train Epoch: 1 [10016/60000 (17%)]\tLoss: 0.398032\n",
            "Train Epoch: 1 [10048/60000 (17%)]\tLoss: 0.137950\n",
            "Train Epoch: 1 [10080/60000 (17%)]\tLoss: 0.158196\n",
            "Train Epoch: 1 [10112/60000 (17%)]\tLoss: 0.225916\n",
            "Train Epoch: 1 [10144/60000 (17%)]\tLoss: 0.210225\n",
            "Train Epoch: 1 [10176/60000 (17%)]\tLoss: 0.342245\n",
            "Train Epoch: 1 [10208/60000 (17%)]\tLoss: 0.218246\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.352146\n",
            "Train Epoch: 1 [10272/60000 (17%)]\tLoss: 0.264135\n",
            "Train Epoch: 1 [10304/60000 (17%)]\tLoss: 0.168746\n",
            "Train Epoch: 1 [10336/60000 (17%)]\tLoss: 0.090744\n",
            "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.055139\n",
            "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.115031\n",
            "Train Epoch: 1 [10432/60000 (17%)]\tLoss: 0.297344\n",
            "Train Epoch: 1 [10464/60000 (17%)]\tLoss: 0.152709\n",
            "Train Epoch: 1 [10496/60000 (17%)]\tLoss: 0.235741\n",
            "Train Epoch: 1 [10528/60000 (18%)]\tLoss: 0.037426\n",
            "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.143193\n",
            "Train Epoch: 1 [10592/60000 (18%)]\tLoss: 0.123201\n",
            "Train Epoch: 1 [10624/60000 (18%)]\tLoss: 0.272354\n",
            "Train Epoch: 1 [10656/60000 (18%)]\tLoss: 0.135227\n",
            "Train Epoch: 1 [10688/60000 (18%)]\tLoss: 0.159807\n",
            "Train Epoch: 1 [10720/60000 (18%)]\tLoss: 0.357659\n",
            "Train Epoch: 1 [10752/60000 (18%)]\tLoss: 0.323039\n",
            "Train Epoch: 1 [10784/60000 (18%)]\tLoss: 0.144474\n",
            "Train Epoch: 1 [10816/60000 (18%)]\tLoss: 0.094626\n",
            "Train Epoch: 1 [10848/60000 (18%)]\tLoss: 0.333214\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.267165\n",
            "Train Epoch: 1 [10912/60000 (18%)]\tLoss: 0.172252\n",
            "Train Epoch: 1 [10944/60000 (18%)]\tLoss: 0.102742\n",
            "Train Epoch: 1 [10976/60000 (18%)]\tLoss: 0.469663\n",
            "Train Epoch: 1 [11008/60000 (18%)]\tLoss: 0.401226\n",
            "Train Epoch: 1 [11040/60000 (18%)]\tLoss: 0.080472\n",
            "Train Epoch: 1 [11072/60000 (18%)]\tLoss: 0.177116\n",
            "Train Epoch: 1 [11104/60000 (19%)]\tLoss: 0.246675\n",
            "Train Epoch: 1 [11136/60000 (19%)]\tLoss: 0.139182\n",
            "Train Epoch: 1 [11168/60000 (19%)]\tLoss: 0.088835\n",
            "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.380128\n",
            "Train Epoch: 1 [11232/60000 (19%)]\tLoss: 0.221650\n",
            "Train Epoch: 1 [11264/60000 (19%)]\tLoss: 0.119782\n",
            "Train Epoch: 1 [11296/60000 (19%)]\tLoss: 0.086615\n",
            "Train Epoch: 1 [11328/60000 (19%)]\tLoss: 0.063378\n",
            "Train Epoch: 1 [11360/60000 (19%)]\tLoss: 0.276510\n",
            "Train Epoch: 1 [11392/60000 (19%)]\tLoss: 0.094753\n",
            "Train Epoch: 1 [11424/60000 (19%)]\tLoss: 0.193692\n",
            "Train Epoch: 1 [11456/60000 (19%)]\tLoss: 0.226587\n",
            "Train Epoch: 1 [11488/60000 (19%)]\tLoss: 0.218928\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.292915\n",
            "Train Epoch: 1 [11552/60000 (19%)]\tLoss: 0.550891\n",
            "Train Epoch: 1 [11584/60000 (19%)]\tLoss: 0.310657\n",
            "Train Epoch: 1 [11616/60000 (19%)]\tLoss: 0.375818\n",
            "Train Epoch: 1 [11648/60000 (19%)]\tLoss: 0.199638\n",
            "Train Epoch: 1 [11680/60000 (19%)]\tLoss: 0.652271\n",
            "Train Epoch: 1 [11712/60000 (20%)]\tLoss: 0.219766\n",
            "Train Epoch: 1 [11744/60000 (20%)]\tLoss: 0.238631\n",
            "Train Epoch: 1 [11776/60000 (20%)]\tLoss: 0.161184\n",
            "Train Epoch: 1 [11808/60000 (20%)]\tLoss: 0.154450\n",
            "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.328044\n",
            "Train Epoch: 1 [11872/60000 (20%)]\tLoss: 0.186174\n",
            "Train Epoch: 1 [11904/60000 (20%)]\tLoss: 0.082504\n",
            "Train Epoch: 1 [11936/60000 (20%)]\tLoss: 0.212904\n",
            "Train Epoch: 1 [11968/60000 (20%)]\tLoss: 0.249960\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.109145\n",
            "Train Epoch: 1 [12032/60000 (20%)]\tLoss: 0.276021\n",
            "Train Epoch: 1 [12064/60000 (20%)]\tLoss: 0.354832\n",
            "Train Epoch: 1 [12096/60000 (20%)]\tLoss: 0.171343\n",
            "Train Epoch: 1 [12128/60000 (20%)]\tLoss: 0.096098\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.125666\n",
            "Train Epoch: 1 [12192/60000 (20%)]\tLoss: 0.332594\n",
            "Train Epoch: 1 [12224/60000 (20%)]\tLoss: 0.126161\n",
            "Train Epoch: 1 [12256/60000 (20%)]\tLoss: 0.357835\n",
            "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.322477\n",
            "Train Epoch: 1 [12320/60000 (21%)]\tLoss: 0.159267\n",
            "Train Epoch: 1 [12352/60000 (21%)]\tLoss: 0.345984\n",
            "Train Epoch: 1 [12384/60000 (21%)]\tLoss: 0.135787\n",
            "Train Epoch: 1 [12416/60000 (21%)]\tLoss: 0.223778\n",
            "Train Epoch: 1 [12448/60000 (21%)]\tLoss: 0.232698\n",
            "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.487227\n",
            "Train Epoch: 1 [12512/60000 (21%)]\tLoss: 0.222152\n",
            "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 0.307488\n",
            "Train Epoch: 1 [12576/60000 (21%)]\tLoss: 0.537406\n",
            "Train Epoch: 1 [12608/60000 (21%)]\tLoss: 0.496306\n",
            "Train Epoch: 1 [12640/60000 (21%)]\tLoss: 0.534033\n",
            "Train Epoch: 1 [12672/60000 (21%)]\tLoss: 0.508496\n",
            "Train Epoch: 1 [12704/60000 (21%)]\tLoss: 0.093367\n",
            "Train Epoch: 1 [12736/60000 (21%)]\tLoss: 0.170298\n",
            "Train Epoch: 1 [12768/60000 (21%)]\tLoss: 0.242379\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.101902\n",
            "Train Epoch: 1 [12832/60000 (21%)]\tLoss: 0.186542\n",
            "Train Epoch: 1 [12864/60000 (21%)]\tLoss: 0.108095\n",
            "Train Epoch: 1 [12896/60000 (21%)]\tLoss: 0.233599\n",
            "Train Epoch: 1 [12928/60000 (22%)]\tLoss: 0.352259\n",
            "Train Epoch: 1 [12960/60000 (22%)]\tLoss: 0.275322\n",
            "Train Epoch: 1 [12992/60000 (22%)]\tLoss: 0.315720\n",
            "Train Epoch: 1 [13024/60000 (22%)]\tLoss: 0.351971\n",
            "Train Epoch: 1 [13056/60000 (22%)]\tLoss: 0.367978\n",
            "Train Epoch: 1 [13088/60000 (22%)]\tLoss: 0.112564\n",
            "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.561237\n",
            "Train Epoch: 1 [13152/60000 (22%)]\tLoss: 0.084283\n",
            "Train Epoch: 1 [13184/60000 (22%)]\tLoss: 0.302921\n",
            "Train Epoch: 1 [13216/60000 (22%)]\tLoss: 0.060243\n",
            "Train Epoch: 1 [13248/60000 (22%)]\tLoss: 0.255792\n",
            "Train Epoch: 1 [13280/60000 (22%)]\tLoss: 0.143303\n",
            "Train Epoch: 1 [13312/60000 (22%)]\tLoss: 0.199522\n",
            "Train Epoch: 1 [13344/60000 (22%)]\tLoss: 0.157791\n",
            "Train Epoch: 1 [13376/60000 (22%)]\tLoss: 0.249888\n",
            "Train Epoch: 1 [13408/60000 (22%)]\tLoss: 0.090924\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.275014\n",
            "Train Epoch: 1 [13472/60000 (22%)]\tLoss: 0.067467\n",
            "Train Epoch: 1 [13504/60000 (23%)]\tLoss: 0.333097\n",
            "Train Epoch: 1 [13536/60000 (23%)]\tLoss: 0.147433\n",
            "Train Epoch: 1 [13568/60000 (23%)]\tLoss: 0.055552\n",
            "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 0.049154\n",
            "Train Epoch: 1 [13632/60000 (23%)]\tLoss: 0.249807\n",
            "Train Epoch: 1 [13664/60000 (23%)]\tLoss: 0.237072\n",
            "Train Epoch: 1 [13696/60000 (23%)]\tLoss: 0.297017\n",
            "Train Epoch: 1 [13728/60000 (23%)]\tLoss: 0.367951\n",
            "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.063546\n",
            "Train Epoch: 1 [13792/60000 (23%)]\tLoss: 0.077898\n",
            "Train Epoch: 1 [13824/60000 (23%)]\tLoss: 0.247521\n",
            "Train Epoch: 1 [13856/60000 (23%)]\tLoss: 0.129326\n",
            "Train Epoch: 1 [13888/60000 (23%)]\tLoss: 0.133047\n",
            "Train Epoch: 1 [13920/60000 (23%)]\tLoss: 0.148118\n",
            "Train Epoch: 1 [13952/60000 (23%)]\tLoss: 0.647883\n",
            "Train Epoch: 1 [13984/60000 (23%)]\tLoss: 0.303016\n",
            "Train Epoch: 1 [14016/60000 (23%)]\tLoss: 0.138517\n",
            "Train Epoch: 1 [14048/60000 (23%)]\tLoss: 0.326792\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.153267\n",
            "Train Epoch: 1 [14112/60000 (24%)]\tLoss: 0.225714\n",
            "Train Epoch: 1 [14144/60000 (24%)]\tLoss: 0.181539\n",
            "Train Epoch: 1 [14176/60000 (24%)]\tLoss: 0.208629\n",
            "Train Epoch: 1 [14208/60000 (24%)]\tLoss: 0.202658\n",
            "Train Epoch: 1 [14240/60000 (24%)]\tLoss: 0.146767\n",
            "Train Epoch: 1 [14272/60000 (24%)]\tLoss: 0.284636\n",
            "Train Epoch: 1 [14304/60000 (24%)]\tLoss: 0.333728\n",
            "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 0.409122\n",
            "Train Epoch: 1 [14368/60000 (24%)]\tLoss: 0.437043\n",
            "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.172748\n",
            "Train Epoch: 1 [14432/60000 (24%)]\tLoss: 0.114808\n",
            "Train Epoch: 1 [14464/60000 (24%)]\tLoss: 0.096733\n",
            "Train Epoch: 1 [14496/60000 (24%)]\tLoss: 0.188712\n",
            "Train Epoch: 1 [14528/60000 (24%)]\tLoss: 0.242053\n",
            "Train Epoch: 1 [14560/60000 (24%)]\tLoss: 0.265393\n",
            "Train Epoch: 1 [14592/60000 (24%)]\tLoss: 0.111743\n",
            "Train Epoch: 1 [14624/60000 (24%)]\tLoss: 0.271380\n",
            "Train Epoch: 1 [14656/60000 (24%)]\tLoss: 0.168754\n",
            "Train Epoch: 1 [14688/60000 (24%)]\tLoss: 0.350267\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.366570\n",
            "Train Epoch: 1 [14752/60000 (25%)]\tLoss: 0.391408\n",
            "Train Epoch: 1 [14784/60000 (25%)]\tLoss: 0.365967\n",
            "Train Epoch: 1 [14816/60000 (25%)]\tLoss: 0.283534\n",
            "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.226811\n",
            "Train Epoch: 1 [14880/60000 (25%)]\tLoss: 0.162060\n",
            "Train Epoch: 1 [14912/60000 (25%)]\tLoss: 0.065038\n",
            "Train Epoch: 1 [14944/60000 (25%)]\tLoss: 0.215614\n",
            "Train Epoch: 1 [14976/60000 (25%)]\tLoss: 0.204728\n",
            "Train Epoch: 1 [15008/60000 (25%)]\tLoss: 0.132293\n",
            "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 0.212249\n",
            "Train Epoch: 1 [15072/60000 (25%)]\tLoss: 0.099656\n",
            "Train Epoch: 1 [15104/60000 (25%)]\tLoss: 0.430050\n",
            "Train Epoch: 1 [15136/60000 (25%)]\tLoss: 0.201811\n",
            "Train Epoch: 1 [15168/60000 (25%)]\tLoss: 0.200388\n",
            "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 0.172220\n",
            "Train Epoch: 1 [15232/60000 (25%)]\tLoss: 0.170089\n",
            "Train Epoch: 1 [15264/60000 (25%)]\tLoss: 0.117210\n",
            "Train Epoch: 1 [15296/60000 (25%)]\tLoss: 0.058338\n",
            "Train Epoch: 1 [15328/60000 (26%)]\tLoss: 0.176717\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.154952\n",
            "Train Epoch: 1 [15392/60000 (26%)]\tLoss: 0.088786\n",
            "Train Epoch: 1 [15424/60000 (26%)]\tLoss: 0.313690\n",
            "Train Epoch: 1 [15456/60000 (26%)]\tLoss: 0.086331\n",
            "Train Epoch: 1 [15488/60000 (26%)]\tLoss: 0.261574\n",
            "Train Epoch: 1 [15520/60000 (26%)]\tLoss: 0.169099\n",
            "Train Epoch: 1 [15552/60000 (26%)]\tLoss: 0.166892\n",
            "Train Epoch: 1 [15584/60000 (26%)]\tLoss: 0.223559\n",
            "Train Epoch: 1 [15616/60000 (26%)]\tLoss: 0.116168\n",
            "Train Epoch: 1 [15648/60000 (26%)]\tLoss: 0.107725\n",
            "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.035501\n",
            "Train Epoch: 1 [15712/60000 (26%)]\tLoss: 0.326603\n",
            "Train Epoch: 1 [15744/60000 (26%)]\tLoss: 0.243898\n",
            "Train Epoch: 1 [15776/60000 (26%)]\tLoss: 0.290280\n",
            "Train Epoch: 1 [15808/60000 (26%)]\tLoss: 0.176005\n",
            "Train Epoch: 1 [15840/60000 (26%)]\tLoss: 0.253447\n",
            "Train Epoch: 1 [15872/60000 (26%)]\tLoss: 0.251727\n",
            "Train Epoch: 1 [15904/60000 (27%)]\tLoss: 0.171296\n",
            "Train Epoch: 1 [15936/60000 (27%)]\tLoss: 0.624753\n",
            "Train Epoch: 1 [15968/60000 (27%)]\tLoss: 0.299141\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.233214\n",
            "Train Epoch: 1 [16032/60000 (27%)]\tLoss: 0.335391\n",
            "Train Epoch: 1 [16064/60000 (27%)]\tLoss: 0.078298\n",
            "Train Epoch: 1 [16096/60000 (27%)]\tLoss: 0.101398\n",
            "Train Epoch: 1 [16128/60000 (27%)]\tLoss: 0.106125\n",
            "Train Epoch: 1 [16160/60000 (27%)]\tLoss: 0.050615\n",
            "Train Epoch: 1 [16192/60000 (27%)]\tLoss: 0.213708\n",
            "Train Epoch: 1 [16224/60000 (27%)]\tLoss: 0.028891\n",
            "Train Epoch: 1 [16256/60000 (27%)]\tLoss: 0.148997\n",
            "Train Epoch: 1 [16288/60000 (27%)]\tLoss: 0.129283\n",
            "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.044776\n",
            "Train Epoch: 1 [16352/60000 (27%)]\tLoss: 0.285616\n",
            "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.061368\n",
            "Train Epoch: 1 [16416/60000 (27%)]\tLoss: 0.143289\n",
            "Train Epoch: 1 [16448/60000 (27%)]\tLoss: 0.097105\n",
            "Train Epoch: 1 [16480/60000 (27%)]\tLoss: 0.209771\n",
            "Train Epoch: 1 [16512/60000 (28%)]\tLoss: 0.054369\n",
            "Train Epoch: 1 [16544/60000 (28%)]\tLoss: 0.458153\n",
            "Train Epoch: 1 [16576/60000 (28%)]\tLoss: 0.053305\n",
            "Train Epoch: 1 [16608/60000 (28%)]\tLoss: 0.110385\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.176761\n",
            "Train Epoch: 1 [16672/60000 (28%)]\tLoss: 0.276638\n",
            "Train Epoch: 1 [16704/60000 (28%)]\tLoss: 0.213581\n",
            "Train Epoch: 1 [16736/60000 (28%)]\tLoss: 0.281434\n",
            "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.098360\n",
            "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 0.048767\n",
            "Train Epoch: 1 [16832/60000 (28%)]\tLoss: 0.071823\n",
            "Train Epoch: 1 [16864/60000 (28%)]\tLoss: 0.148075\n",
            "Train Epoch: 1 [16896/60000 (28%)]\tLoss: 0.116883\n",
            "Train Epoch: 1 [16928/60000 (28%)]\tLoss: 0.108587\n",
            "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.169562\n",
            "Train Epoch: 1 [16992/60000 (28%)]\tLoss: 0.222465\n",
            "Train Epoch: 1 [17024/60000 (28%)]\tLoss: 0.235530\n",
            "Train Epoch: 1 [17056/60000 (28%)]\tLoss: 0.142106\n",
            "Train Epoch: 1 [17088/60000 (28%)]\tLoss: 0.272451\n",
            "Train Epoch: 1 [17120/60000 (29%)]\tLoss: 0.093490\n",
            "Train Epoch: 1 [17152/60000 (29%)]\tLoss: 0.059486\n",
            "Train Epoch: 1 [17184/60000 (29%)]\tLoss: 0.178179\n",
            "Train Epoch: 1 [17216/60000 (29%)]\tLoss: 0.456018\n",
            "Train Epoch: 1 [17248/60000 (29%)]\tLoss: 0.033516\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.134956\n",
            "Train Epoch: 1 [17312/60000 (29%)]\tLoss: 0.022047\n",
            "Train Epoch: 1 [17344/60000 (29%)]\tLoss: 0.105679\n",
            "Train Epoch: 1 [17376/60000 (29%)]\tLoss: 0.118992\n",
            "Train Epoch: 1 [17408/60000 (29%)]\tLoss: 0.097542\n",
            "Train Epoch: 1 [17440/60000 (29%)]\tLoss: 0.119944\n",
            "Train Epoch: 1 [17472/60000 (29%)]\tLoss: 0.389435\n",
            "Train Epoch: 1 [17504/60000 (29%)]\tLoss: 0.062553\n",
            "Train Epoch: 1 [17536/60000 (29%)]\tLoss: 0.328317\n",
            "Train Epoch: 1 [17568/60000 (29%)]\tLoss: 0.210910\n",
            "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.085511\n",
            "Train Epoch: 1 [17632/60000 (29%)]\tLoss: 0.107787\n",
            "Train Epoch: 1 [17664/60000 (29%)]\tLoss: 0.042649\n",
            "Train Epoch: 1 [17696/60000 (29%)]\tLoss: 0.255493\n",
            "Train Epoch: 1 [17728/60000 (30%)]\tLoss: 0.188754\n",
            "Train Epoch: 1 [17760/60000 (30%)]\tLoss: 0.236853\n",
            "Train Epoch: 1 [17792/60000 (30%)]\tLoss: 0.354939\n",
            "Train Epoch: 1 [17824/60000 (30%)]\tLoss: 0.122020\n",
            "Train Epoch: 1 [17856/60000 (30%)]\tLoss: 0.077123\n",
            "Train Epoch: 1 [17888/60000 (30%)]\tLoss: 0.141140\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.140622\n",
            "Train Epoch: 1 [17952/60000 (30%)]\tLoss: 0.158650\n",
            "Train Epoch: 1 [17984/60000 (30%)]\tLoss: 0.312704\n",
            "Train Epoch: 1 [18016/60000 (30%)]\tLoss: 0.087106\n",
            "Train Epoch: 1 [18048/60000 (30%)]\tLoss: 0.105744\n",
            "Train Epoch: 1 [18080/60000 (30%)]\tLoss: 0.197377\n",
            "Train Epoch: 1 [18112/60000 (30%)]\tLoss: 0.116132\n",
            "Train Epoch: 1 [18144/60000 (30%)]\tLoss: 0.203940\n",
            "Train Epoch: 1 [18176/60000 (30%)]\tLoss: 0.056598\n",
            "Train Epoch: 1 [18208/60000 (30%)]\tLoss: 0.110845\n",
            "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.124503\n",
            "Train Epoch: 1 [18272/60000 (30%)]\tLoss: 0.093619\n",
            "Train Epoch: 1 [18304/60000 (31%)]\tLoss: 0.143241\n",
            "Train Epoch: 1 [18336/60000 (31%)]\tLoss: 0.190322\n",
            "Train Epoch: 1 [18368/60000 (31%)]\tLoss: 0.070837\n",
            "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 0.107675\n",
            "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 0.076118\n",
            "Train Epoch: 1 [18464/60000 (31%)]\tLoss: 0.172697\n",
            "Train Epoch: 1 [18496/60000 (31%)]\tLoss: 0.146710\n",
            "Train Epoch: 1 [18528/60000 (31%)]\tLoss: 0.048491\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.085770\n",
            "Train Epoch: 1 [18592/60000 (31%)]\tLoss: 0.319311\n",
            "Train Epoch: 1 [18624/60000 (31%)]\tLoss: 0.121390\n",
            "Train Epoch: 1 [18656/60000 (31%)]\tLoss: 0.089079\n",
            "Train Epoch: 1 [18688/60000 (31%)]\tLoss: 0.145847\n",
            "Train Epoch: 1 [18720/60000 (31%)]\tLoss: 0.205160\n",
            "Train Epoch: 1 [18752/60000 (31%)]\tLoss: 0.063122\n",
            "Train Epoch: 1 [18784/60000 (31%)]\tLoss: 0.064209\n",
            "Train Epoch: 1 [18816/60000 (31%)]\tLoss: 0.202535\n",
            "Train Epoch: 1 [18848/60000 (31%)]\tLoss: 0.027305\n",
            "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.170227\n",
            "Train Epoch: 1 [18912/60000 (32%)]\tLoss: 0.060474\n",
            "Train Epoch: 1 [18944/60000 (32%)]\tLoss: 0.035858\n",
            "Train Epoch: 1 [18976/60000 (32%)]\tLoss: 0.125996\n",
            "Train Epoch: 1 [19008/60000 (32%)]\tLoss: 0.254781\n",
            "Train Epoch: 1 [19040/60000 (32%)]\tLoss: 0.108699\n",
            "Train Epoch: 1 [19072/60000 (32%)]\tLoss: 0.245488\n",
            "Train Epoch: 1 [19104/60000 (32%)]\tLoss: 0.208699\n",
            "Train Epoch: 1 [19136/60000 (32%)]\tLoss: 0.155634\n",
            "Train Epoch: 1 [19168/60000 (32%)]\tLoss: 0.133557\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.098503\n",
            "Train Epoch: 1 [19232/60000 (32%)]\tLoss: 0.271837\n",
            "Train Epoch: 1 [19264/60000 (32%)]\tLoss: 0.120729\n",
            "Train Epoch: 1 [19296/60000 (32%)]\tLoss: 0.061709\n",
            "Train Epoch: 1 [19328/60000 (32%)]\tLoss: 0.277090\n",
            "Train Epoch: 1 [19360/60000 (32%)]\tLoss: 0.154988\n",
            "Train Epoch: 1 [19392/60000 (32%)]\tLoss: 0.081721\n",
            "Train Epoch: 1 [19424/60000 (32%)]\tLoss: 0.086793\n",
            "Train Epoch: 1 [19456/60000 (32%)]\tLoss: 0.063771\n",
            "Train Epoch: 1 [19488/60000 (32%)]\tLoss: 0.175256\n",
            "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.126011\n",
            "Train Epoch: 1 [19552/60000 (33%)]\tLoss: 0.134832\n",
            "Train Epoch: 1 [19584/60000 (33%)]\tLoss: 0.090014\n",
            "Train Epoch: 1 [19616/60000 (33%)]\tLoss: 0.094524\n",
            "Train Epoch: 1 [19648/60000 (33%)]\tLoss: 0.089343\n",
            "Train Epoch: 1 [19680/60000 (33%)]\tLoss: 0.055245\n",
            "Train Epoch: 1 [19712/60000 (33%)]\tLoss: 0.020720\n",
            "Train Epoch: 1 [19744/60000 (33%)]\tLoss: 0.041857\n",
            "Train Epoch: 1 [19776/60000 (33%)]\tLoss: 0.153631\n",
            "Train Epoch: 1 [19808/60000 (33%)]\tLoss: 0.359940\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.083461\n",
            "Train Epoch: 1 [19872/60000 (33%)]\tLoss: 0.045042\n",
            "Train Epoch: 1 [19904/60000 (33%)]\tLoss: 0.076835\n",
            "Train Epoch: 1 [19936/60000 (33%)]\tLoss: 0.143304\n",
            "Train Epoch: 1 [19968/60000 (33%)]\tLoss: 0.109873\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.144139\n",
            "Train Epoch: 1 [20032/60000 (33%)]\tLoss: 0.203281\n",
            "Train Epoch: 1 [20064/60000 (33%)]\tLoss: 0.263127\n",
            "Train Epoch: 1 [20096/60000 (33%)]\tLoss: 0.144343\n",
            "Train Epoch: 1 [20128/60000 (34%)]\tLoss: 0.037446\n",
            "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.506745\n",
            "Train Epoch: 1 [20192/60000 (34%)]\tLoss: 0.094692\n",
            "Train Epoch: 1 [20224/60000 (34%)]\tLoss: 0.105110\n",
            "Train Epoch: 1 [20256/60000 (34%)]\tLoss: 0.078279\n",
            "Train Epoch: 1 [20288/60000 (34%)]\tLoss: 0.063976\n",
            "Train Epoch: 1 [20320/60000 (34%)]\tLoss: 0.230538\n",
            "Train Epoch: 1 [20352/60000 (34%)]\tLoss: 0.076569\n",
            "Train Epoch: 1 [20384/60000 (34%)]\tLoss: 0.018313\n",
            "Train Epoch: 1 [20416/60000 (34%)]\tLoss: 0.057828\n",
            "Train Epoch: 1 [20448/60000 (34%)]\tLoss: 0.058837\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.030582\n",
            "Train Epoch: 1 [20512/60000 (34%)]\tLoss: 0.063023\n",
            "Train Epoch: 1 [20544/60000 (34%)]\tLoss: 0.180702\n",
            "Train Epoch: 1 [20576/60000 (34%)]\tLoss: 0.086698\n",
            "Train Epoch: 1 [20608/60000 (34%)]\tLoss: 0.060628\n",
            "Train Epoch: 1 [20640/60000 (34%)]\tLoss: 0.191635\n",
            "Train Epoch: 1 [20672/60000 (34%)]\tLoss: 0.312157\n",
            "Train Epoch: 1 [20704/60000 (35%)]\tLoss: 0.354619\n",
            "Train Epoch: 1 [20736/60000 (35%)]\tLoss: 0.197531\n",
            "Train Epoch: 1 [20768/60000 (35%)]\tLoss: 0.356882\n",
            "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.109600\n",
            "Train Epoch: 1 [20832/60000 (35%)]\tLoss: 0.148066\n",
            "Train Epoch: 1 [20864/60000 (35%)]\tLoss: 0.191906\n",
            "Train Epoch: 1 [20896/60000 (35%)]\tLoss: 0.451707\n",
            "Train Epoch: 1 [20928/60000 (35%)]\tLoss: 0.209928\n",
            "Train Epoch: 1 [20960/60000 (35%)]\tLoss: 0.265636\n",
            "Train Epoch: 1 [20992/60000 (35%)]\tLoss: 0.144983\n",
            "Train Epoch: 1 [21024/60000 (35%)]\tLoss: 0.232679\n",
            "Train Epoch: 1 [21056/60000 (35%)]\tLoss: 0.225571\n",
            "Train Epoch: 1 [21088/60000 (35%)]\tLoss: 0.123386\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.239558\n",
            "Train Epoch: 1 [21152/60000 (35%)]\tLoss: 0.127453\n",
            "Train Epoch: 1 [21184/60000 (35%)]\tLoss: 0.157104\n",
            "Train Epoch: 1 [21216/60000 (35%)]\tLoss: 0.077802\n",
            "Train Epoch: 1 [21248/60000 (35%)]\tLoss: 0.028290\n",
            "Train Epoch: 1 [21280/60000 (35%)]\tLoss: 0.223132\n",
            "Train Epoch: 1 [21312/60000 (36%)]\tLoss: 0.064955\n",
            "Train Epoch: 1 [21344/60000 (36%)]\tLoss: 0.217216\n",
            "Train Epoch: 1 [21376/60000 (36%)]\tLoss: 0.169876\n",
            "Train Epoch: 1 [21408/60000 (36%)]\tLoss: 0.180811\n",
            "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.109105\n",
            "Train Epoch: 1 [21472/60000 (36%)]\tLoss: 0.031898\n",
            "Train Epoch: 1 [21504/60000 (36%)]\tLoss: 0.108705\n",
            "Train Epoch: 1 [21536/60000 (36%)]\tLoss: 0.042634\n",
            "Train Epoch: 1 [21568/60000 (36%)]\tLoss: 0.191170\n",
            "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 0.347094\n",
            "Train Epoch: 1 [21632/60000 (36%)]\tLoss: 0.071759\n",
            "Train Epoch: 1 [21664/60000 (36%)]\tLoss: 0.059404\n",
            "Train Epoch: 1 [21696/60000 (36%)]\tLoss: 0.182739\n",
            "Train Epoch: 1 [21728/60000 (36%)]\tLoss: 0.060528\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.027022\n",
            "Train Epoch: 1 [21792/60000 (36%)]\tLoss: 0.041620\n",
            "Train Epoch: 1 [21824/60000 (36%)]\tLoss: 0.097758\n",
            "Train Epoch: 1 [21856/60000 (36%)]\tLoss: 0.043836\n",
            "Train Epoch: 1 [21888/60000 (36%)]\tLoss: 0.144014\n",
            "Train Epoch: 1 [21920/60000 (37%)]\tLoss: 0.135481\n",
            "Train Epoch: 1 [21952/60000 (37%)]\tLoss: 0.257120\n",
            "Train Epoch: 1 [21984/60000 (37%)]\tLoss: 0.126141\n",
            "Train Epoch: 1 [22016/60000 (37%)]\tLoss: 0.026544\n",
            "Train Epoch: 1 [22048/60000 (37%)]\tLoss: 0.059268\n",
            "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.036897\n",
            "Train Epoch: 1 [22112/60000 (37%)]\tLoss: 0.247037\n",
            "Train Epoch: 1 [22144/60000 (37%)]\tLoss: 0.143968\n",
            "Train Epoch: 1 [22176/60000 (37%)]\tLoss: 0.302048\n",
            "Train Epoch: 1 [22208/60000 (37%)]\tLoss: 0.355477\n",
            "Train Epoch: 1 [22240/60000 (37%)]\tLoss: 0.056258\n",
            "Train Epoch: 1 [22272/60000 (37%)]\tLoss: 0.122841\n",
            "Train Epoch: 1 [22304/60000 (37%)]\tLoss: 0.121987\n",
            "Train Epoch: 1 [22336/60000 (37%)]\tLoss: 0.020264\n",
            "Train Epoch: 1 [22368/60000 (37%)]\tLoss: 0.019522\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.079458\n",
            "Train Epoch: 1 [22432/60000 (37%)]\tLoss: 0.130237\n",
            "Train Epoch: 1 [22464/60000 (37%)]\tLoss: 0.206606\n",
            "Train Epoch: 1 [22496/60000 (37%)]\tLoss: 0.374861\n",
            "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 0.224802\n",
            "Train Epoch: 1 [22560/60000 (38%)]\tLoss: 0.369713\n",
            "Train Epoch: 1 [22592/60000 (38%)]\tLoss: 0.249817\n",
            "Train Epoch: 1 [22624/60000 (38%)]\tLoss: 0.167559\n",
            "Train Epoch: 1 [22656/60000 (38%)]\tLoss: 0.104334\n",
            "Train Epoch: 1 [22688/60000 (38%)]\tLoss: 0.111266\n",
            "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.145810\n",
            "Train Epoch: 1 [22752/60000 (38%)]\tLoss: 0.200643\n",
            "Train Epoch: 1 [22784/60000 (38%)]\tLoss: 0.079879\n",
            "Train Epoch: 1 [22816/60000 (38%)]\tLoss: 0.062870\n",
            "Train Epoch: 1 [22848/60000 (38%)]\tLoss: 0.034048\n",
            "Train Epoch: 1 [22880/60000 (38%)]\tLoss: 0.085240\n",
            "Train Epoch: 1 [22912/60000 (38%)]\tLoss: 0.069941\n",
            "Train Epoch: 1 [22944/60000 (38%)]\tLoss: 0.017527\n",
            "Train Epoch: 1 [22976/60000 (38%)]\tLoss: 0.065152\n",
            "Train Epoch: 1 [23008/60000 (38%)]\tLoss: 0.132339\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.116211\n",
            "Train Epoch: 1 [23072/60000 (38%)]\tLoss: 0.544808\n",
            "Train Epoch: 1 [23104/60000 (39%)]\tLoss: 0.137609\n",
            "Train Epoch: 1 [23136/60000 (39%)]\tLoss: 0.140066\n",
            "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.083482\n",
            "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 0.171123\n",
            "Train Epoch: 1 [23232/60000 (39%)]\tLoss: 0.025744\n",
            "Train Epoch: 1 [23264/60000 (39%)]\tLoss: 0.049968\n",
            "Train Epoch: 1 [23296/60000 (39%)]\tLoss: 0.030655\n",
            "Train Epoch: 1 [23328/60000 (39%)]\tLoss: 0.136533\n",
            "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.122804\n",
            "Train Epoch: 1 [23392/60000 (39%)]\tLoss: 0.063555\n",
            "Train Epoch: 1 [23424/60000 (39%)]\tLoss: 0.070304\n",
            "Train Epoch: 1 [23456/60000 (39%)]\tLoss: 0.228114\n",
            "Train Epoch: 1 [23488/60000 (39%)]\tLoss: 0.074162\n",
            "Train Epoch: 1 [23520/60000 (39%)]\tLoss: 0.092632\n",
            "Train Epoch: 1 [23552/60000 (39%)]\tLoss: 0.087262\n",
            "Train Epoch: 1 [23584/60000 (39%)]\tLoss: 0.177690\n",
            "Train Epoch: 1 [23616/60000 (39%)]\tLoss: 0.174821\n",
            "Train Epoch: 1 [23648/60000 (39%)]\tLoss: 0.074680\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.136744\n",
            "Train Epoch: 1 [23712/60000 (40%)]\tLoss: 0.344576\n",
            "Train Epoch: 1 [23744/60000 (40%)]\tLoss: 0.048306\n",
            "Train Epoch: 1 [23776/60000 (40%)]\tLoss: 0.117096\n",
            "Train Epoch: 1 [23808/60000 (40%)]\tLoss: 0.211367\n",
            "Train Epoch: 1 [23840/60000 (40%)]\tLoss: 0.170630\n",
            "Train Epoch: 1 [23872/60000 (40%)]\tLoss: 0.152246\n",
            "Train Epoch: 1 [23904/60000 (40%)]\tLoss: 0.215109\n",
            "Train Epoch: 1 [23936/60000 (40%)]\tLoss: 0.284009\n",
            "Train Epoch: 1 [23968/60000 (40%)]\tLoss: 0.069869\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.065456\n",
            "Train Epoch: 1 [24032/60000 (40%)]\tLoss: 0.215659\n",
            "Train Epoch: 1 [24064/60000 (40%)]\tLoss: 0.074107\n",
            "Train Epoch: 1 [24096/60000 (40%)]\tLoss: 0.146679\n",
            "Train Epoch: 1 [24128/60000 (40%)]\tLoss: 0.100412\n",
            "Train Epoch: 1 [24160/60000 (40%)]\tLoss: 0.122554\n",
            "Train Epoch: 1 [24192/60000 (40%)]\tLoss: 0.157618\n",
            "Train Epoch: 1 [24224/60000 (40%)]\tLoss: 0.062025\n",
            "Train Epoch: 1 [24256/60000 (40%)]\tLoss: 0.226778\n",
            "Train Epoch: 1 [24288/60000 (40%)]\tLoss: 0.071394\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.046135\n",
            "Train Epoch: 1 [24352/60000 (41%)]\tLoss: 0.037911\n",
            "Train Epoch: 1 [24384/60000 (41%)]\tLoss: 0.057338\n",
            "Train Epoch: 1 [24416/60000 (41%)]\tLoss: 0.090333\n",
            "Train Epoch: 1 [24448/60000 (41%)]\tLoss: 0.070802\n",
            "Train Epoch: 1 [24480/60000 (41%)]\tLoss: 0.052919\n",
            "Train Epoch: 1 [24512/60000 (41%)]\tLoss: 0.205652\n",
            "Train Epoch: 1 [24544/60000 (41%)]\tLoss: 0.149634\n",
            "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.182661\n",
            "Train Epoch: 1 [24608/60000 (41%)]\tLoss: 0.186487\n",
            "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.178725\n",
            "Train Epoch: 1 [24672/60000 (41%)]\tLoss: 0.179421\n",
            "Train Epoch: 1 [24704/60000 (41%)]\tLoss: 0.083518\n",
            "Train Epoch: 1 [24736/60000 (41%)]\tLoss: 0.164140\n",
            "Train Epoch: 1 [24768/60000 (41%)]\tLoss: 0.482398\n",
            "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 0.087285\n",
            "Train Epoch: 1 [24832/60000 (41%)]\tLoss: 0.126750\n",
            "Train Epoch: 1 [24864/60000 (41%)]\tLoss: 0.078080\n",
            "Train Epoch: 1 [24896/60000 (41%)]\tLoss: 0.174724\n",
            "Train Epoch: 1 [24928/60000 (42%)]\tLoss: 0.207621\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.193698\n",
            "Train Epoch: 1 [24992/60000 (42%)]\tLoss: 0.033608\n",
            "Train Epoch: 1 [25024/60000 (42%)]\tLoss: 0.027718\n",
            "Train Epoch: 1 [25056/60000 (42%)]\tLoss: 0.067507\n",
            "Train Epoch: 1 [25088/60000 (42%)]\tLoss: 0.260640\n",
            "Train Epoch: 1 [25120/60000 (42%)]\tLoss: 0.062503\n",
            "Train Epoch: 1 [25152/60000 (42%)]\tLoss: 0.147991\n",
            "Train Epoch: 1 [25184/60000 (42%)]\tLoss: 0.119766\n",
            "Train Epoch: 1 [25216/60000 (42%)]\tLoss: 0.122169\n",
            "Train Epoch: 1 [25248/60000 (42%)]\tLoss: 0.054731\n",
            "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.222131\n",
            "Train Epoch: 1 [25312/60000 (42%)]\tLoss: 0.077516\n",
            "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 0.031891\n",
            "Train Epoch: 1 [25376/60000 (42%)]\tLoss: 0.078153\n",
            "Train Epoch: 1 [25408/60000 (42%)]\tLoss: 0.057859\n",
            "Train Epoch: 1 [25440/60000 (42%)]\tLoss: 0.030872\n",
            "Train Epoch: 1 [25472/60000 (42%)]\tLoss: 0.330681\n",
            "Train Epoch: 1 [25504/60000 (43%)]\tLoss: 0.028718\n",
            "Train Epoch: 1 [25536/60000 (43%)]\tLoss: 0.398300\n",
            "Train Epoch: 1 [25568/60000 (43%)]\tLoss: 0.041775\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.089107\n",
            "Train Epoch: 1 [25632/60000 (43%)]\tLoss: 0.070133\n",
            "Train Epoch: 1 [25664/60000 (43%)]\tLoss: 0.216395\n",
            "Train Epoch: 1 [25696/60000 (43%)]\tLoss: 0.184222\n",
            "Train Epoch: 1 [25728/60000 (43%)]\tLoss: 0.104421\n",
            "Train Epoch: 1 [25760/60000 (43%)]\tLoss: 0.075327\n",
            "Train Epoch: 1 [25792/60000 (43%)]\tLoss: 0.420698\n",
            "Train Epoch: 1 [25824/60000 (43%)]\tLoss: 0.240216\n",
            "Train Epoch: 1 [25856/60000 (43%)]\tLoss: 0.089582\n",
            "Train Epoch: 1 [25888/60000 (43%)]\tLoss: 0.113895\n",
            "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.171410\n",
            "Train Epoch: 1 [25952/60000 (43%)]\tLoss: 0.136274\n",
            "Train Epoch: 1 [25984/60000 (43%)]\tLoss: 0.059461\n",
            "Train Epoch: 1 [26016/60000 (43%)]\tLoss: 0.068770\n",
            "Train Epoch: 1 [26048/60000 (43%)]\tLoss: 0.196607\n",
            "Train Epoch: 1 [26080/60000 (43%)]\tLoss: 0.044747\n",
            "Train Epoch: 1 [26112/60000 (44%)]\tLoss: 0.103562\n",
            "Train Epoch: 1 [26144/60000 (44%)]\tLoss: 0.054711\n",
            "Train Epoch: 1 [26176/60000 (44%)]\tLoss: 0.050522\n",
            "Train Epoch: 1 [26208/60000 (44%)]\tLoss: 0.093140\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.096705\n",
            "Train Epoch: 1 [26272/60000 (44%)]\tLoss: 0.056630\n",
            "Train Epoch: 1 [26304/60000 (44%)]\tLoss: 0.010747\n",
            "Train Epoch: 1 [26336/60000 (44%)]\tLoss: 0.212005\n",
            "Train Epoch: 1 [26368/60000 (44%)]\tLoss: 0.281270\n",
            "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 0.239382\n",
            "Train Epoch: 1 [26432/60000 (44%)]\tLoss: 0.192692\n",
            "Train Epoch: 1 [26464/60000 (44%)]\tLoss: 0.115252\n",
            "Train Epoch: 1 [26496/60000 (44%)]\tLoss: 0.284908\n",
            "Train Epoch: 1 [26528/60000 (44%)]\tLoss: 0.047289\n",
            "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.264294\n",
            "Train Epoch: 1 [26592/60000 (44%)]\tLoss: 0.049708\n",
            "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 0.724334\n",
            "Train Epoch: 1 [26656/60000 (44%)]\tLoss: 0.068446\n",
            "Train Epoch: 1 [26688/60000 (44%)]\tLoss: 0.120515\n",
            "Train Epoch: 1 [26720/60000 (45%)]\tLoss: 0.385278\n",
            "Train Epoch: 1 [26752/60000 (45%)]\tLoss: 0.173256\n",
            "Train Epoch: 1 [26784/60000 (45%)]\tLoss: 0.149877\n",
            "Train Epoch: 1 [26816/60000 (45%)]\tLoss: 0.057707\n",
            "Train Epoch: 1 [26848/60000 (45%)]\tLoss: 0.289911\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.547738\n",
            "Train Epoch: 1 [26912/60000 (45%)]\tLoss: 0.047814\n",
            "Train Epoch: 1 [26944/60000 (45%)]\tLoss: 0.035807\n",
            "Train Epoch: 1 [26976/60000 (45%)]\tLoss: 0.022533\n",
            "Train Epoch: 1 [27008/60000 (45%)]\tLoss: 0.069786\n",
            "Train Epoch: 1 [27040/60000 (45%)]\tLoss: 0.030391\n",
            "Train Epoch: 1 [27072/60000 (45%)]\tLoss: 0.081656\n",
            "Train Epoch: 1 [27104/60000 (45%)]\tLoss: 0.074755\n",
            "Train Epoch: 1 [27136/60000 (45%)]\tLoss: 0.390838\n",
            "Train Epoch: 1 [27168/60000 (45%)]\tLoss: 0.273736\n",
            "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.182416\n",
            "Train Epoch: 1 [27232/60000 (45%)]\tLoss: 0.267037\n",
            "Train Epoch: 1 [27264/60000 (45%)]\tLoss: 0.039133\n",
            "Train Epoch: 1 [27296/60000 (45%)]\tLoss: 0.082897\n",
            "Train Epoch: 1 [27328/60000 (46%)]\tLoss: 0.078317\n",
            "Train Epoch: 1 [27360/60000 (46%)]\tLoss: 0.041960\n",
            "Train Epoch: 1 [27392/60000 (46%)]\tLoss: 0.032518\n",
            "Train Epoch: 1 [27424/60000 (46%)]\tLoss: 0.106103\n",
            "Train Epoch: 1 [27456/60000 (46%)]\tLoss: 0.095335\n",
            "Train Epoch: 1 [27488/60000 (46%)]\tLoss: 0.232148\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.162469\n",
            "Train Epoch: 1 [27552/60000 (46%)]\tLoss: 0.031104\n",
            "Train Epoch: 1 [27584/60000 (46%)]\tLoss: 0.234066\n",
            "Train Epoch: 1 [27616/60000 (46%)]\tLoss: 0.091011\n",
            "Train Epoch: 1 [27648/60000 (46%)]\tLoss: 0.101375\n",
            "Train Epoch: 1 [27680/60000 (46%)]\tLoss: 0.121831\n",
            "Train Epoch: 1 [27712/60000 (46%)]\tLoss: 0.087290\n",
            "Train Epoch: 1 [27744/60000 (46%)]\tLoss: 0.019049\n",
            "Train Epoch: 1 [27776/60000 (46%)]\tLoss: 0.103735\n",
            "Train Epoch: 1 [27808/60000 (46%)]\tLoss: 0.109261\n",
            "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.077183\n",
            "Train Epoch: 1 [27872/60000 (46%)]\tLoss: 0.057610\n",
            "Train Epoch: 1 [27904/60000 (47%)]\tLoss: 0.027959\n",
            "Train Epoch: 1 [27936/60000 (47%)]\tLoss: 0.079396\n",
            "Train Epoch: 1 [27968/60000 (47%)]\tLoss: 0.112132\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.073106\n",
            "Train Epoch: 1 [28032/60000 (47%)]\tLoss: 0.016930\n",
            "Train Epoch: 1 [28064/60000 (47%)]\tLoss: 0.051325\n",
            "Train Epoch: 1 [28096/60000 (47%)]\tLoss: 0.079109\n",
            "Train Epoch: 1 [28128/60000 (47%)]\tLoss: 0.189061\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.127742\n",
            "Train Epoch: 1 [28192/60000 (47%)]\tLoss: 0.091503\n",
            "Train Epoch: 1 [28224/60000 (47%)]\tLoss: 0.038227\n",
            "Train Epoch: 1 [28256/60000 (47%)]\tLoss: 0.052917\n",
            "Train Epoch: 1 [28288/60000 (47%)]\tLoss: 0.056470\n",
            "Train Epoch: 1 [28320/60000 (47%)]\tLoss: 0.020181\n",
            "Train Epoch: 1 [28352/60000 (47%)]\tLoss: 0.442076\n",
            "Train Epoch: 1 [28384/60000 (47%)]\tLoss: 0.204898\n",
            "Train Epoch: 1 [28416/60000 (47%)]\tLoss: 0.122032\n",
            "Train Epoch: 1 [28448/60000 (47%)]\tLoss: 0.025089\n",
            "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.113230\n",
            "Train Epoch: 1 [28512/60000 (48%)]\tLoss: 0.055505\n",
            "Train Epoch: 1 [28544/60000 (48%)]\tLoss: 0.173967\n",
            "Train Epoch: 1 [28576/60000 (48%)]\tLoss: 0.068179\n",
            "Train Epoch: 1 [28608/60000 (48%)]\tLoss: 0.287325\n",
            "Train Epoch: 1 [28640/60000 (48%)]\tLoss: 0.511011\n",
            "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.052135\n",
            "Train Epoch: 1 [28704/60000 (48%)]\tLoss: 0.166342\n",
            "Train Epoch: 1 [28736/60000 (48%)]\tLoss: 0.031753\n",
            "Train Epoch: 1 [28768/60000 (48%)]\tLoss: 0.132261\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.107334\n",
            "Train Epoch: 1 [28832/60000 (48%)]\tLoss: 0.036025\n",
            "Train Epoch: 1 [28864/60000 (48%)]\tLoss: 0.016954\n",
            "Train Epoch: 1 [28896/60000 (48%)]\tLoss: 0.037448\n",
            "Train Epoch: 1 [28928/60000 (48%)]\tLoss: 0.203254\n",
            "Train Epoch: 1 [28960/60000 (48%)]\tLoss: 0.137227\n",
            "Train Epoch: 1 [28992/60000 (48%)]\tLoss: 0.065180\n",
            "Train Epoch: 1 [29024/60000 (48%)]\tLoss: 0.104910\n",
            "Train Epoch: 1 [29056/60000 (48%)]\tLoss: 0.146258\n",
            "Train Epoch: 1 [29088/60000 (48%)]\tLoss: 0.059067\n",
            "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.089519\n",
            "Train Epoch: 1 [29152/60000 (49%)]\tLoss: 0.296120\n",
            "Train Epoch: 1 [29184/60000 (49%)]\tLoss: 0.175120\n",
            "Train Epoch: 1 [29216/60000 (49%)]\tLoss: 0.153510\n",
            "Train Epoch: 1 [29248/60000 (49%)]\tLoss: 0.052219\n",
            "Train Epoch: 1 [29280/60000 (49%)]\tLoss: 0.329282\n",
            "Train Epoch: 1 [29312/60000 (49%)]\tLoss: 0.165073\n",
            "Train Epoch: 1 [29344/60000 (49%)]\tLoss: 0.055214\n",
            "Train Epoch: 1 [29376/60000 (49%)]\tLoss: 0.070024\n",
            "Train Epoch: 1 [29408/60000 (49%)]\tLoss: 0.281660\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.122256\n",
            "Train Epoch: 1 [29472/60000 (49%)]\tLoss: 0.049973\n",
            "Train Epoch: 1 [29504/60000 (49%)]\tLoss: 0.172049\n",
            "Train Epoch: 1 [29536/60000 (49%)]\tLoss: 0.029002\n",
            "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.246203\n",
            "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 0.026438\n",
            "Train Epoch: 1 [29632/60000 (49%)]\tLoss: 0.064222\n",
            "Train Epoch: 1 [29664/60000 (49%)]\tLoss: 0.161223\n",
            "Train Epoch: 1 [29696/60000 (49%)]\tLoss: 0.147220\n",
            "Train Epoch: 1 [29728/60000 (50%)]\tLoss: 0.210018\n",
            "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.085829\n",
            "Train Epoch: 1 [29792/60000 (50%)]\tLoss: 0.053953\n",
            "Train Epoch: 1 [29824/60000 (50%)]\tLoss: 0.246445\n",
            "Train Epoch: 1 [29856/60000 (50%)]\tLoss: 0.198927\n",
            "Train Epoch: 1 [29888/60000 (50%)]\tLoss: 0.110488\n",
            "Train Epoch: 1 [29920/60000 (50%)]\tLoss: 0.236761\n",
            "Train Epoch: 1 [29952/60000 (50%)]\tLoss: 0.174974\n",
            "Train Epoch: 1 [29984/60000 (50%)]\tLoss: 0.103827\n",
            "Train Epoch: 1 [30016/60000 (50%)]\tLoss: 0.090691\n",
            "Train Epoch: 1 [30048/60000 (50%)]\tLoss: 0.227390\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.085520\n",
            "Train Epoch: 1 [30112/60000 (50%)]\tLoss: 0.213440\n",
            "Train Epoch: 1 [30144/60000 (50%)]\tLoss: 0.135924\n",
            "Train Epoch: 1 [30176/60000 (50%)]\tLoss: 0.072374\n",
            "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.128248\n",
            "Train Epoch: 1 [30240/60000 (50%)]\tLoss: 0.092187\n",
            "Train Epoch: 1 [30272/60000 (50%)]\tLoss: 0.047468\n",
            "Train Epoch: 1 [30304/60000 (51%)]\tLoss: 0.118105\n",
            "Train Epoch: 1 [30336/60000 (51%)]\tLoss: 0.088411\n",
            "Train Epoch: 1 [30368/60000 (51%)]\tLoss: 0.030195\n",
            "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.080152\n",
            "Train Epoch: 1 [30432/60000 (51%)]\tLoss: 0.071283\n",
            "Train Epoch: 1 [30464/60000 (51%)]\tLoss: 0.226400\n",
            "Train Epoch: 1 [30496/60000 (51%)]\tLoss: 0.145070\n",
            "Train Epoch: 1 [30528/60000 (51%)]\tLoss: 0.077413\n",
            "Train Epoch: 1 [30560/60000 (51%)]\tLoss: 0.075635\n",
            "Train Epoch: 1 [30592/60000 (51%)]\tLoss: 0.211982\n",
            "Train Epoch: 1 [30624/60000 (51%)]\tLoss: 0.078866\n",
            "Train Epoch: 1 [30656/60000 (51%)]\tLoss: 0.104109\n",
            "Train Epoch: 1 [30688/60000 (51%)]\tLoss: 0.153416\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.061675\n",
            "Train Epoch: 1 [30752/60000 (51%)]\tLoss: 0.044743\n",
            "Train Epoch: 1 [30784/60000 (51%)]\tLoss: 0.202348\n",
            "Train Epoch: 1 [30816/60000 (51%)]\tLoss: 0.151044\n",
            "Train Epoch: 1 [30848/60000 (51%)]\tLoss: 0.090706\n",
            "Train Epoch: 1 [30880/60000 (51%)]\tLoss: 0.176995\n",
            "Train Epoch: 1 [30912/60000 (52%)]\tLoss: 0.039967\n",
            "Train Epoch: 1 [30944/60000 (52%)]\tLoss: 0.192776\n",
            "Train Epoch: 1 [30976/60000 (52%)]\tLoss: 0.069524\n",
            "Train Epoch: 1 [31008/60000 (52%)]\tLoss: 0.063827\n",
            "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.071729\n",
            "Train Epoch: 1 [31072/60000 (52%)]\tLoss: 0.090655\n",
            "Train Epoch: 1 [31104/60000 (52%)]\tLoss: 0.448736\n",
            "Train Epoch: 1 [31136/60000 (52%)]\tLoss: 0.030393\n",
            "Train Epoch: 1 [31168/60000 (52%)]\tLoss: 0.390876\n",
            "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 0.075876\n",
            "Train Epoch: 1 [31232/60000 (52%)]\tLoss: 0.182914\n",
            "Train Epoch: 1 [31264/60000 (52%)]\tLoss: 0.183053\n",
            "Train Epoch: 1 [31296/60000 (52%)]\tLoss: 0.511960\n",
            "Train Epoch: 1 [31328/60000 (52%)]\tLoss: 0.118795\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.119716\n",
            "Train Epoch: 1 [31392/60000 (52%)]\tLoss: 0.248225\n",
            "Train Epoch: 1 [31424/60000 (52%)]\tLoss: 0.137924\n",
            "Train Epoch: 1 [31456/60000 (52%)]\tLoss: 0.095165\n",
            "Train Epoch: 1 [31488/60000 (52%)]\tLoss: 0.056098\n",
            "Train Epoch: 1 [31520/60000 (53%)]\tLoss: 0.084947\n",
            "Train Epoch: 1 [31552/60000 (53%)]\tLoss: 0.139309\n",
            "Train Epoch: 1 [31584/60000 (53%)]\tLoss: 0.166776\n",
            "Train Epoch: 1 [31616/60000 (53%)]\tLoss: 0.019755\n",
            "Train Epoch: 1 [31648/60000 (53%)]\tLoss: 0.356096\n",
            "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.297594\n",
            "Train Epoch: 1 [31712/60000 (53%)]\tLoss: 0.418335\n",
            "Train Epoch: 1 [31744/60000 (53%)]\tLoss: 0.200178\n",
            "Train Epoch: 1 [31776/60000 (53%)]\tLoss: 0.198754\n",
            "Train Epoch: 1 [31808/60000 (53%)]\tLoss: 0.024780\n",
            "Train Epoch: 1 [31840/60000 (53%)]\tLoss: 0.314031\n",
            "Train Epoch: 1 [31872/60000 (53%)]\tLoss: 0.044152\n",
            "Train Epoch: 1 [31904/60000 (53%)]\tLoss: 0.051837\n",
            "Train Epoch: 1 [31936/60000 (53%)]\tLoss: 0.357926\n",
            "Train Epoch: 1 [31968/60000 (53%)]\tLoss: 0.030295\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.260495\n",
            "Train Epoch: 1 [32032/60000 (53%)]\tLoss: 0.136356\n",
            "Train Epoch: 1 [32064/60000 (53%)]\tLoss: 0.088723\n",
            "Train Epoch: 1 [32096/60000 (53%)]\tLoss: 0.226012\n",
            "Train Epoch: 1 [32128/60000 (54%)]\tLoss: 0.114908\n",
            "Train Epoch: 1 [32160/60000 (54%)]\tLoss: 0.218310\n",
            "Train Epoch: 1 [32192/60000 (54%)]\tLoss: 0.071500\n",
            "Train Epoch: 1 [32224/60000 (54%)]\tLoss: 0.107691\n",
            "Train Epoch: 1 [32256/60000 (54%)]\tLoss: 0.181152\n",
            "Train Epoch: 1 [32288/60000 (54%)]\tLoss: 0.111058\n",
            "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.444589\n",
            "Train Epoch: 1 [32352/60000 (54%)]\tLoss: 0.095458\n",
            "Train Epoch: 1 [32384/60000 (54%)]\tLoss: 0.139803\n",
            "Train Epoch: 1 [32416/60000 (54%)]\tLoss: 0.340794\n",
            "Train Epoch: 1 [32448/60000 (54%)]\tLoss: 0.204562\n",
            "Train Epoch: 1 [32480/60000 (54%)]\tLoss: 0.108514\n",
            "Train Epoch: 1 [32512/60000 (54%)]\tLoss: 0.024795\n",
            "Train Epoch: 1 [32544/60000 (54%)]\tLoss: 0.130296\n",
            "Train Epoch: 1 [32576/60000 (54%)]\tLoss: 0.013662\n",
            "Train Epoch: 1 [32608/60000 (54%)]\tLoss: 0.040290\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.293730\n",
            "Train Epoch: 1 [32672/60000 (54%)]\tLoss: 0.086869\n",
            "Train Epoch: 1 [32704/60000 (55%)]\tLoss: 0.031760\n",
            "Train Epoch: 1 [32736/60000 (55%)]\tLoss: 0.075526\n",
            "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.167450\n",
            "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 0.103065\n",
            "Train Epoch: 1 [32832/60000 (55%)]\tLoss: 0.049243\n",
            "Train Epoch: 1 [32864/60000 (55%)]\tLoss: 0.264786\n",
            "Train Epoch: 1 [32896/60000 (55%)]\tLoss: 0.134268\n",
            "Train Epoch: 1 [32928/60000 (55%)]\tLoss: 0.052038\n",
            "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.024539\n",
            "Train Epoch: 1 [32992/60000 (55%)]\tLoss: 0.079191\n",
            "Train Epoch: 1 [33024/60000 (55%)]\tLoss: 0.078655\n",
            "Train Epoch: 1 [33056/60000 (55%)]\tLoss: 0.233050\n",
            "Train Epoch: 1 [33088/60000 (55%)]\tLoss: 0.047272\n",
            "Train Epoch: 1 [33120/60000 (55%)]\tLoss: 0.204683\n",
            "Train Epoch: 1 [33152/60000 (55%)]\tLoss: 0.051852\n",
            "Train Epoch: 1 [33184/60000 (55%)]\tLoss: 0.082402\n",
            "Train Epoch: 1 [33216/60000 (55%)]\tLoss: 0.212390\n",
            "Train Epoch: 1 [33248/60000 (55%)]\tLoss: 0.044894\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.147473\n",
            "Train Epoch: 1 [33312/60000 (56%)]\tLoss: 0.150095\n",
            "Train Epoch: 1 [33344/60000 (56%)]\tLoss: 0.076377\n",
            "Train Epoch: 1 [33376/60000 (56%)]\tLoss: 0.123574\n",
            "Train Epoch: 1 [33408/60000 (56%)]\tLoss: 0.100500\n",
            "Train Epoch: 1 [33440/60000 (56%)]\tLoss: 0.084394\n",
            "Train Epoch: 1 [33472/60000 (56%)]\tLoss: 0.074887\n",
            "Train Epoch: 1 [33504/60000 (56%)]\tLoss: 0.210450\n",
            "Train Epoch: 1 [33536/60000 (56%)]\tLoss: 0.092379\n",
            "Train Epoch: 1 [33568/60000 (56%)]\tLoss: 0.060928\n",
            "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.121374\n",
            "Train Epoch: 1 [33632/60000 (56%)]\tLoss: 0.035779\n",
            "Train Epoch: 1 [33664/60000 (56%)]\tLoss: 0.135560\n",
            "Train Epoch: 1 [33696/60000 (56%)]\tLoss: 0.017665\n",
            "Train Epoch: 1 [33728/60000 (56%)]\tLoss: 0.107979\n",
            "Train Epoch: 1 [33760/60000 (56%)]\tLoss: 0.369413\n",
            "Train Epoch: 1 [33792/60000 (56%)]\tLoss: 0.055017\n",
            "Train Epoch: 1 [33824/60000 (56%)]\tLoss: 0.044807\n",
            "Train Epoch: 1 [33856/60000 (56%)]\tLoss: 0.013273\n",
            "Train Epoch: 1 [33888/60000 (56%)]\tLoss: 0.061497\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.010560\n",
            "Train Epoch: 1 [33952/60000 (57%)]\tLoss: 0.081087\n",
            "Train Epoch: 1 [33984/60000 (57%)]\tLoss: 0.155090\n",
            "Train Epoch: 1 [34016/60000 (57%)]\tLoss: 0.042790\n",
            "Train Epoch: 1 [34048/60000 (57%)]\tLoss: 0.342389\n",
            "Train Epoch: 1 [34080/60000 (57%)]\tLoss: 0.074286\n",
            "Train Epoch: 1 [34112/60000 (57%)]\tLoss: 0.131304\n",
            "Train Epoch: 1 [34144/60000 (57%)]\tLoss: 0.020896\n",
            "Train Epoch: 1 [34176/60000 (57%)]\tLoss: 0.089355\n",
            "Train Epoch: 1 [34208/60000 (57%)]\tLoss: 0.073643\n",
            "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.058379\n",
            "Train Epoch: 1 [34272/60000 (57%)]\tLoss: 0.009639\n",
            "Train Epoch: 1 [34304/60000 (57%)]\tLoss: 0.107165\n",
            "Train Epoch: 1 [34336/60000 (57%)]\tLoss: 0.045225\n",
            "Train Epoch: 1 [34368/60000 (57%)]\tLoss: 0.038928\n",
            "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 0.325691\n",
            "Train Epoch: 1 [34432/60000 (57%)]\tLoss: 0.084289\n",
            "Train Epoch: 1 [34464/60000 (57%)]\tLoss: 0.118345\n",
            "Train Epoch: 1 [34496/60000 (57%)]\tLoss: 0.198290\n",
            "Train Epoch: 1 [34528/60000 (58%)]\tLoss: 0.074480\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.148745\n",
            "Train Epoch: 1 [34592/60000 (58%)]\tLoss: 0.053673\n",
            "Train Epoch: 1 [34624/60000 (58%)]\tLoss: 0.050344\n",
            "Train Epoch: 1 [34656/60000 (58%)]\tLoss: 0.392366\n",
            "Train Epoch: 1 [34688/60000 (58%)]\tLoss: 0.257965\n",
            "Train Epoch: 1 [34720/60000 (58%)]\tLoss: 0.229200\n",
            "Train Epoch: 1 [34752/60000 (58%)]\tLoss: 0.044902\n",
            "Train Epoch: 1 [34784/60000 (58%)]\tLoss: 0.165199\n",
            "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 0.183925\n",
            "Train Epoch: 1 [34848/60000 (58%)]\tLoss: 0.044691\n",
            "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.132486\n",
            "Train Epoch: 1 [34912/60000 (58%)]\tLoss: 0.194562\n",
            "Train Epoch: 1 [34944/60000 (58%)]\tLoss: 0.055065\n",
            "Train Epoch: 1 [34976/60000 (58%)]\tLoss: 0.025653\n",
            "Train Epoch: 1 [35008/60000 (58%)]\tLoss: 0.069220\n",
            "Train Epoch: 1 [35040/60000 (58%)]\tLoss: 0.172511\n",
            "Train Epoch: 1 [35072/60000 (58%)]\tLoss: 0.048486\n",
            "Train Epoch: 1 [35104/60000 (59%)]\tLoss: 0.026878\n",
            "Train Epoch: 1 [35136/60000 (59%)]\tLoss: 0.228995\n",
            "Train Epoch: 1 [35168/60000 (59%)]\tLoss: 0.045243\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.069119\n",
            "Train Epoch: 1 [35232/60000 (59%)]\tLoss: 0.341376\n",
            "Train Epoch: 1 [35264/60000 (59%)]\tLoss: 0.023787\n",
            "Train Epoch: 1 [35296/60000 (59%)]\tLoss: 0.073544\n",
            "Train Epoch: 1 [35328/60000 (59%)]\tLoss: 0.040064\n",
            "Train Epoch: 1 [35360/60000 (59%)]\tLoss: 0.057627\n",
            "Train Epoch: 1 [35392/60000 (59%)]\tLoss: 0.179904\n",
            "Train Epoch: 1 [35424/60000 (59%)]\tLoss: 0.078493\n",
            "Train Epoch: 1 [35456/60000 (59%)]\tLoss: 0.400131\n",
            "Train Epoch: 1 [35488/60000 (59%)]\tLoss: 0.066594\n",
            "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.034290\n",
            "Train Epoch: 1 [35552/60000 (59%)]\tLoss: 0.082364\n",
            "Train Epoch: 1 [35584/60000 (59%)]\tLoss: 0.041606\n",
            "Train Epoch: 1 [35616/60000 (59%)]\tLoss: 0.387231\n",
            "Train Epoch: 1 [35648/60000 (59%)]\tLoss: 0.033931\n",
            "Train Epoch: 1 [35680/60000 (59%)]\tLoss: 0.181545\n",
            "Train Epoch: 1 [35712/60000 (60%)]\tLoss: 0.059464\n",
            "Train Epoch: 1 [35744/60000 (60%)]\tLoss: 0.064892\n",
            "Train Epoch: 1 [35776/60000 (60%)]\tLoss: 0.025350\n",
            "Train Epoch: 1 [35808/60000 (60%)]\tLoss: 0.010793\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.144822\n",
            "Train Epoch: 1 [35872/60000 (60%)]\tLoss: 0.043132\n",
            "Train Epoch: 1 [35904/60000 (60%)]\tLoss: 0.073954\n",
            "Train Epoch: 1 [35936/60000 (60%)]\tLoss: 0.179463\n",
            "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.137892\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.266471\n",
            "Train Epoch: 1 [36032/60000 (60%)]\tLoss: 0.368130\n",
            "Train Epoch: 1 [36064/60000 (60%)]\tLoss: 0.089495\n",
            "Train Epoch: 1 [36096/60000 (60%)]\tLoss: 0.302299\n",
            "Train Epoch: 1 [36128/60000 (60%)]\tLoss: 0.035373\n",
            "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.109638\n",
            "Train Epoch: 1 [36192/60000 (60%)]\tLoss: 0.097181\n",
            "Train Epoch: 1 [36224/60000 (60%)]\tLoss: 0.106358\n",
            "Train Epoch: 1 [36256/60000 (60%)]\tLoss: 0.085053\n",
            "Train Epoch: 1 [36288/60000 (60%)]\tLoss: 0.035961\n",
            "Train Epoch: 1 [36320/60000 (61%)]\tLoss: 0.051540\n",
            "Train Epoch: 1 [36352/60000 (61%)]\tLoss: 0.064501\n",
            "Train Epoch: 1 [36384/60000 (61%)]\tLoss: 0.374016\n",
            "Train Epoch: 1 [36416/60000 (61%)]\tLoss: 0.348807\n",
            "Train Epoch: 1 [36448/60000 (61%)]\tLoss: 0.095921\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.051659\n",
            "Train Epoch: 1 [36512/60000 (61%)]\tLoss: 0.055334\n",
            "Train Epoch: 1 [36544/60000 (61%)]\tLoss: 0.083397\n",
            "Train Epoch: 1 [36576/60000 (61%)]\tLoss: 0.156145\n",
            "Train Epoch: 1 [36608/60000 (61%)]\tLoss: 0.073012\n",
            "Train Epoch: 1 [36640/60000 (61%)]\tLoss: 0.073553\n",
            "Train Epoch: 1 [36672/60000 (61%)]\tLoss: 0.023188\n",
            "Train Epoch: 1 [36704/60000 (61%)]\tLoss: 0.203123\n",
            "Train Epoch: 1 [36736/60000 (61%)]\tLoss: 0.369542\n",
            "Train Epoch: 1 [36768/60000 (61%)]\tLoss: 0.077160\n",
            "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.219626\n",
            "Train Epoch: 1 [36832/60000 (61%)]\tLoss: 0.209903\n",
            "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.135282\n",
            "Train Epoch: 1 [36896/60000 (61%)]\tLoss: 0.064150\n",
            "Train Epoch: 1 [36928/60000 (62%)]\tLoss: 0.102734\n",
            "Train Epoch: 1 [36960/60000 (62%)]\tLoss: 0.046111\n",
            "Train Epoch: 1 [36992/60000 (62%)]\tLoss: 0.043178\n",
            "Train Epoch: 1 [37024/60000 (62%)]\tLoss: 0.531386\n",
            "Train Epoch: 1 [37056/60000 (62%)]\tLoss: 0.245552\n",
            "Train Epoch: 1 [37088/60000 (62%)]\tLoss: 0.152210\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.217050\n",
            "Train Epoch: 1 [37152/60000 (62%)]\tLoss: 0.165295\n",
            "Train Epoch: 1 [37184/60000 (62%)]\tLoss: 0.118830\n",
            "Train Epoch: 1 [37216/60000 (62%)]\tLoss: 0.065513\n",
            "Train Epoch: 1 [37248/60000 (62%)]\tLoss: 0.182926\n",
            "Train Epoch: 1 [37280/60000 (62%)]\tLoss: 0.248744\n",
            "Train Epoch: 1 [37312/60000 (62%)]\tLoss: 0.072578\n",
            "Train Epoch: 1 [37344/60000 (62%)]\tLoss: 0.461926\n",
            "Train Epoch: 1 [37376/60000 (62%)]\tLoss: 0.314359\n",
            "Train Epoch: 1 [37408/60000 (62%)]\tLoss: 0.228783\n",
            "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.436705\n",
            "Train Epoch: 1 [37472/60000 (62%)]\tLoss: 0.103704\n",
            "Train Epoch: 1 [37504/60000 (63%)]\tLoss: 0.107836\n",
            "Train Epoch: 1 [37536/60000 (63%)]\tLoss: 0.284960\n",
            "Train Epoch: 1 [37568/60000 (63%)]\tLoss: 0.096714\n",
            "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 0.084122\n",
            "Train Epoch: 1 [37632/60000 (63%)]\tLoss: 0.101695\n",
            "Train Epoch: 1 [37664/60000 (63%)]\tLoss: 0.075448\n",
            "Train Epoch: 1 [37696/60000 (63%)]\tLoss: 0.204414\n",
            "Train Epoch: 1 [37728/60000 (63%)]\tLoss: 0.263961\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.070672\n",
            "Train Epoch: 1 [37792/60000 (63%)]\tLoss: 0.283074\n",
            "Train Epoch: 1 [37824/60000 (63%)]\tLoss: 0.289271\n",
            "Train Epoch: 1 [37856/60000 (63%)]\tLoss: 0.125145\n",
            "Train Epoch: 1 [37888/60000 (63%)]\tLoss: 0.071089\n",
            "Train Epoch: 1 [37920/60000 (63%)]\tLoss: 0.165697\n",
            "Train Epoch: 1 [37952/60000 (63%)]\tLoss: 0.091910\n",
            "Train Epoch: 1 [37984/60000 (63%)]\tLoss: 0.121675\n",
            "Train Epoch: 1 [38016/60000 (63%)]\tLoss: 0.090703\n",
            "Train Epoch: 1 [38048/60000 (63%)]\tLoss: 0.047547\n",
            "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.051940\n",
            "Train Epoch: 1 [38112/60000 (64%)]\tLoss: 0.067025\n",
            "Train Epoch: 1 [38144/60000 (64%)]\tLoss: 0.033948\n",
            "Train Epoch: 1 [38176/60000 (64%)]\tLoss: 0.087357\n",
            "Train Epoch: 1 [38208/60000 (64%)]\tLoss: 0.096871\n",
            "Train Epoch: 1 [38240/60000 (64%)]\tLoss: 0.195437\n",
            "Train Epoch: 1 [38272/60000 (64%)]\tLoss: 0.031116\n",
            "Train Epoch: 1 [38304/60000 (64%)]\tLoss: 0.135981\n",
            "Train Epoch: 1 [38336/60000 (64%)]\tLoss: 0.040335\n",
            "Train Epoch: 1 [38368/60000 (64%)]\tLoss: 0.191479\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.192917\n",
            "Train Epoch: 1 [38432/60000 (64%)]\tLoss: 0.030293\n",
            "Train Epoch: 1 [38464/60000 (64%)]\tLoss: 0.035135\n",
            "Train Epoch: 1 [38496/60000 (64%)]\tLoss: 0.304151\n",
            "Train Epoch: 1 [38528/60000 (64%)]\tLoss: 0.047221\n",
            "Train Epoch: 1 [38560/60000 (64%)]\tLoss: 0.147020\n",
            "Train Epoch: 1 [38592/60000 (64%)]\tLoss: 0.135983\n",
            "Train Epoch: 1 [38624/60000 (64%)]\tLoss: 0.079065\n",
            "Train Epoch: 1 [38656/60000 (64%)]\tLoss: 0.159384\n",
            "Train Epoch: 1 [38688/60000 (64%)]\tLoss: 0.173190\n",
            "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.015797\n",
            "Train Epoch: 1 [38752/60000 (65%)]\tLoss: 0.126709\n",
            "Train Epoch: 1 [38784/60000 (65%)]\tLoss: 0.077746\n",
            "Train Epoch: 1 [38816/60000 (65%)]\tLoss: 0.013896\n",
            "Train Epoch: 1 [38848/60000 (65%)]\tLoss: 0.015408\n",
            "Train Epoch: 1 [38880/60000 (65%)]\tLoss: 0.096326\n",
            "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 0.078109\n",
            "Train Epoch: 1 [38944/60000 (65%)]\tLoss: 0.042718\n",
            "Train Epoch: 1 [38976/60000 (65%)]\tLoss: 0.036240\n",
            "Train Epoch: 1 [39008/60000 (65%)]\tLoss: 0.130753\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.048336\n",
            "Train Epoch: 1 [39072/60000 (65%)]\tLoss: 0.025488\n",
            "Train Epoch: 1 [39104/60000 (65%)]\tLoss: 0.115246\n",
            "Train Epoch: 1 [39136/60000 (65%)]\tLoss: 0.047298\n",
            "Train Epoch: 1 [39168/60000 (65%)]\tLoss: 0.220120\n",
            "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 0.033096\n",
            "Train Epoch: 1 [39232/60000 (65%)]\tLoss: 0.085620\n",
            "Train Epoch: 1 [39264/60000 (65%)]\tLoss: 0.129799\n",
            "Train Epoch: 1 [39296/60000 (65%)]\tLoss: 0.340522\n",
            "Train Epoch: 1 [39328/60000 (66%)]\tLoss: 0.191977\n",
            "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.278170\n",
            "Train Epoch: 1 [39392/60000 (66%)]\tLoss: 0.207171\n",
            "Train Epoch: 1 [39424/60000 (66%)]\tLoss: 0.131864\n",
            "Train Epoch: 1 [39456/60000 (66%)]\tLoss: 0.130100\n",
            "Train Epoch: 1 [39488/60000 (66%)]\tLoss: 0.031601\n",
            "Train Epoch: 1 [39520/60000 (66%)]\tLoss: 0.069468\n",
            "Train Epoch: 1 [39552/60000 (66%)]\tLoss: 0.036918\n",
            "Train Epoch: 1 [39584/60000 (66%)]\tLoss: 0.106973\n",
            "Train Epoch: 1 [39616/60000 (66%)]\tLoss: 0.207373\n",
            "Train Epoch: 1 [39648/60000 (66%)]\tLoss: 0.221120\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.086048\n",
            "Train Epoch: 1 [39712/60000 (66%)]\tLoss: 0.029366\n",
            "Train Epoch: 1 [39744/60000 (66%)]\tLoss: 0.206055\n",
            "Train Epoch: 1 [39776/60000 (66%)]\tLoss: 0.111912\n",
            "Train Epoch: 1 [39808/60000 (66%)]\tLoss: 0.122165\n",
            "Train Epoch: 1 [39840/60000 (66%)]\tLoss: 0.164541\n",
            "Train Epoch: 1 [39872/60000 (66%)]\tLoss: 0.084220\n",
            "Train Epoch: 1 [39904/60000 (67%)]\tLoss: 0.101966\n",
            "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 0.259319\n",
            "Train Epoch: 1 [39968/60000 (67%)]\tLoss: 0.050986\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.063962\n",
            "Train Epoch: 1 [40032/60000 (67%)]\tLoss: 0.098488\n",
            "Train Epoch: 1 [40064/60000 (67%)]\tLoss: 0.079191\n",
            "Train Epoch: 1 [40096/60000 (67%)]\tLoss: 0.098754\n",
            "Train Epoch: 1 [40128/60000 (67%)]\tLoss: 0.244008\n",
            "Train Epoch: 1 [40160/60000 (67%)]\tLoss: 0.115495\n",
            "Train Epoch: 1 [40192/60000 (67%)]\tLoss: 0.033622\n",
            "Train Epoch: 1 [40224/60000 (67%)]\tLoss: 0.062209\n",
            "Train Epoch: 1 [40256/60000 (67%)]\tLoss: 0.129503\n",
            "Train Epoch: 1 [40288/60000 (67%)]\tLoss: 0.165844\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.012909\n",
            "Train Epoch: 1 [40352/60000 (67%)]\tLoss: 0.228335\n",
            "Train Epoch: 1 [40384/60000 (67%)]\tLoss: 0.070983\n",
            "Train Epoch: 1 [40416/60000 (67%)]\tLoss: 0.023692\n",
            "Train Epoch: 1 [40448/60000 (67%)]\tLoss: 0.062124\n",
            "Train Epoch: 1 [40480/60000 (67%)]\tLoss: 0.082155\n",
            "Train Epoch: 1 [40512/60000 (68%)]\tLoss: 0.035362\n",
            "Train Epoch: 1 [40544/60000 (68%)]\tLoss: 0.202392\n",
            "Train Epoch: 1 [40576/60000 (68%)]\tLoss: 0.052515\n",
            "Train Epoch: 1 [40608/60000 (68%)]\tLoss: 0.134428\n",
            "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.237093\n",
            "Train Epoch: 1 [40672/60000 (68%)]\tLoss: 0.013957\n",
            "Train Epoch: 1 [40704/60000 (68%)]\tLoss: 0.109516\n",
            "Train Epoch: 1 [40736/60000 (68%)]\tLoss: 0.115097\n",
            "Train Epoch: 1 [40768/60000 (68%)]\tLoss: 0.027634\n",
            "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 0.072545\n",
            "Train Epoch: 1 [40832/60000 (68%)]\tLoss: 0.014035\n",
            "Train Epoch: 1 [40864/60000 (68%)]\tLoss: 0.207134\n",
            "Train Epoch: 1 [40896/60000 (68%)]\tLoss: 0.016127\n",
            "Train Epoch: 1 [40928/60000 (68%)]\tLoss: 0.033784\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.207452\n",
            "Train Epoch: 1 [40992/60000 (68%)]\tLoss: 0.061908\n",
            "Train Epoch: 1 [41024/60000 (68%)]\tLoss: 0.094039\n",
            "Train Epoch: 1 [41056/60000 (68%)]\tLoss: 0.158946\n",
            "Train Epoch: 1 [41088/60000 (68%)]\tLoss: 0.158264\n",
            "Train Epoch: 1 [41120/60000 (69%)]\tLoss: 0.054108\n",
            "Train Epoch: 1 [41152/60000 (69%)]\tLoss: 0.114195\n",
            "Train Epoch: 1 [41184/60000 (69%)]\tLoss: 0.152875\n",
            "Train Epoch: 1 [41216/60000 (69%)]\tLoss: 0.036724\n",
            "Train Epoch: 1 [41248/60000 (69%)]\tLoss: 0.306828\n",
            "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.264913\n",
            "Train Epoch: 1 [41312/60000 (69%)]\tLoss: 0.162560\n",
            "Train Epoch: 1 [41344/60000 (69%)]\tLoss: 0.097218\n",
            "Train Epoch: 1 [41376/60000 (69%)]\tLoss: 0.102167\n",
            "Train Epoch: 1 [41408/60000 (69%)]\tLoss: 0.125708\n",
            "Train Epoch: 1 [41440/60000 (69%)]\tLoss: 0.205164\n",
            "Train Epoch: 1 [41472/60000 (69%)]\tLoss: 0.043300\n",
            "Train Epoch: 1 [41504/60000 (69%)]\tLoss: 0.094899\n",
            "Train Epoch: 1 [41536/60000 (69%)]\tLoss: 0.170235\n",
            "Train Epoch: 1 [41568/60000 (69%)]\tLoss: 0.094555\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.106475\n",
            "Train Epoch: 1 [41632/60000 (69%)]\tLoss: 0.012488\n",
            "Train Epoch: 1 [41664/60000 (69%)]\tLoss: 0.068809\n",
            "Train Epoch: 1 [41696/60000 (69%)]\tLoss: 0.065755\n",
            "Train Epoch: 1 [41728/60000 (70%)]\tLoss: 0.099520\n",
            "Train Epoch: 1 [41760/60000 (70%)]\tLoss: 0.158577\n",
            "Train Epoch: 1 [41792/60000 (70%)]\tLoss: 0.080621\n",
            "Train Epoch: 1 [41824/60000 (70%)]\tLoss: 0.057725\n",
            "Train Epoch: 1 [41856/60000 (70%)]\tLoss: 0.042098\n",
            "Train Epoch: 1 [41888/60000 (70%)]\tLoss: 0.126144\n",
            "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.098479\n",
            "Train Epoch: 1 [41952/60000 (70%)]\tLoss: 0.037669\n",
            "Train Epoch: 1 [41984/60000 (70%)]\tLoss: 0.196896\n",
            "Train Epoch: 1 [42016/60000 (70%)]\tLoss: 0.146226\n",
            "Train Epoch: 1 [42048/60000 (70%)]\tLoss: 0.035676\n",
            "Train Epoch: 1 [42080/60000 (70%)]\tLoss: 0.033330\n",
            "Train Epoch: 1 [42112/60000 (70%)]\tLoss: 0.158560\n",
            "Train Epoch: 1 [42144/60000 (70%)]\tLoss: 0.036542\n",
            "Train Epoch: 1 [42176/60000 (70%)]\tLoss: 0.078589\n",
            "Train Epoch: 1 [42208/60000 (70%)]\tLoss: 0.127985\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.023873\n",
            "Train Epoch: 1 [42272/60000 (70%)]\tLoss: 0.092535\n",
            "Train Epoch: 1 [42304/60000 (71%)]\tLoss: 0.119015\n",
            "Train Epoch: 1 [42336/60000 (71%)]\tLoss: 0.195364\n",
            "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.059188\n",
            "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 0.106645\n",
            "Train Epoch: 1 [42432/60000 (71%)]\tLoss: 0.385761\n",
            "Train Epoch: 1 [42464/60000 (71%)]\tLoss: 0.246728\n",
            "Train Epoch: 1 [42496/60000 (71%)]\tLoss: 0.410828\n",
            "Train Epoch: 1 [42528/60000 (71%)]\tLoss: 0.038150\n",
            "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.146748\n",
            "Train Epoch: 1 [42592/60000 (71%)]\tLoss: 0.019897\n",
            "Train Epoch: 1 [42624/60000 (71%)]\tLoss: 0.028397\n",
            "Train Epoch: 1 [42656/60000 (71%)]\tLoss: 0.089381\n",
            "Train Epoch: 1 [42688/60000 (71%)]\tLoss: 0.158947\n",
            "Train Epoch: 1 [42720/60000 (71%)]\tLoss: 0.054764\n",
            "Train Epoch: 1 [42752/60000 (71%)]\tLoss: 0.107903\n",
            "Train Epoch: 1 [42784/60000 (71%)]\tLoss: 0.020050\n",
            "Train Epoch: 1 [42816/60000 (71%)]\tLoss: 0.139094\n",
            "Train Epoch: 1 [42848/60000 (71%)]\tLoss: 0.288379\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.151865\n",
            "Train Epoch: 1 [42912/60000 (72%)]\tLoss: 0.209833\n",
            "Train Epoch: 1 [42944/60000 (72%)]\tLoss: 0.163105\n",
            "Train Epoch: 1 [42976/60000 (72%)]\tLoss: 0.139493\n",
            "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 0.093960\n",
            "Train Epoch: 1 [43040/60000 (72%)]\tLoss: 0.155908\n",
            "Train Epoch: 1 [43072/60000 (72%)]\tLoss: 0.136717\n",
            "Train Epoch: 1 [43104/60000 (72%)]\tLoss: 0.157513\n",
            "Train Epoch: 1 [43136/60000 (72%)]\tLoss: 0.070595\n",
            "Train Epoch: 1 [43168/60000 (72%)]\tLoss: 0.090275\n",
            "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.133736\n",
            "Train Epoch: 1 [43232/60000 (72%)]\tLoss: 0.046022\n",
            "Train Epoch: 1 [43264/60000 (72%)]\tLoss: 0.046020\n",
            "Train Epoch: 1 [43296/60000 (72%)]\tLoss: 0.009369\n",
            "Train Epoch: 1 [43328/60000 (72%)]\tLoss: 0.117004\n",
            "Train Epoch: 1 [43360/60000 (72%)]\tLoss: 0.143332\n",
            "Train Epoch: 1 [43392/60000 (72%)]\tLoss: 0.024607\n",
            "Train Epoch: 1 [43424/60000 (72%)]\tLoss: 0.234006\n",
            "Train Epoch: 1 [43456/60000 (72%)]\tLoss: 0.094655\n",
            "Train Epoch: 1 [43488/60000 (72%)]\tLoss: 0.031679\n",
            "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.119616\n",
            "Train Epoch: 1 [43552/60000 (73%)]\tLoss: 0.234758\n",
            "Train Epoch: 1 [43584/60000 (73%)]\tLoss: 0.012601\n",
            "Train Epoch: 1 [43616/60000 (73%)]\tLoss: 0.034139\n",
            "Train Epoch: 1 [43648/60000 (73%)]\tLoss: 0.247402\n",
            "Train Epoch: 1 [43680/60000 (73%)]\tLoss: 0.048917\n",
            "Train Epoch: 1 [43712/60000 (73%)]\tLoss: 0.022401\n",
            "Train Epoch: 1 [43744/60000 (73%)]\tLoss: 0.024173\n",
            "Train Epoch: 1 [43776/60000 (73%)]\tLoss: 0.106436\n",
            "Train Epoch: 1 [43808/60000 (73%)]\tLoss: 0.134876\n",
            "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.048372\n",
            "Train Epoch: 1 [43872/60000 (73%)]\tLoss: 0.317025\n",
            "Train Epoch: 1 [43904/60000 (73%)]\tLoss: 0.101640\n",
            "Train Epoch: 1 [43936/60000 (73%)]\tLoss: 0.248026\n",
            "Train Epoch: 1 [43968/60000 (73%)]\tLoss: 0.315733\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.065054\n",
            "Train Epoch: 1 [44032/60000 (73%)]\tLoss: 0.088483\n",
            "Train Epoch: 1 [44064/60000 (73%)]\tLoss: 0.143731\n",
            "Train Epoch: 1 [44096/60000 (73%)]\tLoss: 0.159026\n",
            "Train Epoch: 1 [44128/60000 (74%)]\tLoss: 0.073107\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.068528\n",
            "Train Epoch: 1 [44192/60000 (74%)]\tLoss: 0.065171\n",
            "Train Epoch: 1 [44224/60000 (74%)]\tLoss: 0.159647\n",
            "Train Epoch: 1 [44256/60000 (74%)]\tLoss: 0.053895\n",
            "Train Epoch: 1 [44288/60000 (74%)]\tLoss: 0.041134\n",
            "Train Epoch: 1 [44320/60000 (74%)]\tLoss: 0.134205\n",
            "Train Epoch: 1 [44352/60000 (74%)]\tLoss: 0.225987\n",
            "Train Epoch: 1 [44384/60000 (74%)]\tLoss: 0.038891\n",
            "Train Epoch: 1 [44416/60000 (74%)]\tLoss: 0.157059\n",
            "Train Epoch: 1 [44448/60000 (74%)]\tLoss: 0.326602\n",
            "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.048729\n",
            "Train Epoch: 1 [44512/60000 (74%)]\tLoss: 0.102113\n",
            "Train Epoch: 1 [44544/60000 (74%)]\tLoss: 0.068515\n",
            "Train Epoch: 1 [44576/60000 (74%)]\tLoss: 0.027895\n",
            "Train Epoch: 1 [44608/60000 (74%)]\tLoss: 0.091785\n",
            "Train Epoch: 1 [44640/60000 (74%)]\tLoss: 0.035177\n",
            "Train Epoch: 1 [44672/60000 (74%)]\tLoss: 0.027320\n",
            "Train Epoch: 1 [44704/60000 (75%)]\tLoss: 0.081973\n",
            "Train Epoch: 1 [44736/60000 (75%)]\tLoss: 0.268222\n",
            "Train Epoch: 1 [44768/60000 (75%)]\tLoss: 0.069752\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.068668\n",
            "Train Epoch: 1 [44832/60000 (75%)]\tLoss: 0.260383\n",
            "Train Epoch: 1 [44864/60000 (75%)]\tLoss: 0.179841\n",
            "Train Epoch: 1 [44896/60000 (75%)]\tLoss: 0.134611\n",
            "Train Epoch: 1 [44928/60000 (75%)]\tLoss: 0.034309\n",
            "Train Epoch: 1 [44960/60000 (75%)]\tLoss: 0.240354\n",
            "Train Epoch: 1 [44992/60000 (75%)]\tLoss: 0.050711\n",
            "Train Epoch: 1 [45024/60000 (75%)]\tLoss: 0.083668\n",
            "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.087958\n",
            "Train Epoch: 1 [45088/60000 (75%)]\tLoss: 0.167183\n",
            "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.248464\n",
            "Train Epoch: 1 [45152/60000 (75%)]\tLoss: 0.138470\n",
            "Train Epoch: 1 [45184/60000 (75%)]\tLoss: 0.203931\n",
            "Train Epoch: 1 [45216/60000 (75%)]\tLoss: 0.045276\n",
            "Train Epoch: 1 [45248/60000 (75%)]\tLoss: 0.111849\n",
            "Train Epoch: 1 [45280/60000 (75%)]\tLoss: 0.016807\n",
            "Train Epoch: 1 [45312/60000 (76%)]\tLoss: 0.010073\n",
            "Train Epoch: 1 [45344/60000 (76%)]\tLoss: 0.136025\n",
            "Train Epoch: 1 [45376/60000 (76%)]\tLoss: 0.084139\n",
            "Train Epoch: 1 [45408/60000 (76%)]\tLoss: 0.289982\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.210696\n",
            "Train Epoch: 1 [45472/60000 (76%)]\tLoss: 0.201517\n",
            "Train Epoch: 1 [45504/60000 (76%)]\tLoss: 0.189422\n",
            "Train Epoch: 1 [45536/60000 (76%)]\tLoss: 0.013995\n",
            "Train Epoch: 1 [45568/60000 (76%)]\tLoss: 0.152097\n",
            "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.275080\n",
            "Train Epoch: 1 [45632/60000 (76%)]\tLoss: 0.059171\n",
            "Train Epoch: 1 [45664/60000 (76%)]\tLoss: 0.042895\n",
            "Train Epoch: 1 [45696/60000 (76%)]\tLoss: 0.039395\n",
            "Train Epoch: 1 [45728/60000 (76%)]\tLoss: 0.062676\n",
            "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.167857\n",
            "Train Epoch: 1 [45792/60000 (76%)]\tLoss: 0.388712\n",
            "Train Epoch: 1 [45824/60000 (76%)]\tLoss: 0.081968\n",
            "Train Epoch: 1 [45856/60000 (76%)]\tLoss: 0.316919\n",
            "Train Epoch: 1 [45888/60000 (76%)]\tLoss: 0.186437\n",
            "Train Epoch: 1 [45920/60000 (77%)]\tLoss: 0.020493\n",
            "Train Epoch: 1 [45952/60000 (77%)]\tLoss: 0.271568\n",
            "Train Epoch: 1 [45984/60000 (77%)]\tLoss: 0.039526\n",
            "Train Epoch: 1 [46016/60000 (77%)]\tLoss: 0.130863\n",
            "Train Epoch: 1 [46048/60000 (77%)]\tLoss: 0.076635\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.259624\n",
            "Train Epoch: 1 [46112/60000 (77%)]\tLoss: 0.158199\n",
            "Train Epoch: 1 [46144/60000 (77%)]\tLoss: 0.052777\n",
            "Train Epoch: 1 [46176/60000 (77%)]\tLoss: 0.155713\n",
            "Train Epoch: 1 [46208/60000 (77%)]\tLoss: 0.043645\n",
            "Train Epoch: 1 [46240/60000 (77%)]\tLoss: 0.381660\n",
            "Train Epoch: 1 [46272/60000 (77%)]\tLoss: 0.393064\n",
            "Train Epoch: 1 [46304/60000 (77%)]\tLoss: 0.105524\n",
            "Train Epoch: 1 [46336/60000 (77%)]\tLoss: 0.215990\n",
            "Train Epoch: 1 [46368/60000 (77%)]\tLoss: 0.152605\n",
            "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.309638\n",
            "Train Epoch: 1 [46432/60000 (77%)]\tLoss: 0.141450\n",
            "Train Epoch: 1 [46464/60000 (77%)]\tLoss: 0.040441\n",
            "Train Epoch: 1 [46496/60000 (77%)]\tLoss: 0.011301\n",
            "Train Epoch: 1 [46528/60000 (78%)]\tLoss: 0.023467\n",
            "Train Epoch: 1 [46560/60000 (78%)]\tLoss: 0.247151\n",
            "Train Epoch: 1 [46592/60000 (78%)]\tLoss: 0.074466\n",
            "Train Epoch: 1 [46624/60000 (78%)]\tLoss: 0.051004\n",
            "Train Epoch: 1 [46656/60000 (78%)]\tLoss: 0.013588\n",
            "Train Epoch: 1 [46688/60000 (78%)]\tLoss: 0.069118\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.325377\n",
            "Train Epoch: 1 [46752/60000 (78%)]\tLoss: 0.051624\n",
            "Train Epoch: 1 [46784/60000 (78%)]\tLoss: 0.032449\n",
            "Train Epoch: 1 [46816/60000 (78%)]\tLoss: 0.021017\n",
            "Train Epoch: 1 [46848/60000 (78%)]\tLoss: 0.135274\n",
            "Train Epoch: 1 [46880/60000 (78%)]\tLoss: 0.034331\n",
            "Train Epoch: 1 [46912/60000 (78%)]\tLoss: 0.057357\n",
            "Train Epoch: 1 [46944/60000 (78%)]\tLoss: 0.048205\n",
            "Train Epoch: 1 [46976/60000 (78%)]\tLoss: 0.097148\n",
            "Train Epoch: 1 [47008/60000 (78%)]\tLoss: 0.222336\n",
            "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.030873\n",
            "Train Epoch: 1 [47072/60000 (78%)]\tLoss: 0.152589\n",
            "Train Epoch: 1 [47104/60000 (79%)]\tLoss: 0.076625\n",
            "Train Epoch: 1 [47136/60000 (79%)]\tLoss: 0.163470\n",
            "Train Epoch: 1 [47168/60000 (79%)]\tLoss: 0.010724\n",
            "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 0.139746\n",
            "Train Epoch: 1 [47232/60000 (79%)]\tLoss: 0.284040\n",
            "Train Epoch: 1 [47264/60000 (79%)]\tLoss: 0.251812\n",
            "Train Epoch: 1 [47296/60000 (79%)]\tLoss: 0.049348\n",
            "Train Epoch: 1 [47328/60000 (79%)]\tLoss: 0.179841\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.166979\n",
            "Train Epoch: 1 [47392/60000 (79%)]\tLoss: 0.086351\n",
            "Train Epoch: 1 [47424/60000 (79%)]\tLoss: 0.111373\n",
            "Train Epoch: 1 [47456/60000 (79%)]\tLoss: 0.377321\n",
            "Train Epoch: 1 [47488/60000 (79%)]\tLoss: 0.113867\n",
            "Train Epoch: 1 [47520/60000 (79%)]\tLoss: 0.101114\n",
            "Train Epoch: 1 [47552/60000 (79%)]\tLoss: 0.135214\n",
            "Train Epoch: 1 [47584/60000 (79%)]\tLoss: 0.369437\n",
            "Train Epoch: 1 [47616/60000 (79%)]\tLoss: 0.067226\n",
            "Train Epoch: 1 [47648/60000 (79%)]\tLoss: 0.036665\n",
            "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.172729\n",
            "Train Epoch: 1 [47712/60000 (80%)]\tLoss: 0.026732\n",
            "Train Epoch: 1 [47744/60000 (80%)]\tLoss: 0.155260\n",
            "Train Epoch: 1 [47776/60000 (80%)]\tLoss: 0.075484\n",
            "Train Epoch: 1 [47808/60000 (80%)]\tLoss: 0.070958\n",
            "Train Epoch: 1 [47840/60000 (80%)]\tLoss: 0.198619\n",
            "Train Epoch: 1 [47872/60000 (80%)]\tLoss: 0.095855\n",
            "Train Epoch: 1 [47904/60000 (80%)]\tLoss: 0.286316\n",
            "Train Epoch: 1 [47936/60000 (80%)]\tLoss: 0.229256\n",
            "Train Epoch: 1 [47968/60000 (80%)]\tLoss: 0.035006\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.072603\n",
            "Train Epoch: 1 [48032/60000 (80%)]\tLoss: 0.063974\n",
            "Train Epoch: 1 [48064/60000 (80%)]\tLoss: 0.116625\n",
            "Train Epoch: 1 [48096/60000 (80%)]\tLoss: 0.231663\n",
            "Train Epoch: 1 [48128/60000 (80%)]\tLoss: 0.072322\n",
            "Train Epoch: 1 [48160/60000 (80%)]\tLoss: 0.026848\n",
            "Train Epoch: 1 [48192/60000 (80%)]\tLoss: 0.022502\n",
            "Train Epoch: 1 [48224/60000 (80%)]\tLoss: 0.052519\n",
            "Train Epoch: 1 [48256/60000 (80%)]\tLoss: 0.132879\n",
            "Train Epoch: 1 [48288/60000 (80%)]\tLoss: 0.058391\n",
            "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.065619\n",
            "Train Epoch: 1 [48352/60000 (81%)]\tLoss: 0.283626\n",
            "Train Epoch: 1 [48384/60000 (81%)]\tLoss: 0.093952\n",
            "Train Epoch: 1 [48416/60000 (81%)]\tLoss: 0.008942\n",
            "Train Epoch: 1 [48448/60000 (81%)]\tLoss: 0.014690\n",
            "Train Epoch: 1 [48480/60000 (81%)]\tLoss: 0.036222\n",
            "Train Epoch: 1 [48512/60000 (81%)]\tLoss: 0.084690\n",
            "Train Epoch: 1 [48544/60000 (81%)]\tLoss: 0.017225\n",
            "Train Epoch: 1 [48576/60000 (81%)]\tLoss: 0.083442\n",
            "Train Epoch: 1 [48608/60000 (81%)]\tLoss: 0.013642\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.174244\n",
            "Train Epoch: 1 [48672/60000 (81%)]\tLoss: 0.016166\n",
            "Train Epoch: 1 [48704/60000 (81%)]\tLoss: 0.052983\n",
            "Train Epoch: 1 [48736/60000 (81%)]\tLoss: 0.026761\n",
            "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.043503\n",
            "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 0.093082\n",
            "Train Epoch: 1 [48832/60000 (81%)]\tLoss: 0.048643\n",
            "Train Epoch: 1 [48864/60000 (81%)]\tLoss: 0.020405\n",
            "Train Epoch: 1 [48896/60000 (81%)]\tLoss: 0.074938\n",
            "Train Epoch: 1 [48928/60000 (82%)]\tLoss: 0.372466\n",
            "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.389539\n",
            "Train Epoch: 1 [48992/60000 (82%)]\tLoss: 0.160679\n",
            "Train Epoch: 1 [49024/60000 (82%)]\tLoss: 0.093758\n",
            "Train Epoch: 1 [49056/60000 (82%)]\tLoss: 0.121654\n",
            "Train Epoch: 1 [49088/60000 (82%)]\tLoss: 0.060989\n",
            "Train Epoch: 1 [49120/60000 (82%)]\tLoss: 0.057093\n",
            "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.019418\n",
            "Train Epoch: 1 [49184/60000 (82%)]\tLoss: 0.236213\n",
            "Train Epoch: 1 [49216/60000 (82%)]\tLoss: 0.126326\n",
            "Train Epoch: 1 [49248/60000 (82%)]\tLoss: 0.111162\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.082384\n",
            "Train Epoch: 1 [49312/60000 (82%)]\tLoss: 0.032973\n",
            "Train Epoch: 1 [49344/60000 (82%)]\tLoss: 0.039429\n",
            "Train Epoch: 1 [49376/60000 (82%)]\tLoss: 0.016453\n",
            "Train Epoch: 1 [49408/60000 (82%)]\tLoss: 0.127054\n",
            "Train Epoch: 1 [49440/60000 (82%)]\tLoss: 0.096743\n",
            "Train Epoch: 1 [49472/60000 (82%)]\tLoss: 0.400416\n",
            "Train Epoch: 1 [49504/60000 (83%)]\tLoss: 0.218346\n",
            "Train Epoch: 1 [49536/60000 (83%)]\tLoss: 0.494675\n",
            "Train Epoch: 1 [49568/60000 (83%)]\tLoss: 0.271819\n",
            "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.165838\n",
            "Train Epoch: 1 [49632/60000 (83%)]\tLoss: 0.446237\n",
            "Train Epoch: 1 [49664/60000 (83%)]\tLoss: 0.119035\n",
            "Train Epoch: 1 [49696/60000 (83%)]\tLoss: 0.034958\n",
            "Train Epoch: 1 [49728/60000 (83%)]\tLoss: 0.126459\n",
            "Train Epoch: 1 [49760/60000 (83%)]\tLoss: 0.067191\n",
            "Train Epoch: 1 [49792/60000 (83%)]\tLoss: 0.048545\n",
            "Train Epoch: 1 [49824/60000 (83%)]\tLoss: 0.118465\n",
            "Train Epoch: 1 [49856/60000 (83%)]\tLoss: 0.099269\n",
            "Train Epoch: 1 [49888/60000 (83%)]\tLoss: 0.347759\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.076156\n",
            "Train Epoch: 1 [49952/60000 (83%)]\tLoss: 0.048648\n",
            "Train Epoch: 1 [49984/60000 (83%)]\tLoss: 0.047860\n",
            "Train Epoch: 1 [50016/60000 (83%)]\tLoss: 0.057230\n",
            "Train Epoch: 1 [50048/60000 (83%)]\tLoss: 0.103650\n",
            "Train Epoch: 1 [50080/60000 (83%)]\tLoss: 0.092483\n",
            "Train Epoch: 1 [50112/60000 (84%)]\tLoss: 0.142342\n",
            "Train Epoch: 1 [50144/60000 (84%)]\tLoss: 0.072287\n",
            "Train Epoch: 1 [50176/60000 (84%)]\tLoss: 0.052885\n",
            "Train Epoch: 1 [50208/60000 (84%)]\tLoss: 0.327863\n",
            "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.175567\n",
            "Train Epoch: 1 [50272/60000 (84%)]\tLoss: 0.049351\n",
            "Train Epoch: 1 [50304/60000 (84%)]\tLoss: 0.119381\n",
            "Train Epoch: 1 [50336/60000 (84%)]\tLoss: 0.191845\n",
            "Train Epoch: 1 [50368/60000 (84%)]\tLoss: 0.352682\n",
            "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.551083\n",
            "Train Epoch: 1 [50432/60000 (84%)]\tLoss: 0.150166\n",
            "Train Epoch: 1 [50464/60000 (84%)]\tLoss: 0.033154\n",
            "Train Epoch: 1 [50496/60000 (84%)]\tLoss: 0.352445\n",
            "Train Epoch: 1 [50528/60000 (84%)]\tLoss: 0.029987\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.135425\n",
            "Train Epoch: 1 [50592/60000 (84%)]\tLoss: 0.068904\n",
            "Train Epoch: 1 [50624/60000 (84%)]\tLoss: 0.293812\n",
            "Train Epoch: 1 [50656/60000 (84%)]\tLoss: 0.008205\n",
            "Train Epoch: 1 [50688/60000 (84%)]\tLoss: 0.126820\n",
            "Train Epoch: 1 [50720/60000 (85%)]\tLoss: 0.047058\n",
            "Train Epoch: 1 [50752/60000 (85%)]\tLoss: 0.143071\n",
            "Train Epoch: 1 [50784/60000 (85%)]\tLoss: 0.046474\n",
            "Train Epoch: 1 [50816/60000 (85%)]\tLoss: 0.071691\n",
            "Train Epoch: 1 [50848/60000 (85%)]\tLoss: 0.018154\n",
            "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.098984\n",
            "Train Epoch: 1 [50912/60000 (85%)]\tLoss: 0.063090\n",
            "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 0.043637\n",
            "Train Epoch: 1 [50976/60000 (85%)]\tLoss: 0.067584\n",
            "Train Epoch: 1 [51008/60000 (85%)]\tLoss: 0.036118\n",
            "Train Epoch: 1 [51040/60000 (85%)]\tLoss: 0.070578\n",
            "Train Epoch: 1 [51072/60000 (85%)]\tLoss: 0.076447\n",
            "Train Epoch: 1 [51104/60000 (85%)]\tLoss: 0.055933\n",
            "Train Epoch: 1 [51136/60000 (85%)]\tLoss: 0.116046\n",
            "Train Epoch: 1 [51168/60000 (85%)]\tLoss: 0.068810\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.145434\n",
            "Train Epoch: 1 [51232/60000 (85%)]\tLoss: 0.253701\n",
            "Train Epoch: 1 [51264/60000 (85%)]\tLoss: 0.266598\n",
            "Train Epoch: 1 [51296/60000 (85%)]\tLoss: 0.123575\n",
            "Train Epoch: 1 [51328/60000 (86%)]\tLoss: 0.115197\n",
            "Train Epoch: 1 [51360/60000 (86%)]\tLoss: 0.022146\n",
            "Train Epoch: 1 [51392/60000 (86%)]\tLoss: 0.010548\n",
            "Train Epoch: 1 [51424/60000 (86%)]\tLoss: 0.056206\n",
            "Train Epoch: 1 [51456/60000 (86%)]\tLoss: 0.119726\n",
            "Train Epoch: 1 [51488/60000 (86%)]\tLoss: 0.007310\n",
            "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.233088\n",
            "Train Epoch: 1 [51552/60000 (86%)]\tLoss: 0.079385\n",
            "Train Epoch: 1 [51584/60000 (86%)]\tLoss: 0.085031\n",
            "Train Epoch: 1 [51616/60000 (86%)]\tLoss: 0.050219\n",
            "Train Epoch: 1 [51648/60000 (86%)]\tLoss: 0.055833\n",
            "Train Epoch: 1 [51680/60000 (86%)]\tLoss: 0.166144\n",
            "Train Epoch: 1 [51712/60000 (86%)]\tLoss: 0.111496\n",
            "Train Epoch: 1 [51744/60000 (86%)]\tLoss: 0.224700\n",
            "Train Epoch: 1 [51776/60000 (86%)]\tLoss: 0.046680\n",
            "Train Epoch: 1 [51808/60000 (86%)]\tLoss: 0.014174\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.064876\n",
            "Train Epoch: 1 [51872/60000 (86%)]\tLoss: 0.043765\n",
            "Train Epoch: 1 [51904/60000 (87%)]\tLoss: 0.075904\n",
            "Train Epoch: 1 [51936/60000 (87%)]\tLoss: 0.165031\n",
            "Train Epoch: 1 [51968/60000 (87%)]\tLoss: 0.420271\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.055667\n",
            "Train Epoch: 1 [52032/60000 (87%)]\tLoss: 0.021115\n",
            "Train Epoch: 1 [52064/60000 (87%)]\tLoss: 0.182647\n",
            "Train Epoch: 1 [52096/60000 (87%)]\tLoss: 0.101836\n",
            "Train Epoch: 1 [52128/60000 (87%)]\tLoss: 0.405020\n",
            "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.106000\n",
            "Train Epoch: 1 [52192/60000 (87%)]\tLoss: 0.193980\n",
            "Train Epoch: 1 [52224/60000 (87%)]\tLoss: 0.208935\n",
            "Train Epoch: 1 [52256/60000 (87%)]\tLoss: 0.146443\n",
            "Train Epoch: 1 [52288/60000 (87%)]\tLoss: 0.116517\n",
            "Train Epoch: 1 [52320/60000 (87%)]\tLoss: 0.188410\n",
            "Train Epoch: 1 [52352/60000 (87%)]\tLoss: 0.079744\n",
            "Train Epoch: 1 [52384/60000 (87%)]\tLoss: 0.050679\n",
            "Train Epoch: 1 [52416/60000 (87%)]\tLoss: 0.037831\n",
            "Train Epoch: 1 [52448/60000 (87%)]\tLoss: 0.077752\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.012581\n",
            "Train Epoch: 1 [52512/60000 (88%)]\tLoss: 0.015230\n",
            "Train Epoch: 1 [52544/60000 (88%)]\tLoss: 0.033900\n",
            "Train Epoch: 1 [52576/60000 (88%)]\tLoss: 0.029064\n",
            "Train Epoch: 1 [52608/60000 (88%)]\tLoss: 0.034416\n",
            "Train Epoch: 1 [52640/60000 (88%)]\tLoss: 0.047017\n",
            "Train Epoch: 1 [52672/60000 (88%)]\tLoss: 0.138451\n",
            "Train Epoch: 1 [52704/60000 (88%)]\tLoss: 0.103924\n",
            "Train Epoch: 1 [52736/60000 (88%)]\tLoss: 0.142341\n",
            "Train Epoch: 1 [52768/60000 (88%)]\tLoss: 0.040252\n",
            "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.224997\n",
            "Train Epoch: 1 [52832/60000 (88%)]\tLoss: 0.138991\n",
            "Train Epoch: 1 [52864/60000 (88%)]\tLoss: 0.077060\n",
            "Train Epoch: 1 [52896/60000 (88%)]\tLoss: 0.291738\n",
            "Train Epoch: 1 [52928/60000 (88%)]\tLoss: 0.356162\n",
            "Train Epoch: 1 [52960/60000 (88%)]\tLoss: 0.311296\n",
            "Train Epoch: 1 [52992/60000 (88%)]\tLoss: 0.049780\n",
            "Train Epoch: 1 [53024/60000 (88%)]\tLoss: 0.168140\n",
            "Train Epoch: 1 [53056/60000 (88%)]\tLoss: 0.042861\n",
            "Train Epoch: 1 [53088/60000 (88%)]\tLoss: 0.024952\n",
            "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.061839\n",
            "Train Epoch: 1 [53152/60000 (89%)]\tLoss: 0.463322\n",
            "Train Epoch: 1 [53184/60000 (89%)]\tLoss: 0.061089\n",
            "Train Epoch: 1 [53216/60000 (89%)]\tLoss: 0.215671\n",
            "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.015370\n",
            "Train Epoch: 1 [53280/60000 (89%)]\tLoss: 0.008466\n",
            "Train Epoch: 1 [53312/60000 (89%)]\tLoss: 0.045403\n",
            "Train Epoch: 1 [53344/60000 (89%)]\tLoss: 0.005773\n",
            "Train Epoch: 1 [53376/60000 (89%)]\tLoss: 0.102723\n",
            "Train Epoch: 1 [53408/60000 (89%)]\tLoss: 0.003753\n",
            "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.069640\n",
            "Train Epoch: 1 [53472/60000 (89%)]\tLoss: 0.117402\n",
            "Train Epoch: 1 [53504/60000 (89%)]\tLoss: 0.047488\n",
            "Train Epoch: 1 [53536/60000 (89%)]\tLoss: 0.120047\n",
            "Train Epoch: 1 [53568/60000 (89%)]\tLoss: 0.223604\n",
            "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 0.127318\n",
            "Train Epoch: 1 [53632/60000 (89%)]\tLoss: 0.084536\n",
            "Train Epoch: 1 [53664/60000 (89%)]\tLoss: 0.095198\n",
            "Train Epoch: 1 [53696/60000 (89%)]\tLoss: 0.025927\n",
            "Train Epoch: 1 [53728/60000 (90%)]\tLoss: 0.079149\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.015727\n",
            "Train Epoch: 1 [53792/60000 (90%)]\tLoss: 0.097275\n",
            "Train Epoch: 1 [53824/60000 (90%)]\tLoss: 0.152540\n",
            "Train Epoch: 1 [53856/60000 (90%)]\tLoss: 0.263863\n",
            "Train Epoch: 1 [53888/60000 (90%)]\tLoss: 0.202191\n",
            "Train Epoch: 1 [53920/60000 (90%)]\tLoss: 0.024774\n",
            "Train Epoch: 1 [53952/60000 (90%)]\tLoss: 0.050280\n",
            "Train Epoch: 1 [53984/60000 (90%)]\tLoss: 0.173885\n",
            "Train Epoch: 1 [54016/60000 (90%)]\tLoss: 0.052031\n",
            "Train Epoch: 1 [54048/60000 (90%)]\tLoss: 0.053360\n",
            "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.173506\n",
            "Train Epoch: 1 [54112/60000 (90%)]\tLoss: 0.007516\n",
            "Train Epoch: 1 [54144/60000 (90%)]\tLoss: 0.017495\n",
            "Train Epoch: 1 [54176/60000 (90%)]\tLoss: 0.126011\n",
            "Train Epoch: 1 [54208/60000 (90%)]\tLoss: 0.013964\n",
            "Train Epoch: 1 [54240/60000 (90%)]\tLoss: 0.052426\n",
            "Train Epoch: 1 [54272/60000 (90%)]\tLoss: 0.090826\n",
            "Train Epoch: 1 [54304/60000 (91%)]\tLoss: 0.082121\n",
            "Train Epoch: 1 [54336/60000 (91%)]\tLoss: 0.011594\n",
            "Train Epoch: 1 [54368/60000 (91%)]\tLoss: 0.085407\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.043644\n",
            "Train Epoch: 1 [54432/60000 (91%)]\tLoss: 0.089473\n",
            "Train Epoch: 1 [54464/60000 (91%)]\tLoss: 0.031743\n",
            "Train Epoch: 1 [54496/60000 (91%)]\tLoss: 0.223064\n",
            "Train Epoch: 1 [54528/60000 (91%)]\tLoss: 0.105344\n",
            "Train Epoch: 1 [54560/60000 (91%)]\tLoss: 0.110280\n",
            "Train Epoch: 1 [54592/60000 (91%)]\tLoss: 0.015063\n",
            "Train Epoch: 1 [54624/60000 (91%)]\tLoss: 0.015314\n",
            "Train Epoch: 1 [54656/60000 (91%)]\tLoss: 0.064967\n",
            "Train Epoch: 1 [54688/60000 (91%)]\tLoss: 0.050878\n",
            "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.032834\n",
            "Train Epoch: 1 [54752/60000 (91%)]\tLoss: 0.110509\n",
            "Train Epoch: 1 [54784/60000 (91%)]\tLoss: 0.033768\n",
            "Train Epoch: 1 [54816/60000 (91%)]\tLoss: 0.099742\n",
            "Train Epoch: 1 [54848/60000 (91%)]\tLoss: 0.122457\n",
            "Train Epoch: 1 [54880/60000 (91%)]\tLoss: 0.189615\n",
            "Train Epoch: 1 [54912/60000 (92%)]\tLoss: 0.162462\n",
            "Train Epoch: 1 [54944/60000 (92%)]\tLoss: 0.172016\n",
            "Train Epoch: 1 [54976/60000 (92%)]\tLoss: 0.045864\n",
            "Train Epoch: 1 [55008/60000 (92%)]\tLoss: 0.045861\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.061520\n",
            "Train Epoch: 1 [55072/60000 (92%)]\tLoss: 0.011608\n",
            "Train Epoch: 1 [55104/60000 (92%)]\tLoss: 0.019162\n",
            "Train Epoch: 1 [55136/60000 (92%)]\tLoss: 0.045053\n",
            "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.040145\n",
            "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.060461\n",
            "Train Epoch: 1 [55232/60000 (92%)]\tLoss: 0.028211\n",
            "Train Epoch: 1 [55264/60000 (92%)]\tLoss: 0.078981\n",
            "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 0.131201\n",
            "Train Epoch: 1 [55328/60000 (92%)]\tLoss: 0.255635\n",
            "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.024342\n",
            "Train Epoch: 1 [55392/60000 (92%)]\tLoss: 0.032638\n",
            "Train Epoch: 1 [55424/60000 (92%)]\tLoss: 0.144140\n",
            "Train Epoch: 1 [55456/60000 (92%)]\tLoss: 0.064617\n",
            "Train Epoch: 1 [55488/60000 (92%)]\tLoss: 0.187089\n",
            "Train Epoch: 1 [55520/60000 (93%)]\tLoss: 0.128005\n",
            "Train Epoch: 1 [55552/60000 (93%)]\tLoss: 0.017298\n",
            "Train Epoch: 1 [55584/60000 (93%)]\tLoss: 0.124592\n",
            "Train Epoch: 1 [55616/60000 (93%)]\tLoss: 0.011981\n",
            "Train Epoch: 1 [55648/60000 (93%)]\tLoss: 0.086942\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.026568\n",
            "Train Epoch: 1 [55712/60000 (93%)]\tLoss: 0.180487\n",
            "Train Epoch: 1 [55744/60000 (93%)]\tLoss: 0.036854\n",
            "Train Epoch: 1 [55776/60000 (93%)]\tLoss: 0.167627\n",
            "Train Epoch: 1 [55808/60000 (93%)]\tLoss: 0.118294\n",
            "Train Epoch: 1 [55840/60000 (93%)]\tLoss: 0.160216\n",
            "Train Epoch: 1 [55872/60000 (93%)]\tLoss: 0.095842\n",
            "Train Epoch: 1 [55904/60000 (93%)]\tLoss: 0.032833\n",
            "Train Epoch: 1 [55936/60000 (93%)]\tLoss: 0.020410\n",
            "Train Epoch: 1 [55968/60000 (93%)]\tLoss: 0.037988\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.154594\n",
            "Train Epoch: 1 [56032/60000 (93%)]\tLoss: 0.015311\n",
            "Train Epoch: 1 [56064/60000 (93%)]\tLoss: 0.164305\n",
            "Train Epoch: 1 [56096/60000 (93%)]\tLoss: 0.010599\n",
            "Train Epoch: 1 [56128/60000 (94%)]\tLoss: 0.072457\n",
            "Train Epoch: 1 [56160/60000 (94%)]\tLoss: 0.158489\n",
            "Train Epoch: 1 [56192/60000 (94%)]\tLoss: 0.046255\n",
            "Train Epoch: 1 [56224/60000 (94%)]\tLoss: 0.123366\n",
            "Train Epoch: 1 [56256/60000 (94%)]\tLoss: 0.187708\n",
            "Train Epoch: 1 [56288/60000 (94%)]\tLoss: 0.046502\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.040752\n",
            "Train Epoch: 1 [56352/60000 (94%)]\tLoss: 0.075377\n",
            "Train Epoch: 1 [56384/60000 (94%)]\tLoss: 0.149269\n",
            "Train Epoch: 1 [56416/60000 (94%)]\tLoss: 0.010033\n",
            "Train Epoch: 1 [56448/60000 (94%)]\tLoss: 0.250713\n",
            "Train Epoch: 1 [56480/60000 (94%)]\tLoss: 0.178720\n",
            "Train Epoch: 1 [56512/60000 (94%)]\tLoss: 0.038607\n",
            "Train Epoch: 1 [56544/60000 (94%)]\tLoss: 0.007757\n",
            "Train Epoch: 1 [56576/60000 (94%)]\tLoss: 0.177587\n",
            "Train Epoch: 1 [56608/60000 (94%)]\tLoss: 0.073311\n",
            "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.201892\n",
            "Train Epoch: 1 [56672/60000 (94%)]\tLoss: 0.033624\n",
            "Train Epoch: 1 [56704/60000 (95%)]\tLoss: 0.047713\n",
            "Train Epoch: 1 [56736/60000 (95%)]\tLoss: 0.042710\n",
            "Train Epoch: 1 [56768/60000 (95%)]\tLoss: 0.076525\n",
            "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 0.225766\n",
            "Train Epoch: 1 [56832/60000 (95%)]\tLoss: 0.170282\n",
            "Train Epoch: 1 [56864/60000 (95%)]\tLoss: 0.083909\n",
            "Train Epoch: 1 [56896/60000 (95%)]\tLoss: 0.051163\n",
            "Train Epoch: 1 [56928/60000 (95%)]\tLoss: 0.002765\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.032959\n",
            "Train Epoch: 1 [56992/60000 (95%)]\tLoss: 0.070814\n",
            "Train Epoch: 1 [57024/60000 (95%)]\tLoss: 0.140597\n",
            "Train Epoch: 1 [57056/60000 (95%)]\tLoss: 0.165999\n",
            "Train Epoch: 1 [57088/60000 (95%)]\tLoss: 0.021818\n",
            "Train Epoch: 1 [57120/60000 (95%)]\tLoss: 0.010308\n",
            "Train Epoch: 1 [57152/60000 (95%)]\tLoss: 0.055487\n",
            "Train Epoch: 1 [57184/60000 (95%)]\tLoss: 0.076134\n",
            "Train Epoch: 1 [57216/60000 (95%)]\tLoss: 0.049181\n",
            "Train Epoch: 1 [57248/60000 (95%)]\tLoss: 0.114499\n",
            "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 0.111999\n",
            "Train Epoch: 1 [57312/60000 (96%)]\tLoss: 0.066342\n",
            "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.010954\n",
            "Train Epoch: 1 [57376/60000 (96%)]\tLoss: 0.044655\n",
            "Train Epoch: 1 [57408/60000 (96%)]\tLoss: 0.017254\n",
            "Train Epoch: 1 [57440/60000 (96%)]\tLoss: 0.027789\n",
            "Train Epoch: 1 [57472/60000 (96%)]\tLoss: 0.083692\n",
            "Train Epoch: 1 [57504/60000 (96%)]\tLoss: 0.062905\n",
            "Train Epoch: 1 [57536/60000 (96%)]\tLoss: 0.046595\n",
            "Train Epoch: 1 [57568/60000 (96%)]\tLoss: 0.025044\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.077499\n",
            "Train Epoch: 1 [57632/60000 (96%)]\tLoss: 0.220996\n",
            "Train Epoch: 1 [57664/60000 (96%)]\tLoss: 0.068102\n",
            "Train Epoch: 1 [57696/60000 (96%)]\tLoss: 0.075829\n",
            "Train Epoch: 1 [57728/60000 (96%)]\tLoss: 0.373320\n",
            "Train Epoch: 1 [57760/60000 (96%)]\tLoss: 0.280347\n",
            "Train Epoch: 1 [57792/60000 (96%)]\tLoss: 0.030089\n",
            "Train Epoch: 1 [57824/60000 (96%)]\tLoss: 0.009395\n",
            "Train Epoch: 1 [57856/60000 (96%)]\tLoss: 0.082230\n",
            "Train Epoch: 1 [57888/60000 (96%)]\tLoss: 0.015280\n",
            "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.006924\n",
            "Train Epoch: 1 [57952/60000 (97%)]\tLoss: 0.184120\n",
            "Train Epoch: 1 [57984/60000 (97%)]\tLoss: 0.010345\n",
            "Train Epoch: 1 [58016/60000 (97%)]\tLoss: 0.059684\n",
            "Train Epoch: 1 [58048/60000 (97%)]\tLoss: 0.058866\n",
            "Train Epoch: 1 [58080/60000 (97%)]\tLoss: 0.089972\n",
            "Train Epoch: 1 [58112/60000 (97%)]\tLoss: 0.010538\n",
            "Train Epoch: 1 [58144/60000 (97%)]\tLoss: 0.004677\n",
            "Train Epoch: 1 [58176/60000 (97%)]\tLoss: 0.018052\n",
            "Train Epoch: 1 [58208/60000 (97%)]\tLoss: 0.002839\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.080224\n",
            "Train Epoch: 1 [58272/60000 (97%)]\tLoss: 0.013025\n",
            "Train Epoch: 1 [58304/60000 (97%)]\tLoss: 0.024618\n",
            "Train Epoch: 1 [58336/60000 (97%)]\tLoss: 0.014649\n",
            "Train Epoch: 1 [58368/60000 (97%)]\tLoss: 0.060535\n",
            "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 0.037648\n",
            "Train Epoch: 1 [58432/60000 (97%)]\tLoss: 0.005878\n",
            "Train Epoch: 1 [58464/60000 (97%)]\tLoss: 0.037853\n",
            "Train Epoch: 1 [58496/60000 (97%)]\tLoss: 0.011528\n",
            "Train Epoch: 1 [58528/60000 (98%)]\tLoss: 0.006031\n",
            "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.004570\n",
            "Train Epoch: 1 [58592/60000 (98%)]\tLoss: 0.042489\n",
            "Train Epoch: 1 [58624/60000 (98%)]\tLoss: 0.048923\n",
            "Train Epoch: 1 [58656/60000 (98%)]\tLoss: 0.008434\n",
            "Train Epoch: 1 [58688/60000 (98%)]\tLoss: 0.013921\n",
            "Train Epoch: 1 [58720/60000 (98%)]\tLoss: 0.006649\n",
            "Train Epoch: 1 [58752/60000 (98%)]\tLoss: 0.016444\n",
            "Train Epoch: 1 [58784/60000 (98%)]\tLoss: 0.266019\n",
            "Train Epoch: 1 [58816/60000 (98%)]\tLoss: 0.207563\n",
            "Train Epoch: 1 [58848/60000 (98%)]\tLoss: 0.023195\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.019276\n",
            "Train Epoch: 1 [58912/60000 (98%)]\tLoss: 0.003417\n",
            "Train Epoch: 1 [58944/60000 (98%)]\tLoss: 0.004433\n",
            "Train Epoch: 1 [58976/60000 (98%)]\tLoss: 0.002638\n",
            "Train Epoch: 1 [59008/60000 (98%)]\tLoss: 0.004081\n",
            "Train Epoch: 1 [59040/60000 (98%)]\tLoss: 0.007344\n",
            "Train Epoch: 1 [59072/60000 (98%)]\tLoss: 0.022607\n",
            "Train Epoch: 1 [59104/60000 (99%)]\tLoss: 0.014065\n",
            "Train Epoch: 1 [59136/60000 (99%)]\tLoss: 0.001947\n",
            "Train Epoch: 1 [59168/60000 (99%)]\tLoss: 0.004059\n",
            "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.010048\n",
            "Train Epoch: 1 [59232/60000 (99%)]\tLoss: 0.023540\n",
            "Train Epoch: 1 [59264/60000 (99%)]\tLoss: 0.100050\n",
            "Train Epoch: 1 [59296/60000 (99%)]\tLoss: 0.099364\n",
            "Train Epoch: 1 [59328/60000 (99%)]\tLoss: 0.038162\n",
            "Train Epoch: 1 [59360/60000 (99%)]\tLoss: 0.097387\n",
            "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 0.172682\n",
            "Train Epoch: 1 [59424/60000 (99%)]\tLoss: 0.032115\n",
            "Train Epoch: 1 [59456/60000 (99%)]\tLoss: 0.113804\n",
            "Train Epoch: 1 [59488/60000 (99%)]\tLoss: 0.003165\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.005170\n",
            "Train Epoch: 1 [59552/60000 (99%)]\tLoss: 0.004974\n",
            "Train Epoch: 1 [59584/60000 (99%)]\tLoss: 0.005805\n",
            "Train Epoch: 1 [59616/60000 (99%)]\tLoss: 0.012580\n",
            "Train Epoch: 1 [59648/60000 (99%)]\tLoss: 0.156180\n",
            "Train Epoch: 1 [59680/60000 (99%)]\tLoss: 0.197293\n",
            "Train Epoch: 1 [59712/60000 (100%)]\tLoss: 0.914349\n",
            "Train Epoch: 1 [59744/60000 (100%)]\tLoss: 0.335479\n",
            "Train Epoch: 1 [59776/60000 (100%)]\tLoss: 0.088107\n",
            "Train Epoch: 1 [59808/60000 (100%)]\tLoss: 0.050847\n",
            "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.015881\n",
            "Train Epoch: 1 [59872/60000 (100%)]\tLoss: 0.067622\n",
            "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.641829\n",
            "Train Epoch: 1 [59936/60000 (100%)]\tLoss: 0.099022\n",
            "Train Epoch: 1 [59968/60000 (100%)]\tLoss: 0.054983\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan kelas model neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Layer konvolusi pertama, dengan input 1 channel (grayscale image), output 12 channel, dan kernel 3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3)\n",
        "        # Layer pooling maksimum dengan ukuran kernel 2x2 dan stride 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Layer Fully Connected (FC) untuk output 10 kelas (untuk klasifikasi digit MNIST)\n",
        "        self.fc = nn.Linear(12 * 13 * 13, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Mengubah bentuk input menjadi 4 dimensi (-1 adalah batch size yang otomatis ditentukan, 1 adalah jumlah channel, 28x28 adalah ukuran gambar)\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        # Menjalankan input melalui layer konvolusi pertama dan aktivasi ReLU\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # Menjalankan input melalui layer pooling\n",
        "        x = self.pool(x)\n",
        "        # Mengubah input menjadi bentuk vektor satu dimensi sebelum dimasukkan ke layer FC\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        # Melalui layer FC dan menghasilkan output untuk 10 kelas\n",
        "        x = self.fc(x)\n",
        "        # Menggunakan log softmax untuk menghasilkan probabilitas log untuk setiap kelas\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Membuat DataLoader untuk data pelatihan dan pengujian, dengan ukuran batch 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, 32)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, 32)\n",
        "\n",
        "# Memilih device untuk pelatihan (GPU jika tersedia, jika tidak CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Menetapkan jumlah epoch\n",
        "epochs = 1\n",
        "\n",
        "# Menginisialisasi model, optimizer, dan memindahkan model ke device yang telah dipilih\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Mengubah model ke mode pelatihan\n",
        "model.train()\n",
        "\n",
        "# Loop untuk setiap epoch\n",
        "for epoch in range(1, epochs+1):\n",
        "    # Loop untuk setiap batch dalam DataLoader pelatihan\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Memindahkan data dan target ke device yang telah dipilih\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Mengatur gradien optimizer menjadi nol\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Melakukan forward pass untuk mendapatkan output dari model\n",
        "        output = model(data)\n",
        "\n",
        "        # Menghitung loss menggunakan Negative Log-Likelihood Loss (NLLLoss)\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Melakukan backward pass untuk menghitung gradien\n",
        "        loss.backward()\n",
        "\n",
        "        # Memperbarui parameter model dengan optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # Menampilkan progres pelatihan (epoch, batch, dan loss)\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBSEGoKv7jzI"
      },
      "source": [
        "### Kuantisasi Model\n",
        "\n",
        "Setelah pelatihan, kita dapat mengkuantisasi model menggunakan fungsi `torch.quantization.quantize_dynamic` dari pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sc2xBb9p7jzI"
      },
      "outputs": [],
      "source": [
        "# Memindahkan model ke CPU\n",
        "model.to('cpu')\n",
        "\n",
        "# Melakukan quantization dinamis pada model, dengan mengubah tipe data layer Linear menjadi 8-bit integer (qint8)\n",
        "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzQH2cUF7jzI"
      },
      "source": [
        "### Periksa Ukuran Model\n",
        "\n",
        "Kita dapat melihat bahwa model terkuantisasi jauh lebih kecil daripada model asli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_snd1Acl7jzJ",
        "outputId": "77d33345-4de3-4eda-bd45-69c436dcfb03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 136K\n",
            "-rw-r--r-- 1 root root 82K Jan  4 11:08 original_model.p\n",
            "-rw-r--r-- 1 root root 25K Jan  4 10:50 post_quantized_model.p\n",
            "-rw-r--r-- 1 root root 23K Jan  4 11:08 quantized_model.p\n"
          ]
        }
      ],
      "source": [
        "# Menentukan path direktori untuk menyimpan model\n",
        "models_dir = pathlib.Path(\"./models/\")\n",
        "models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Menyimpan model yang telah dilatih (model asli) ke dalam file dengan ekstensi .p\n",
        "torch.save(model.state_dict(), \"./models/original_model.p\")\n",
        "\n",
        "# Menyimpan model yang sudah melalui proses quantization ke dalam file dengan ekstensi .p\n",
        "torch.save(quantized_model.state_dict(), \"./models/quantized_model.p\")\n",
        "\n",
        "# Menampilkan daftar isi dari direktori \"models\" beserta ukuran file\n",
        "%ls -lh models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ajPGiD7jzJ"
      },
      "source": [
        "### Periksa Akurasi\n",
        "\n",
        "Kita dapat melihat bahwa model terkuantisasi memiliki akurasi yang sebanding dengan model asli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bou7PSa7jzJ",
        "outputId": "53c3fc12-ccdf-4270-b6fc-88eafa3b3563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model accuracy: 97%\n",
            "Quantized model accuracy: 97%\n"
          ]
        }
      ],
      "source": [
        "# Fungsi untuk menguji akurasi model\n",
        "def test(model, device, data_loader, quantized=False):\n",
        "    # Memindahkan model ke device (misalnya CPU atau GPU)\n",
        "    model.to(device)\n",
        "    # Menetapkan model ke mode evaluasi (non-training)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0  # Untuk menyimpan total kerugian\n",
        "    correct = 0  # Untuk menghitung jumlah prediksi yang benar\n",
        "\n",
        "    # Nonaktifkan perhitungan gradient (untuk menghemat memori dan mempercepat inference)\n",
        "    with torch.no_grad():\n",
        "        # Loop untuk setiap batch data di data_loader\n",
        "        for data, target in data_loader:\n",
        "            # Memindahkan data dan target ke device yang sama dengan model\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # Melakukan prediksi dengan model\n",
        "            output = model(data)\n",
        "            # Menghitung kerugian menggunakan Negative Log Likelihood Loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # Menjumlahkan kerugian per batch\n",
        "            # Menentukan prediksi dengan nilai probabilitas terbesar\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # Menghitung jumlah prediksi yang benar\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Menghitung rata-rata kerugian per sampel\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "\n",
        "    # Mengembalikan akurasi dalam persen\n",
        "    return 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "# Menguji akurasi model asli\n",
        "original_acc = test(model, \"cpu\", test_loader)\n",
        "# Menguji akurasi model yang telah diquantize\n",
        "quantized_acc = test(quantized_model, \"cpu\", test_loader)\n",
        "\n",
        "# Menampilkan hasil akurasi dari kedua model\n",
        "print('Original model accuracy: {:.0f}%'.format(original_acc))\n",
        "print('Quantized model accuracy: {:.0f}%'.format(quantized_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IGqA6gN7jzK"
      },
      "source": [
        "## Kuantisasi Statis Pasca-pelatihan\n",
        "\n",
        "Kuantisasi statis pasca-pelatihan adalah saat bobot dan aktivasi dikuantisasi dan kalibrasi diperlukan pasca-pelatihan. Di sini, kami mengkuantisasi model menggunakan fungsi `torch.quantization.quantize_fx()` dari PyTorch dan membandingkan akurasi dan ukuran model yang dikuantisasi dengan model FP32 asli.\n",
        "\n",
        "Untuk mengkuantisasi menggunakan alat kuantisasi statis pasca-pelatihan, pertama-tama tentukan model atau muat model yang telah dilatih sebelumnya, lalu buat pemetaan konfigurasi kuantisasi menggunakan default untuk mesin QNNPACK. Atur model ke mode evaluasi dan buat tensor masukan sampel. Kemudian, persiapkan model untuk kuantisasi menggunakan fungsi `quantize_fx.prepare_fx()`. Ini melibatkan penerapan pemetaan konfigurasi kuantisasi dan persiapan model untuk menangani presisi int8. Model yang disiapkan kemudian dieksekusi pada tensor masukan. Terakhir, model terkuantisasi dengan memanggil `quantize_fx.convert_fx()` dan menyimpan model ke disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imMIHOBA7jzK",
        "outputId": "20359889-5479-4044-cb60-fea1425e9c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-01b6b1aec99a>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(\"./models/original_model.p\"))\n"
          ]
        }
      ],
      "source": [
        "# Mengimpor modul yang diperlukan untuk kuantisasi\n",
        "from torch.ao.quantization import (\n",
        "  get_default_qconfig_mapping,\n",
        "  get_default_qat_qconfig_mapping,\n",
        "  QConfigMapping,\n",
        ")\n",
        "import torch.ao.quantization.quantize_fx as quantize_fx\n",
        "import copy\n",
        "\n",
        "# Memuat model yang telah dilatih sebelumnya\n",
        "loaded_model = Net()\n",
        "loaded_model.load_state_dict(torch.load(\"./models/original_model.p\"))\n",
        "model_to_quantize = copy.deepcopy(loaded_model)\n",
        "\n",
        "# Mendapatkan konfigurasi kuantisasi default untuk 'qnnpack' (algoritma kuantisasi yang digunakan)\n",
        "qconfig_mapping = get_default_qconfig_mapping(\"qnnpack\")\n",
        "\n",
        "# Menetapkan model ke mode evaluasi\n",
        "model_to_quantize.eval()\n",
        "\n",
        "# Mengambil input FP32 pertama dari data test untuk mempersiapkan model untuk kuantisasi\n",
        "input_fp32 = next(iter(test_loader))[0][0:1]\n",
        "input_fp32.to('cpu')  # Memindahkan input ke CPU\n",
        "\n",
        "# Mempersiapkan model untuk kuantisasi (membuat versi model yang siap untuk kuantisasi)\n",
        "model_fp32_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_mapping, input_fp32)\n",
        "\n",
        "# Menjalankan model yang sudah dipersiapkan untuk kuantisasi dengan input FP32\n",
        "model_fp32_prepared(input_fp32)\n",
        "\n",
        "# Mengonversi model ke format INT8 setelah kuantisasi\n",
        "model_int8 = quantize_fx.convert_fx(model_fp32_prepared)\n",
        "\n",
        "# Menyimpan model yang telah dikuantisasi ke dalam file\n",
        "torch.save(model_int8.state_dict(), \"./models/post_quantized_model.p\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mgMBBkP7jzL"
      },
      "source": [
        "## Periksa Ukuran Model\n",
        "\n",
        "Sekali lagi, kita dapat melihat bahwa model terkuantisasi jauh lebih kecil daripada model asli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WG3MfV37jzL",
        "outputId": "a29a5649-9062-45a3-8f3f-f3c321b0c144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 136K\n",
            "-rw-r--r-- 1 root root 82K Jan  4 11:08 original_model.p\n",
            "-rw-r--r-- 1 root root 25K Jan  4 11:08 post_quantized_model.p\n",
            "-rw-r--r-- 1 root root 23K Jan  4 11:08 quantized_model.p\n"
          ]
        }
      ],
      "source": [
        "%ls -lh models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1leqK0wT7jzL"
      },
      "source": [
        "## Periksa Akurasi\n",
        "\n",
        "Sekali lagi, kita dapat melihat bahwa akurasi model terkuantisasi tidak jauh berbeda dengan akurasi aslinya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGIbioKq7jzM",
        "outputId": "5c1ad0d2-c247-488c-c916-f568e5037241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post quantized model accuracy: 97%\n"
          ]
        }
      ],
      "source": [
        "# Menguji model yang telah dikuantisasi\n",
        "quantized_acc = test(model_int8, \"cpu\", test_loader, quantized=True)\n",
        "\n",
        "# Mencetak akurasi model yang telah dikuantisasi\n",
        "print('Post quantized model accuracy: {:.0f}%'.format(quantized_acc))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "model_optimization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}