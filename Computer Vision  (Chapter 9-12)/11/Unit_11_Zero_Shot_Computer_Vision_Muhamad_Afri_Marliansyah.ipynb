{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Unit 11: Zero-Shot Learning\n",
        "\n",
        "### 1. Pendahuluan\n",
        "#### Penjelasan:\n",
        "#### Zero-Shot Learning (ZSL) adalah pendekatan dalam pembelajaran mesin yang memungkinkan model untuk mengenali kelas objek yang belum pernah ditemui sebelumnya dalam proses pelatihan. Teknik ini memanfaatkan informasi tambahan seperti deskripsi tekstual, atribut, atau fitur lainnya untuk menghubungkan antara kelas yang sudah terlihat dan yang belum terlihat. ZSL memanfaatkan kemampuan representasi umum, memungkinkan model untuk belajar dan menggeneralisasi dengan lebih luas. Dengan kata lain, model belajar memahami konsep dasar sehingga dapat mengenali hal-hal baru hanya berdasarkan deskripsi atau atribut yang dimiliki.\n",
        "\n",
        "#### Keuntungan ZSL:\n",
        "##### - Mengurangi kebutuhan akan anotasi data yang memakan biaya.\n",
        "##### - Meningkatkan fleksibilitas model dalam menangani kategori baru.\n",
        "##### - Berguna dalam situasi di mana data untuk kelas tertentu sulit atau bahkan tidak mungkin diperoleh.\n",
        "\n",
        "#### Contoh aplikasi Zero-Shot Learning:\n",
        "##### - **Visi Komputer**: Pengidentifikasian objek baru yang tidak ada dalam dataset pelatihan.\n",
        "##### - **Pemrosesan Bahasa Alami**: Klasifikasi teks atau entitas tanpa pelatihan khusus pada kelas target.\n",
        "##### - **Sistem Rekomendasi**: Kemampuan merekomendasikan produk atau layanan baru yang belum pernah dilihat sebelumnya.\n",
        "##### - **Robotika**: Memahami instruksi baru tanpa perlu pelatihan tambahan."
      ],
      "metadata": {
        "id": "dcBRbQO5D3Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Introduction to Zero-Shot Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVvipth6Fi4L",
        "outputId": "bb3e1ffb-2fa7-41f7-9acb-85c739825150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Introduction to Zero-Shot Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Zero-Shot Learning\n",
        "#### Penjelasan:\n",
        "#### Dalam Zero-Shot Learning, terdapat dua pendekatan utama yang sering diterapkan:\n",
        "##### - **Metode Berbasis Embedding**: Dalam pendekatan ini, baik gambar maupun deskripsi kelas dipetakan ke dalam ruang vektor yang sama. Kesamaan antara vektor-vektor tersebut digunakan untuk memprediksi kelas. Model seperti CLIP mengadopsi metode ini.\n",
        "##### - **Metode Berbasis Generatif**: Pendekatan ini menggunakan model generatif seperti GAN atau Diffusion Models untuk mensintesis fitur visual untuk kelas yang belum terlihat. Fitur yang dihasilkan kemudian digunakan untuk melatih model klasifikasi tambahan.\n",
        "\n",
        "#### Implementasi Zero-Shot Learning menggunakan model CLIP:\n",
        "#### CLIP (Contrastive Languageâ€“Image Pre-training) adalah model dari OpenAI yang menghubungkan teks dengan gambar. Model ini mempelajari representasi bersama untuk teks dan gambar, yang memungkinkan Zero-Shot Learning dilakukan dengan efektif."
      ],
      "metadata": {
        "id": "aHg_1z5eFk0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "\n",
        "# Memuat model CLIP\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Contoh gambar dan teks untuk prediksi Zero-Shot\n",
        "image_path = \"/content/kuching.jpg\"  # Ganti dengan path ke gambar Anda\n",
        "texts = [\"Kucing\", \"Anjing\", \"Sepeda\"]  # Label teks yang ingin diuji\n",
        "\n",
        "# Memproses gambar dan teks\n",
        "from PIL import Image\n",
        "image = Image.open(image_path)\n",
        "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Melakukan prediksi\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image  # Skor prediksi\n",
        "probs = logits_per_image.softmax(dim=1)  # Probabilitas untuk setiap label teks\n",
        "\n",
        "# Menampilkan hasil\n",
        "for i, text in enumerate(texts):\n",
        "    print(f\"Label: {text}, Probabilitas: {probs[0][i].item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fOqobilF2ej",
        "outputId": "49cdbe91-edf3-42f0-cbf1-02e98b210881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Kucing, Probabilitas: 0.9675\n",
            "Label: Anjing, Probabilitas: 0.0324\n",
            "Label: Sepeda, Probabilitas: 0.0001\n"
          ]
        }
      ]
    }
  ]
}