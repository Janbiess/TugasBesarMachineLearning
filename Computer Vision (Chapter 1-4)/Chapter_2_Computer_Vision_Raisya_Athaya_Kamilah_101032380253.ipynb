{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM54xl3awp2+zzo/47cnyA6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "346f3f0be1a9444d834be50cc72af192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edcecaaa760740a0b71ebf70b6e6c194",
              "IPY_MODEL_023715a4f905486389d72d9e5e64ea19",
              "IPY_MODEL_76f9832d3789422bbba4dab2dd2df765"
            ],
            "layout": "IPY_MODEL_c7379ac629e243ac9e86744e31a6640e"
          }
        },
        "edcecaaa760740a0b71ebf70b6e6c194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea8e88193b3a45c382900bc932f66fee",
            "placeholder": "​",
            "style": "IPY_MODEL_c9520966f74d43b586475bd32018523f",
            "value": "model.safetensors: 100%"
          }
        },
        "023715a4f905486389d72d9e5e64ea19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380317ccbf744cc9b9719cdec1ec96f9",
            "max": 22058321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e0c7cc5a3ed4932b7143d3bbf017a2f",
            "value": 22058321
          }
        },
        "76f9832d3789422bbba4dab2dd2df765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a2806782d64a38a50e5bc42c910b59",
            "placeholder": "​",
            "style": "IPY_MODEL_a77ca5aaf0754094bfcb9be304366380",
            "value": " 22.1M/22.1M [00:00&lt;00:00, 67.2MB/s]"
          }
        },
        "c7379ac629e243ac9e86744e31a6640e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8e88193b3a45c382900bc932f66fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9520966f74d43b586475bd32018523f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "380317ccbf744cc9b9719cdec1ec96f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0c7cc5a3ed4932b7143d3bbf017a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40a2806782d64a38a50e5bc42c910b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77ca5aaf0754094bfcb9be304366380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinobu357/TugasMLRaisya/blob/main/UAS/Chapter_2_Computer_Vision_Raisya_Athaya_Kamilah_101032380253.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "WUfuxgih0UEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unit ini membahas arsitektur Convolutional Neural Networks, yang merupakan fondasi dari banyak aplikasi computer vision modern. CNN (Convolutional Neural Network) adalah jenis jaringan saraf tiruan yang terinspirasi oleh cara otak manusia memproses informasi visual. CNN dirancang untuk memproses data dalam bentuk grid, seperti citra, dan mampu mengenali pola visual yang kompleks melalui lapisan konvolusi dan pooling."
      ],
      "metadata": {
        "id": "SzAgOJtF0TtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arsitektur CNN dasar (Sequential)"
      ],
      "metadata": {
        "id": "PlpiMOpR3eaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), #\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "1YBSCFIT5x5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convoluliton untuk mengenali pola atau fitur penting dengan mengestraksi fitur pada gambar.\n",
        "Pooling untuk mengurangi fitur/dimensi dengan mempertahankan informasi penting pada pola atau fitur yang telah diidentifikasi selama proses konvolusi.\n",
        "\n",
        "Flatten berfungsi mengubah hasil konvolusi menjadi vektor datar\n",
        "\n",
        "Fungsi Relu untuk mengubah nilai negatif menjadi nol dan membiarkan nilai positif tetap tidak berubah. ReLU memperkenalkan non-linearitas dalam model sambil menjaga komputasi efisien.\n",
        "\n",
        "Dropout untuk Mencegah overfitting dengan menonaktifkan 50% neuron(0.5)\n",
        "\n",
        "Dense yaitu Lapisan fully connected untuk klasifikasi dengan aktivasi softmax untuk probabilitas kelas."
      ],
      "metadata": {
        "id": "vDoXkQZ15sIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG19"
      ],
      "metadata": {
        "id": "mEzhv62cz85x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19 adalah arsitektur jaringan saraf konvolusional (CNN) yang terdiri dari 19 lapisan, termasuk 16 lapisan konvolusi dan 3 lapisan fully connected. Model ini dirancang oleh Visual Geometry Group (VGG) dari University of Oxford dan terkenal karena kesederhanaannya serta kinerjanya yang baik dalam berbagai tugas pengenalan citra. VGG19 menggunakan ukuran kernel yang konsisten (3x3) dan memiliki banyak lapisan untuk menangkap fitur gambar secara mendalam"
      ],
      "metadata": {
        "id": "tNuqb5oQ0TaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " VGG Network Architechture\n",
        "\n",
        "    Inputs are 224x224 images.\n",
        "    Convolution kernel shape is (3,3) and max pooling window shape is (2,2).\n",
        "    Number of channels for each convolutional layer 64 -> 128 -> 256 -> 512 -> 512.\n",
        "    VGG16 has 16 hidden layers (13 convolutional layers and 3 fully connected layers).\n",
        "    VGG19 has 19 hidden layers (16 convolutional layers and 3 fully connected layers)."
      ],
      "metadata": {
        "id": "He9nf6bs0Q-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNzNqOj9z0vv"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(VGG19, self).__init__()\n",
        "\n",
        "        # Feature extraction layers: Convolutional and pooling layers\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                3, 64, kernel_size=3, padding=1\n",
        "            ),  # 3 input channels, 64 output channels, 3x3 kernel, 1 padding\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=2, stride=2\n",
        "            ),  # Max pooling with 2x2 kernel and stride 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Fully connected layers for classification\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                512 * 7 * 7, 4096\n",
        "            ),  # 512 channels, 7x7 spatial dimensions after max pooling\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout layer with 0.5 dropout probability\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_classes),  # Output layer with 'num_classes' output units\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)  # Pass input through the feature extractor layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layers\n",
        "        x = self.classifier(x)  # Pass flattened output through the classifier layers\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogleNet"
      ],
      "metadata": {
        "id": "_LJ-5WHl93q8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogLeNet adalah arsitektur jaringan saraf konvolusional (CNN) yang diperkenalkan oleh Google pada tahun 2014. Model ini dikenal dengan penggunaan modul Inception yang memungkinkan pemilihan berbagai ukuran filter konvolusi dalam satu blok, sehingga meningkatkan efisiensi komputasi dan akurasi."
      ],
      "metadata": {
        "id": "GsHsL68W94Np"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitur Utama GoogLeNet:\n",
        "\n",
        "Modul Inception: Menggabungkan berbagai ukuran filter konvolusi dalam satu blok untuk menangkap fitur pada berbagai skala.\n",
        "   \n",
        "Pengurangan Parameter: Menggunakan teknik seperti 1x1 konvolusi untuk mengurangi jumlah parameter, sehingga meningkatkan efisiensi komputasi.\n",
        "    \n",
        "\n",
        "Auxiliary Classifiers: Menambahkan classifier tambahan pada lapisan tertentu untuk membantu pelatihan dan mengurangi overfitting"
      ],
      "metadata": {
        "id": "CdiiM9E5-grG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BaseConv2d(nn.Module):  # Menyediakan blok dasar konvolusi yang menggabungkan konvolusi 2D dan aktivasi ReLU.\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(BaseConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class InceptionModule(nn.Module):  #Implementasi dari modul Inception, yang menggabungkan beberapa operasi konvolusi dengan ukuran kernel yang berbeda dalam satu blok untuk mengekstraksi fitur dengan berbagai skala\n",
        "    def __init__(self, in_channels, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        self.b1 = BaseConv2d(in_channels, n1x1, kernel_size=1)  # b1: Lapisan konvolusi 1x1 untuk mengubah jumlah saluran input menjadi 1x1.\n",
        "\n",
        "        self.b2 = nn.Sequential(    # b2: Menggunakan 1x1 konvolusi untuk mereduksi dimensi, lalu 3x3 konvolusi.\n",
        "            BaseConv2d(in_channels, n3x3red, kernel_size=1),\n",
        "            BaseConv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.b3 = nn.Sequential(   #b3: Menggunakan 1x1 konvolusi untuk mereduksi dimensi, lalu 5x5 konvolusi.\n",
        "            BaseConv2d(in_channels, n5x5red, kernel_size=1),\n",
        "            BaseConv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "\n",
        "        self.b4 = nn.Sequential(  #b4: Lapisan pooling (MaxPooling), kemudian diikuti oleh 1x1 konvolusi.\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            BaseConv2d(in_channels, pool_proj, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1, y2, y3, y4], 1)\n",
        "\n",
        "\n",
        "class AuxiliaryClassifier(nn.Module):  #  Menambahkan classifier pembantu untuk membantu pelatihan dan mengurangi overfitting\n",
        "    def __init__(self, in_channels, num_classes, dropout=0.7):\n",
        "        super(AuxiliaryClassifier, self).__init__()\n",
        "        self.pool = nn.AvgPool2d(5, stride=3)\n",
        "        self.conv = BaseConv2d(in_channels, 128, kernel_size=1)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module): # implementasi arsitektur GoogLeNet secara keseluruhan, yang menggabungkan beberapa modul Inception dan lapisan lainnya.\n",
        "    def __init__(self, use_aux=True):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "\n",
        "        self.use_aux = use_aux\n",
        "        ## block 1 (Menggunakan lapisan konvolusi 7x7, diikuti oleh max pooling dan Local Response Normalization (LRN) untuk stabilitas numerik.)\n",
        "        self.conv1 = BaseConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 2 (Block 2: Konvolusi 1x1 dan 3x3, diikuti dengan LRN dan max pooling)\n",
        "        self.conv2 = BaseConv2d(64, 64, kernel_size=1)\n",
        "        self.conv3 = BaseConv2d(64, 192, kernel_size=3, padding=1)\n",
        "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 3 (Menggunakan beberapa modul Inception yang telah didefinisikan sebelumnya.)\n",
        "        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 4\n",
        "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 5 (Dua modul Inception yang lebih besar)\n",
        "        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        ## auxiliary classifier (Jika use_aux diset ke True, dua auxiliary classifier ditambahkan setelah beberapa blok)\n",
        "        if self.use_aux:\n",
        "            self.aux1 = AuxiliaryClassifier(512, 1000)\n",
        "            self.aux2 = AuxiliaryClassifier(528, 1000)\n",
        "\n",
        "        ## block 6 ( Global average pooling dan lapisan dropout untuk regularisasi, diikuti oleh lapisan fully connected yang menghasilkan prediksi kelas)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(1024, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.lrn1(x)\n",
        "\n",
        "        ## block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        ## block 3\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        ## block 4\n",
        "        x = self.inception4a(x)\n",
        "        if self.use_aux:\n",
        "            aux1 = self.aux1(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        if self.use_aux:\n",
        "            aux2 = self.aux2(x)\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        ## block 5\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        ## block 6\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        if self.use_aux:\n",
        "            return x, aux1, aux2\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "6qo-uz8N958Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mobilenet"
      ],
      "metadata": {
        "id": "N9FAL3KqAcOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet adalah jenis arsitektur jaringan saraf yang dirancang untuk mobile. Arsitektur ini dikembangkan oleh tim peneliti Google dan pertama kali diperkenalkan pada tahun 2017. Tujuan utama MobileNet adalah menyediakan klasifikasi gambar dan deteksi objek berperforma tinggi dan latensi rendah pada smartphone, tablet, dan perangkat lain yang memiliki keterbatasan sumber daya.\n",
        "\n",
        "Keunggulan utama MobileNet terletak pada penggunaan konvolusi separabel kedalaman (depthwise separable convolutions), yang secara signifikan mengurangi jumlah parameter dibandingkan dengan konvolusi standar. Konvolusi separabel kedalaman terdiri dari dua operasi: konvolusi kedalaman (depthwise convolution) dan konvolusi titik (pointwise convolution). Pendekatan ini memungkinkan MobileNet untuk mencapai keseimbangan antara akurasi dan efisiensi komputasi, menjadikannya ideal untuk aplikasi pada perangkat dengan sumber daya terbatas.\n",
        "\n",
        "\n",
        "Deptwise: Operasi konvolusi dilakukan secara terpisah untuk setiap channel input (grouped convolution). Hal ini mengurangi jumlah operasi komputasi dibandingkan dengan konvolusi standar\n",
        "\n",
        "Pointwise: Konvolusi 1x1 untuk menggabungkan informasi antar channel output dari depthwise convolution."
      ],
      "metadata": {
        "id": "9fY0WO-gAcwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        # Depthwise convolution: memproses setiap channel secara independen\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels,\n",
        "            in_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            groups=in_channels,  # \"groups\" sama dengan jumlah channel input\n",
        "        )\n",
        "        # Pointwise convolution: menggabungkan channel dengan kernel 1x1\n",
        "        self.pointwise = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)  # Operasi depthwise convolution\n",
        "        x = self.pointwise(x)  # Operasi pointwise convolution\n",
        "        return x\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super().__init__()\n",
        "        # Layer awal: Konvolusi biasa\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # MobileNet body: Kumpulan depthwise separable convolution\n",
        "        self.dw_conv2 = DepthwiseSeparableConv(32, 64, 1)\n",
        "        self.dw_conv3 = DepthwiseSeparableConv(64, 128, 2)\n",
        "        self.dw_conv4 = DepthwiseSeparableConv(128, 128, 1)\n",
        "        self.dw_conv5 = DepthwiseSeparableConv(128, 256, 2)\n",
        "        self.dw_conv6 = DepthwiseSeparableConv(256, 256, 1)\n",
        "        self.dw_conv7 = DepthwiseSeparableConv(256, 512, 2)\n",
        "\n",
        "        # Lima konvolusi separable tambahan dengan stride 1\n",
        "        self.dw_conv8 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv9 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv10 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv11 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv12 = DepthwiseSeparableConv(512, 512, 1)\n",
        "\n",
        "        self.dw_conv13 = DepthwiseSeparableConv(512, 1024, 2)\n",
        "        self.dw_conv14 = DepthwiseSeparableConv(1024, 1024, 1)\n",
        "\n",
        "        # Layer pooling dan fully connected untuk klasifikasi\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # Output ukuran (1, 1)\n",
        "        self.fc = nn.Linear(1024, num_classes)  # Klasifikasi\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # Konvolusi awal\n",
        "        x = F.relu(x)  # Aktivasi ReLU\n",
        "\n",
        "        # MobileNet body\n",
        "        x = self.dw_conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv7(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Lima depthwise separable convolution tambahan\n",
        "        x = self.dw_conv8(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv9(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv10(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv11(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv12(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dw_conv13(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv14(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Pooling dan fully connected\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten output\n",
        "        x = self.fc(x)  # Klasifikasi\n",
        "        return x\n",
        "\n",
        "# Create the model\n",
        "mobilenet = MobileNet(num_classes=1000)\n",
        "print(mobilenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATHRXyxxAdFT",
        "outputId": "e26040d2-0da7-4b0f-bb7d-669657747e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (dw_conv2): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv3): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
            "    (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv4): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "    (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv5): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv6): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "    (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv7): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
            "    (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv8): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv9): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv10): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv11): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv12): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv13): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv14): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
            "    (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "PmTxfvGWFgp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning adalah teknik pembelajaran mesin di mana model yang sudah dilatih untuk suatu tugas digunakan kembali sebagai titik awal untuk model di tugas lain. Teknik ini memanfaatkan pengetahuan dari tugas sebelumnya untuk meningkatkan pembelajaran dan performa pada tugas baru yang berhubungan.\n",
        "\n",
        "Pendekatan Transfer Learning:\n",
        "Fine-Tuning: Menyesuaikan model yang telah dilatih dengan melatih ulang beberapa lapisan akhir menggunakan data dari tugas baru. Ini memungkinkan model beradaptasi dengan spesifikasi tugas yang berbeda.\n",
        "\n",
        "Feature Extraction: Menggunakan model yang telah dilatih sebagai ekstraktor fitur, di mana representasi yang dihasilkan digunakan untuk melatih model sederhana pada tugas baru."
      ],
      "metadata": {
        "id": "4DMX92HEFjFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "timm: Library Python untuk model visi komputer yang telah dilatih sebelumnya. Mendukung banyak model arsitektur jaringan saraf dalam computer vision"
      ],
      "metadata": {
        "id": "TDcZ4f1AGF-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzWuxJd6ICJB",
        "outputId": "cca7be2d-add0-42f2-e17d-03894ca33c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.27.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tujuan: Menggunakan MobileNetV3-Large (versi besar dari arsitektur MobileNetV3) yang telah dilatih sebelumnya (pre-trained) pada dataset ImageNet untuk melakukan inferensi pada gambar input . Transfer learning pada MobileNetV3 berarti memanfaatkan model yang sudah dilatih sebelumnya pada dataset besar seperti ImageNet untuk mempercepat dan meningkatkan akurasi model ketika diterapkan pada tugas baru."
      ],
      "metadata": {
        "id": "KKQRNSxiIcFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained MobileNet model\n",
        "model_name = \"mobilenetv3_large_100\"\n",
        "\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# If you want to use the model for inference\n",
        "model.eval()\n",
        "\n",
        "# Forward pass with a dummy input\n",
        "# Batch size 1, 3 color channels, 224x224 image\n",
        "input_tensor = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "346f3f0be1a9444d834be50cc72af192",
            "edcecaaa760740a0b71ebf70b6e6c194",
            "023715a4f905486389d72d9e5e64ea19",
            "76f9832d3789422bbba4dab2dd2df765",
            "c7379ac629e243ac9e86744e31a6640e",
            "ea8e88193b3a45c382900bc932f66fee",
            "c9520966f74d43b586475bd32018523f",
            "380317ccbf744cc9b9719cdec1ec96f9",
            "2e0c7cc5a3ed4932b7143d3bbf017a2f",
            "40a2806782d64a38a50e5bc42c910b59",
            "a77ca5aaf0754094bfcb9be304366380"
          ]
        },
        "id": "1wKUo3T2IC-C",
        "outputId": "79909d8f-dc29-4870-8a65-603ec51da11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/22.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "346f3f0be1a9444d834be50cc72af192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.5577e+00,  3.7155e-01,  4.6123e-01,  9.6552e-02,  8.1252e-01,\n",
            "          6.6807e-02,  6.5756e-01, -3.3988e-01, -1.9668e-01, -5.2795e-01,\n",
            "          1.2036e-01,  4.1430e-01,  8.9071e-01,  5.1821e-01,  5.8612e-01,\n",
            "          8.1270e-01,  1.4119e+00, -2.3977e-01,  1.7008e+00,  1.1076e+00,\n",
            "          3.7075e-01,  3.3031e+00,  1.9536e+00,  2.7468e+00,  8.6084e-01,\n",
            "         -4.1663e-01, -1.1914e+00, -7.6253e-01, -8.2769e-01, -1.7428e+00,\n",
            "         -1.0516e+00, -7.8037e-01, -1.6514e+00,  9.6664e-01,  3.0694e+00,\n",
            "         -1.4948e+00, -1.2673e+00, -1.2919e+00, -2.6515e-01, -9.4674e-01,\n",
            "         -2.2127e-01, -4.2171e-02,  1.6027e+00,  3.7812e-01, -6.1439e-02,\n",
            "          9.1364e-02, -5.5856e-02, -5.0446e-01, -7.9315e-01, -1.6457e+00,\n",
            "         -2.0898e-01,  2.5867e-02, -8.5002e-02,  2.4259e-01,  8.4431e-01,\n",
            "         -1.8692e-01,  5.5112e-01, -1.2460e+00,  1.5623e+00, -4.9573e-01,\n",
            "          1.4243e+00, -2.5727e-01, -6.7993e-03, -3.0962e-02, -1.5995e-01,\n",
            "          2.7360e+00,  1.3497e+00,  4.7449e-01,  1.7000e+00,  1.1530e+00,\n",
            "          6.5959e-01,  1.8148e+00,  5.0080e-01, -2.0181e-01,  2.4087e-01,\n",
            "          8.5842e-01,  4.1068e-01,  1.0210e+00,  2.9564e+00,  2.1030e+00,\n",
            "         -3.6926e-01,  3.7951e-01, -4.3149e-01, -9.1639e-01, -2.6414e-01,\n",
            "          8.8439e-01, -4.5813e-01,  1.4771e+00,  9.4837e-01,  1.5072e+00,\n",
            "         -7.1454e-01,  1.0664e+00,  2.8925e+00,  6.6919e-01,  2.9462e+00,\n",
            "          2.8514e-01,  8.8005e-01, -1.9087e-01,  4.6962e-01,  8.4710e-01,\n",
            "         -1.5022e-01, -1.1616e+00,  3.4865e-01, -4.9142e-01, -2.2481e-01,\n",
            "         -2.0268e-01,  3.3632e-01,  2.2733e+00, -8.7373e-01,  1.4957e-01,\n",
            "         -9.5060e-01,  1.6573e+00,  1.9677e+00, -1.2296e-01,  8.2243e-01,\n",
            "         -1.6460e+00, -1.2646e+00,  8.9242e-01, -7.3757e-01,  9.4817e-02,\n",
            "          1.1243e+00, -1.2193e+00, -1.5558e+00, -1.2212e+00, -5.2498e-01,\n",
            "          1.5662e+00,  4.5737e-01,  1.9298e+00,  2.4836e+00,  1.5301e+00,\n",
            "         -3.8420e-01, -4.0518e-02,  1.3536e+00,  1.0735e+00, -3.7804e-02,\n",
            "          1.3477e-01, -4.0286e-01,  8.0505e-01,  1.4248e+00,  9.8300e-01,\n",
            "          8.8497e-01,  7.6961e-01,  3.9133e-01,  4.9606e-01, -2.5525e-01,\n",
            "         -1.3550e+00,  1.5335e+00,  2.1773e-01, -9.6177e-02, -1.4213e+00,\n",
            "         -7.7161e-01,  7.3642e-01, -1.0605e+00,  7.1956e-01, -8.1666e-02,\n",
            "          1.3819e+00,  8.6296e-02,  5.8247e-02,  2.1532e-01, -9.9472e-01,\n",
            "         -1.8605e+00,  4.3528e-01,  1.0970e+00, -2.0618e-01,  1.1471e+00,\n",
            "         -5.2621e-01,  4.5679e-01, -9.6677e-01,  1.1063e+00, -6.7510e-01,\n",
            "          9.0682e-02,  9.2015e-01, -4.7317e-01, -5.9015e-01,  2.3269e-01,\n",
            "         -1.0903e+00, -2.2110e+00, -1.8001e+00,  1.3010e-01, -2.0260e+00,\n",
            "          6.4908e-01, -1.1661e+00, -3.5562e-01, -8.3115e-01,  8.5138e-02,\n",
            "         -4.8270e-01, -1.6869e-01,  1.3394e+00, -1.5208e+00, -9.2497e-01,\n",
            "         -2.8560e-01, -2.1948e+00,  4.9951e-01, -4.5371e-01, -7.2915e-01,\n",
            "          1.1024e-01,  5.9032e-01, -8.7872e-01, -7.3308e-02, -1.1195e+00,\n",
            "         -8.2727e-01, -1.5917e-03, -2.7101e-01,  1.0427e+00, -9.6990e-01,\n",
            "         -1.0829e+00, -9.6307e-01, -5.9880e-01, -1.3061e+00,  4.1001e-02,\n",
            "         -3.6987e-01, -5.4750e-02, -5.0183e-01, -1.2248e+00, -1.0045e+00,\n",
            "         -3.3886e-01, -1.0561e+00, -4.9893e-01, -2.0561e-02, -5.4775e-01,\n",
            "         -8.3386e-01, -1.3979e+00, -1.1157e+00,  7.3509e-03, -1.3133e+00,\n",
            "         -6.7876e-01, -1.2459e+00,  6.8756e-01, -7.6531e-01,  4.1790e-01,\n",
            "         -1.4138e+00, -8.7892e-01, -3.9481e-01, -1.1520e+00, -9.8490e-01,\n",
            "          7.5616e-02, -6.1134e-02,  3.9599e-01,  6.6941e-01, -1.3915e+00,\n",
            "         -1.3830e+00, -7.7900e-01, -1.2623e+00, -1.0108e+00, -1.6574e+00,\n",
            "          1.3982e-01, -1.3573e+00, -7.3027e-01,  1.5078e-01, -2.1821e-01,\n",
            "         -7.8293e-01, -3.8823e-01, -1.1447e+00,  2.0927e-01, -1.1067e+00,\n",
            "         -1.5962e+00, -2.3467e-01,  2.7493e-01,  6.2459e-01,  4.3501e-01,\n",
            "         -7.6240e-01, -3.4563e-01, -2.2356e+00,  2.9521e-01,  7.7339e-01,\n",
            "          5.9254e-01, -5.9790e-01, -8.6988e-01, -1.1492e+00, -1.2992e+00,\n",
            "         -7.8282e-01, -1.5520e+00, -9.9506e-02,  1.6114e-01, -1.0832e+00,\n",
            "         -3.4134e-01,  2.5226e-02, -5.7768e-01, -2.9522e-01, -7.4310e-01,\n",
            "         -7.8835e-01,  8.9961e-01,  1.8730e-01, -7.7779e-01,  7.4100e-01,\n",
            "          2.4453e+00, -3.1100e-01, -2.6196e-01, -1.5471e+00, -2.0184e+00,\n",
            "         -9.8121e-01, -2.3534e-01, -1.6560e+00,  9.4215e-02, -2.0181e+00,\n",
            "         -3.2787e-01, -9.5132e-01,  3.6888e-01,  5.3300e-01,  1.1673e+00,\n",
            "         -2.3016e-01,  1.5716e+00, -5.7777e-01, -5.0620e-01,  4.0367e-01,\n",
            "          2.6173e+00,  1.0935e+00,  3.1504e-01, -4.9560e-01, -1.2004e+00,\n",
            "          9.0658e-01,  1.2446e-01,  1.2921e+00,  1.5859e+00,  2.6178e+00,\n",
            "          3.6271e-01,  1.4420e-02, -1.1701e-01,  1.0487e+00,  1.1189e+00,\n",
            "          5.4403e-01, -1.5005e+00, -1.1476e+00, -3.6002e-01, -5.4812e-01,\n",
            "         -3.8673e-01, -8.7156e-01,  2.6357e+00,  3.2197e-01,  5.4614e-01,\n",
            "         -8.1203e-01, -4.4339e-01, -2.8550e-01, -2.4204e+00, -7.3092e-02,\n",
            "         -7.8139e-01, -1.0441e+00, -1.8430e+00, -1.3354e+00, -8.7242e-01,\n",
            "         -1.7891e+00, -1.9186e+00, -1.6953e+00, -7.2249e-01, -1.7951e+00,\n",
            "         -1.5530e+00, -3.4669e-01, -7.7544e-01, -3.5416e-01,  8.1257e-01,\n",
            "         -2.5685e-02, -3.3450e-01, -1.3592e+00,  1.1620e+00,  2.0740e-01,\n",
            "         -1.7411e+00,  8.6083e-01, -1.2586e+00,  1.7688e-01,  1.5376e+00,\n",
            "         -1.1816e+00, -1.7486e-01, -4.4078e-01,  5.2218e-01, -5.6430e-01,\n",
            "         -1.1061e-01, -5.1824e-01, -6.8486e-02, -8.9385e-01, -9.0500e-01,\n",
            "         -9.7333e-01, -1.4122e+00, -3.0679e-01, -7.1768e-01, -5.9945e-01,\n",
            "         -4.3046e-01,  4.4057e-01, -3.2263e-01, -1.2670e+00, -1.0959e+00,\n",
            "         -5.7772e-01, -7.1911e-01, -2.0551e-01, -8.6687e-01, -3.1191e-02,\n",
            "         -1.3235e+00, -1.0120e+00, -9.1443e-01, -1.1550e+00, -1.2105e+00,\n",
            "         -4.6239e-01, -8.1502e-01, -2.0724e+00, -1.7894e+00, -1.3826e+00,\n",
            "         -1.0044e-01, -9.5321e-01,  1.1337e+00, -1.0746e+00,  2.5947e-01,\n",
            "         -8.2941e-01, -1.0958e+00,  1.3499e+00, -9.0309e-01,  7.5432e-01,\n",
            "          1.9782e+00, -1.1315e+00, -9.7379e-01, -1.9650e+00,  1.9198e+00,\n",
            "         -1.7017e+00,  1.4730e+00,  6.4859e-01,  3.9225e-01,  7.4011e-01,\n",
            "         -9.1635e-01,  4.2608e-01,  9.0688e-01,  2.5254e+00,  7.7264e-01,\n",
            "          2.7420e+00,  7.6760e-01, -1.5269e+00, -1.0111e+00, -2.0106e+00,\n",
            "         -2.1853e-01,  2.7608e-01, -1.4040e+00, -1.0666e+00,  6.9114e-01,\n",
            "         -7.7549e-01, -1.8928e-01,  1.4720e+00,  6.1134e-01,  8.1069e-01,\n",
            "         -1.7603e+00, -1.7005e+00,  1.3990e+00, -1.9912e-01, -4.6802e-01,\n",
            "          8.6886e-01, -5.3915e-01,  2.2403e-01,  1.9738e+00, -4.1927e-01,\n",
            "         -8.3859e-01,  4.3045e+00, -1.4331e+00,  8.6581e-01, -7.4405e-01,\n",
            "         -1.3874e+00,  1.6526e+00, -7.5861e-01, -1.3524e+00, -7.5823e-01,\n",
            "          1.4684e+00, -6.0791e-02,  2.8163e-01,  6.2630e-01,  3.9753e-01,\n",
            "          1.6727e+00,  6.7513e-01,  7.5085e-01, -4.7676e-01,  1.7116e-01,\n",
            "          8.1339e-01, -1.0368e+00, -1.1525e+00, -8.0496e-01, -1.3210e+00,\n",
            "         -1.3510e-01, -1.4119e+00, -1.6112e+00,  7.0994e-01,  1.1001e+00,\n",
            "         -1.7206e+00, -4.8063e-01, -8.1394e-01,  1.1449e+00, -7.4928e-01,\n",
            "          1.6930e-02,  6.3566e-01, -2.2830e-01, -6.3998e-01,  4.2330e-01,\n",
            "         -2.0032e-01,  2.9266e-01,  7.8329e-01,  2.3082e+00,  1.0096e+00,\n",
            "         -1.5919e-01, -3.3349e-01, -1.4975e-01, -1.1776e+00,  1.1176e+00,\n",
            "         -1.7200e+00,  5.2708e-01, -6.7414e-02, -1.5195e+00, -1.0901e-01,\n",
            "         -5.4176e-01, -1.3288e+00,  1.0679e+00, -5.3139e-01, -5.1603e-01,\n",
            "         -8.6681e-01, -1.3793e-01,  4.9517e-01,  1.2141e-01, -1.5635e+00,\n",
            "          1.0704e-01, -1.2507e+00,  2.2474e+00,  3.8037e-01,  7.1287e-01,\n",
            "          1.1169e+00, -1.6614e+00,  2.1142e+00,  5.4163e-01, -2.5980e+00,\n",
            "         -8.4087e-01, -6.6761e-01,  7.4256e-01,  1.2858e+00, -2.4781e-02,\n",
            "         -1.3027e+00, -1.3124e-01, -1.0928e+00, -1.1110e-01,  4.5736e-01,\n",
            "          2.0255e+00, -9.6880e-01, -1.9907e-01,  7.4848e-01,  7.5519e-01,\n",
            "         -1.3162e+00, -8.0621e-01, -1.0666e-01,  1.2761e+00,  2.6841e+00,\n",
            "          1.8670e-02,  8.0132e-01,  1.6491e+00,  1.8562e+00, -7.4458e-01,\n",
            "          9.6841e-01,  1.2059e+00, -8.3439e-01, -1.1857e+00,  3.7451e+00,\n",
            "         -2.0409e+00, -1.4988e+00,  3.1552e-01,  9.4131e-01, -3.8005e-02,\n",
            "         -1.0992e+00,  2.6504e+00,  1.9556e+00,  2.8413e+00,  1.2183e+00,\n",
            "          8.0327e-01, -1.6989e+00, -3.8993e-01,  3.1083e+00, -2.4042e+00,\n",
            "         -8.7402e-02, -1.3747e+00,  2.0358e-03, -1.3024e+00, -1.8360e+00,\n",
            "         -1.0217e+00, -1.0339e+00,  1.1672e+00,  5.5695e-01,  1.8161e+00,\n",
            "         -1.1643e+00, -2.6699e+00, -3.8262e-02, -6.3223e-01, -1.5882e+00,\n",
            "         -1.8478e-01, -1.2703e+00, -9.7296e-01, -6.1260e-02,  4.8066e-01,\n",
            "         -5.1840e-01, -1.4082e+00,  2.1448e+00,  5.9864e-01,  1.2479e+00,\n",
            "         -1.1735e+00,  2.4519e+00,  3.5660e-02,  1.2141e+00, -1.5445e+00,\n",
            "          7.8049e-01,  1.0200e+00,  1.6057e+00,  1.0879e+00, -4.8108e-01,\n",
            "          2.7801e+00, -4.4668e-01, -2.6487e-01, -1.8939e+00,  1.1844e+00,\n",
            "          1.0577e+00,  1.1355e+00, -4.8089e-01,  4.9401e-01, -1.9586e+00,\n",
            "          2.8504e+00, -5.6898e-01, -9.5008e-01,  1.1181e+00, -4.5489e-01,\n",
            "         -4.8580e-01,  2.6337e+00, -7.6670e-01,  2.8746e+00,  2.9299e+00,\n",
            "          1.8320e+00, -2.8377e-01,  2.4984e+00,  2.6705e+00,  3.0126e-01,\n",
            "          1.9798e-02,  1.0898e+00, -5.6339e-01,  6.4552e-02,  1.2955e+00,\n",
            "         -4.8564e-01,  8.7163e-01,  2.1199e+00, -2.2393e-01, -2.3843e+00,\n",
            "         -4.7533e-01,  4.1816e-01,  1.7365e-01,  4.3134e-01,  9.2501e-02,\n",
            "          1.0557e-01,  9.2775e-01,  1.0260e+00,  8.8623e-01,  2.6554e+00,\n",
            "         -2.3630e-01, -4.0258e-03,  5.8279e-02, -1.3622e+00,  4.1865e-01,\n",
            "          2.1113e+00, -9.0109e-01,  3.9382e-01, -9.4589e-01, -1.3448e+00,\n",
            "          1.0959e+00, -1.1988e+00,  2.4272e+00, -1.1179e+00,  1.0776e+00,\n",
            "         -1.1462e+00, -1.7202e+00,  2.0405e+00, -1.1890e+00,  6.8858e-01,\n",
            "          3.2089e-01, -1.0398e+00, -3.4725e-01, -6.6388e-02, -7.1324e-01,\n",
            "         -8.3704e-01, -1.1286e+00, -7.2338e-01,  6.0306e-01,  1.2116e+00,\n",
            "         -1.8686e+00, -1.2850e+00,  1.6044e+00, -1.2744e+00,  1.5002e+00,\n",
            "          5.2443e-01,  2.4331e+00,  2.3427e+00,  1.3570e+00,  1.2864e+00,\n",
            "         -1.1700e+00,  5.8794e-01, -8.6738e-01, -1.0129e+00, -7.0902e-01,\n",
            "         -1.2354e+00, -1.2906e+00, -1.1971e-01,  7.3684e-02, -3.1972e-01,\n",
            "         -3.3491e-01,  1.7483e+00, -1.4779e+00, -5.3530e-02,  5.5445e-02,\n",
            "          1.8139e+00,  3.2389e+00, -4.2106e-01, -2.0068e+00,  3.5165e-01,\n",
            "         -1.4352e+00, -1.6485e+00, -1.3454e+00, -4.5079e-01, -9.0365e-01,\n",
            "          1.0484e+00, -4.5993e-02,  4.1908e-01, -1.3799e+00,  2.3868e+00,\n",
            "         -1.9071e-01,  3.9746e-01, -1.4234e+00,  6.3296e-01,  4.5992e-01,\n",
            "          7.2529e-01,  2.2775e+00,  1.3628e+00,  9.3747e-01,  4.9120e-01,\n",
            "          1.3567e+00, -4.9184e-01,  9.8025e-01,  2.5783e-02, -1.9213e+00,\n",
            "         -1.0101e+00,  1.7664e+00, -8.6555e-01,  3.1528e-03, -1.6179e+00,\n",
            "          1.1685e+00, -3.0140e-01, -4.2379e-01, -5.8648e-01, -2.7582e+00,\n",
            "          1.9743e+00,  1.7572e+00,  3.2551e-01, -1.0782e+00,  8.5773e-01,\n",
            "         -6.8140e-01,  9.8163e-01, -4.4501e-01, -2.7107e-01,  2.5493e+00,\n",
            "          8.0282e-01, -2.8395e-01,  2.1589e+00,  1.7217e-01, -2.6508e-01,\n",
            "         -3.4300e-01, -1.1504e+00, -1.1082e+00, -6.0463e-03, -4.3128e-01,\n",
            "          3.1009e-01,  1.2581e+00, -1.1349e+00,  3.0017e+00,  1.1142e+00,\n",
            "          6.8471e-01, -6.1446e-01,  1.1749e+00, -8.0652e-01,  2.2094e+00,\n",
            "          8.7067e-01,  9.7003e-02,  2.1370e+00, -1.5774e-01,  5.4563e-01,\n",
            "          7.4831e-01,  5.2951e-01,  1.9747e+00, -2.5741e-01, -6.3998e-01,\n",
            "          7.7542e-01,  4.8932e-01, -1.4698e-01,  2.5672e+00,  2.4736e+00,\n",
            "          8.2917e-02, -2.1970e+00, -9.0250e-01,  1.1720e+00,  4.1614e-01,\n",
            "         -2.9216e-01,  4.1131e-02,  8.8553e-01, -1.3765e-01,  1.5597e+00,\n",
            "          1.5066e+00, -5.6910e-01,  8.9850e-01, -5.7432e-01,  7.7657e-01,\n",
            "         -9.8970e-01, -8.4682e-01, -3.8955e-01, -1.8944e+00,  1.7976e+00,\n",
            "          1.6494e+00,  4.7816e-01, -1.4218e+00, -2.5002e-01, -7.9455e-01,\n",
            "         -1.0439e+00,  2.1450e+00,  8.5731e-01,  1.9126e+00, -1.5597e-01,\n",
            "          1.1420e-01,  1.4584e+00, -6.5797e-01,  8.6355e-01, -1.2554e+00,\n",
            "         -4.8079e-01, -6.4588e-01, -1.3729e+00, -1.2926e+00,  9.1229e-01,\n",
            "         -8.2483e-01,  4.3756e-02, -1.6478e+00,  1.4445e+00, -1.7700e+00,\n",
            "         -3.8941e-01, -8.2507e-01, -7.5367e-01,  4.8445e-01,  5.0382e-01,\n",
            "         -7.8329e-01, -6.6544e-01,  3.4238e-01, -8.6885e-01, -1.1096e-01,\n",
            "          1.4922e+00,  9.9781e-01,  1.1726e+00, -5.8809e-01,  2.8708e+00,\n",
            "          2.9896e+00,  5.7810e-01, -1.5134e+00,  8.1140e-01, -1.8819e-01,\n",
            "         -6.0987e-01, -1.5152e-02,  3.1123e+00, -6.4601e-01, -1.9539e-01,\n",
            "          7.5817e-01,  9.5947e-02, -8.6854e-01, -3.9620e-01,  4.3649e-01,\n",
            "         -4.3993e-01,  4.4333e-01,  6.6160e-02,  5.5424e-01, -1.5105e+00,\n",
            "         -1.2453e+00, -1.3609e+00, -8.6534e-01,  1.8823e+00, -1.1904e+00,\n",
            "          1.5158e+00, -2.6634e-01,  8.1937e-01, -8.1348e-01, -1.1127e+00,\n",
            "         -1.3249e-01, -5.4585e-01, -1.8605e+00, -1.2833e+00,  1.1463e+00,\n",
            "          3.6949e-01, -6.2652e-01,  1.2970e+00,  6.4337e-01, -7.3121e-01,\n",
            "          2.1233e+00, -8.7397e-01, -1.2738e+00, -8.5325e-01, -6.1137e-01,\n",
            "         -8.3543e-01, -8.8326e-01,  3.3975e+00,  1.5598e+00, -4.9280e-01,\n",
            "          1.2058e+00,  2.2748e-01, -6.3221e-01,  1.5788e+00,  1.1049e+00,\n",
            "          1.0955e+00, -1.1656e+00,  9.8157e-01, -2.9675e-01,  1.7350e+00,\n",
            "          5.6011e-01,  8.7904e-01,  6.7060e-02,  1.7625e-01,  6.1378e-02,\n",
            "          1.8299e+00,  2.0282e+00, -3.9648e-01,  8.7078e-02, -5.9477e-01,\n",
            "         -1.4620e+00, -6.2035e-01, -5.5459e-01, -9.8721e-02,  6.0483e-01,\n",
            "          1.4694e+00,  1.8743e+00,  1.3545e+00, -5.3225e-01, -5.3541e-01,\n",
            "          7.7949e-02, -2.0835e+00, -6.5819e-01, -5.9764e-01, -9.3560e-02,\n",
            "         -1.2989e+00, -1.2341e+00,  5.8860e-01, -3.7681e-01, -8.5731e-01,\n",
            "         -3.2459e-01, -1.5057e+00, -1.9417e+00, -1.4117e+00, -8.1125e-01,\n",
            "         -1.9692e+00, -1.1380e+00, -1.8457e+00, -2.4529e-01, -1.2999e+00,\n",
            "         -2.2925e-01, -9.3272e-02, -1.7675e+00, -2.7154e-01,  8.1648e-01,\n",
            "         -5.0255e-01,  5.3764e-01, -1.9068e-01, -1.1315e+00, -6.5748e-02,\n",
            "         -1.0510e+00, -1.9327e+00, -7.9135e-01, -7.3314e-02, -1.0660e+00,\n",
            "         -1.0831e+00,  1.3945e-01, -2.0628e+00, -8.6980e-01,  1.2345e-01,\n",
            "         -1.7770e+00,  1.8029e-02, -3.0463e-01, -6.9094e-02, -5.6364e-01,\n",
            "         -3.1507e-01,  1.1021e+00,  3.3770e-01, -1.3900e+00, -1.6257e-01,\n",
            "          6.6917e-02,  5.2398e-01,  1.6088e+00,  4.7816e-01, -5.6010e-01,\n",
            "         -2.9320e-01, -3.6858e-01, -1.2550e+00, -1.4933e+00,  6.6127e-01,\n",
            "         -5.1024e-01, -9.1710e-01, -1.4983e+00, -1.1844e+00, -2.5387e-01,\n",
            "         -3.7030e-01, -1.1275e+00, -1.2433e+00, -3.6223e-01, -2.7063e-01,\n",
            "         -6.7905e-01, -9.7726e-01, -1.3552e-01, -1.8364e+00,  1.7654e+00]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet"
      ],
      "metadata": {
        "id": "bvbas7SwJJpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet adalah arsitektur jaringan saraf dalam yang diperkenalkan oleh Kaiming He dkk. pada tahun 2015. Arsitektur ini dirancang untuk mengatasi masalah degradasi yang terjadi saat melatih jaringan yang sangat dalam dengan menambahkan skip connections atau residual connections yang memungkinkan aliran informasi langsung dari satu lapisan ke lapisan lainnya tanpa melalui transformasi non-linear. Hal ini memungkinkan pelatihan jaringan yang lebih dalam tanpa penurunan kinerja."
      ],
      "metadata": {
        "id": "ZcH9hs_1JJ-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skip connection (atau shortcut connection) adalah sebuah jalur langsung dari satu lapisan ke lapisan lain, melompati beberapa lapisan tengah. Pada umumnya, jalur ini digunakan untuk membawa informasi dari lapisan sebelumnya langsung ke lapisan yang lebih dalam. Ini bertujuan untuk menjaga agar informasi tidak hilang atau terdistorsi saat melalui lapisan-lapisan yang lebih dalam.\n",
        "\n",
        "Residual connection adalah varian dari skip connection yang lebih khusus. Pada residual connection, lapisan tambahan digunakan untuk menghitung perbedaan (residual) antara input dan output dari lapisan tertentu"
      ],
      "metadata": {
        "id": "8nXO1iTTJSf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-Z666nqKO9j",
        "outputId": "f28b2480-fd31-41ed-846a-3f308cd0798c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang dibutuhkan untuk pemrosesan gambar dan klasifikasi menggunakan pre-trained model\n",
        "from transformers import ResNetForImageClassification\n",
        "from transformers import AutoFeatureExtractor\n",
        "import torch\n",
        "from datasets import load_dataset  # Library untuk mengakses dataset dari Hugging Face Datasets\n",
        "\n",
        "# Memuat model ResNet-50 yang sudah dilatih sebelumnya (pre-trained)\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "# Mengatur model ke mode evaluasi. Ini penting untuk mematikan mekanisme dropout dan batch normalization yang hanya digunakan saat pelatihan\n",
        "model.eval()\n",
        "\n",
        "# Memuat dataset gambar untuk pengujian\n",
        "dataset = load_dataset(\"huggingface/cats-image\")  # Dataset yang berisi gambar kucing untuk pengujian\n",
        "image = dataset[\"test\"][\"image\"][0]  # Mengambil gambar pertama dari set data 'test'\n",
        "\n",
        "# Menggunakan feature extractor untuk mempersiapkan gambar sebelum diberi input ke model\n",
        "# Feature extractor akan mengubah gambar menjadi format tensor yang sesuai dengan input model ResNet-50\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "# Preprocess gambar yang dipilih untuk mempersiapkannya sebagai input model\n",
        "inputs = feature_extractor(image, return_tensors=\"pt\")  # Mengembalikan input dalam format tensor PyTorch\n",
        "\n",
        "# Menggunakan model untuk melakukan prediksi. `torch.no_grad()` digunakan untuk menghindari pencatatan gradien yang tidak diperlukan selama inferensi\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits  # Mendapatkan output logits dari model, yang berisi nilai prediksi untuk setiap kelas\n",
        "\n",
        "# Model memberikan prediksi salah satu dari 1000 kelas ImageNet.\n",
        "# `logits.argmax(-1)` mengambil indeks kelas dengan nilai tertinggi (prediksi model)\n",
        "predicted_label = logits.argmax(-1).item()  # Mengambil indeks kelas dengan probabilitas tertinggi\n",
        "print(model.config.id2label[predicted_label])  # Mencetak nama kelas yang diprediksi berdasarkan indeks yang didapat\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7Rggh_VzJSyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}